{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga](https://www.dropbox.com/s/yjijtfuky3s5dfz/2.5.Compute_Unified_Device_Architecture.pdf?dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Unified Device Architecture (CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un poco de historia..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La industria de videojuegos impulsó el desarrollo de las tarjetas gráficas a una velocidad sin precedente a partir del año 1999 para incrementar el nivel de detalle visual en los juegos de video. Alrededor del 2003 se planteó la posibilidad de utilizar las unidades de procesamiento gráfico para procesamiento en paralelo relacionado con aplicaciones distintas al ambiente de gráficas. A partir del 2006 la empresa [NVIDIA](https://www.nvidia.com/en-us/about-nvidia/) introdujo *CUDA*, una plataforma *GPGPU*\\* y un modelo de programación que facilita el procesamiento en paralelo en las GPU's.\n",
    "\n",
    "\\*GPGPU es un término que se utilizó para referirse a la programación general en unidades de procesamiento gráfico, hoy en día se conoce simplemente como *GPU programming*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde entonces las tarjetas gráficas han creado una brecha significativa con las unidades de procesamiento, CPU's. Ver por ejemplo las gráficas que *NVIDIA* publica año tras año y que están relacionadas con el número de operaciones en punto flotante por segundo (FLOPS) y la transferencia de datos en la memoria RAM de la GPU:\n",
    "\n",
    "https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#from-graphics-processing-to-general-purpose-parallel-computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La arquitectura en la que podemos ubicar a las GPU's es en la de un sistema **MIMD** y **SIMD**, de hecho es [SIMT: Simple Instruction Multiple Thread](https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads) en un modelo de sistema de memoria compartida. Ver [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Diferencia con la CPU multicore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En cuanto al hardware:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/k11qub01w4nvksi/CPU_multicore.png?dl=0\" heigth=\"500\" width=\"500\">\n",
    "\n",
    "**GPU**\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/lw9kia12qhwp95r/GPU.png?dl=0\" heigth=\"500\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de una máquina multicore o multi CPU's con la habilidad de lanzar en un instante de tiempo unos cuantos *threads*, por ejemplo cuatro threads en una máquina *quad core*, la *GPU* puede lanzar cientos o miles de threads en un instante. Sí hay restricciones en el número de threads que se pueden lanzar en un instante pues las tarjetas gráficas tienen diferentes características (modelo) y arquitecturas (ver [List of NVIDIA GPU's](https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units)) pero la diferencia es grande. Por ejemplo, el modelo **GT 200** (2009) en un instante puede lanzar 30,720 threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Otras compañías producen tarjetas gráficas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver por ejemplo la lista de GPU's de [Advanced Micro Devices](https://en.wikipedia.org/wiki/List_of_AMD_graphics_processing_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Si tengo una tarjeta gráfica de AMD puedo correr un programa de CUDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es posible pero entre las alternativas están:\n",
    "\n",
    "* [OpenCl](https://www.khronos.org/opencl/)\n",
    "\n",
    "* [OpenACC](https://www.openacc.org/about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Si tengo una tarjeta gráfica de NVIDIA un poco antigua puedo correr un programa de CUDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las GPU's producidas por NVIDIA desde 2006 son capaces de correr programas basados en **CUDA C**. La cuestión sería revisar qué *compute capability* tiene tu tarjeta. Ver [Compute Capabilities](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities) para las características que tienen las tarjetas más actuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es CUDA C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una extensión al lenguaje C de programación en el que se utiliza una nueva sintaxis para procesamiento en la GPU. Contiene también una librería *runtime* que define funciones que se ejecutan desde **host** por ejemplo para alojar y desalojar memoria en **device**, transferir datos entre la memoria host y la memoria device o manejar múltiples devices. La librería *runtime* está hecha encima de una API de C de bajo nivel llamada [NVIDIA CUDA Driver API](https://docs.nvidia.com/cuda/cuda-driver-api/index.html). Para información de la API de la librería runtime ver [NVIDIA CUDA Runtime API](https://docs.nvidia.com/cuda/cuda-runtime-api/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿A qué se refiere la terminología de host y device?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Host es la máquina multicore o multi CPU's y device es la GPU. Una máquina puede tener múltiples GPU's por lo que tendrá múltiples devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tengo una tarjeta NVIDIA CUDA capable ¿qué debo realizar primero?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar instalaciones dependiendo de tu sistema operativo. Ver [Instalación](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA/instalacion) donde además se encontrará información para instalación de [nvidia-docker](https://github.com/NVIDIA/nvidia-docker)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalé lo necesario y al ejecutar en la terminal `nvcc -V` obtengo la versión... ¿cómo puedo probar mi instalación?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Obteniendo información del NVIDIA driver ejecutando en la terminal:\n",
    "\n",
    "```\n",
    "$nvidia-smi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compilando y ejecutando el siguiente programa de *CUDA C*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programa de hello world:** `hello_world.cu`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    printf(\"Hello world del bloque %d del thread %d!\\n\", blockIdx.x, threadIdx.x);\n",
    "}\n",
    "int main(void){\n",
    "    func<<<3,3>>>(); //3 bloques de 3 threads cada uno\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Hola del cpu thread\\n\");\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilación: `$nvcc hello_world.cu -o hello_world.out`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecución: `$./hello_world.out`:\n",
    "\n",
    "```\n",
    "Hello world del bloque 1 del thread 0!\n",
    "Hello world del bloque 1 del thread 1!\n",
    "Hello world del bloque 1 del thread 2!\n",
    "Hello world del bloque 0 del thread 0!\n",
    "Hello world del bloque 0 del thread 1!\n",
    "Hello world del bloque 0 del thread 2!\n",
    "Hello world del bloque 2 del thread 0!\n",
    "Hello world del bloque 2 del thread 1!\n",
    "Hello world del bloque 2 del thread 2!\n",
    "Hola del cpu thread\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué librerías/paquetes/extensiones se revisarán en el módulo II del curso?\n",
    "\n",
    "* [CUDA_C](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.3.CUDA_C.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**\n",
    "\n",
    "1. N. Matloff, Parallel Computing for Data Science. With Examples in R, C++ and CUDA, 2014.\n",
    "\n",
    "2. [CUDA](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
