{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga](https://www.dropbox.com/s/yjijtfuky3s5dfz/2.5.Compute_Unified_Device_Architecture.pdf?dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notas para contenedor de docker:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comando de docker para ejecución de la nota de forma local:\n",
    "\n",
    "nota: cambiar `<ruta a mi directorio>` por la ruta de directorio que se desea mapear a `/datos` dentro del contenedor de docker.\n",
    "\n",
    "```\n",
    "docker run --gpus all --rm -v $(pwd):/datos --name jupyterlab_nvidia_cuda_c_container -p 8888:8888 -d palmoreck/jupyterlab_nvidia_cuda_c:1.1.0_10.2\n",
    "```\n",
    "\n",
    "password para jupyterlab: `qwerty`\n",
    "\n",
    "Detener el contenedor de docker:\n",
    "\n",
    "```\n",
    "docker stop jupyterlab_nvidia_cuda_c_container\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentación de la imagen de docker `palmoreck/jupyterlab_nvidia_cuda_c:1.1.0_10.2` en [liga](https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/nvidia/cuda_c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota: si se desean ejecutar los ejemplos que se presentan a continuación, es necesario tener una tarjeta gráfica NVIDIA.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA C y generalidades de CUDA y GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consiste en extensiones al lenguaje C y en una *runtime library*. Ver [2.3.CUDA](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.3.CUDA.ipynb) para más información.\n",
    "\n",
    "### Kernel\n",
    "\n",
    "* En CUDA C se define una función que se ejecuta en el device y que se le nombra **kernel**. El *kernel* inicia con la sintaxis:\n",
    "\n",
    "```\n",
    "__global__ void mifun(int param){\n",
    "...\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "y siempre es tipo `void` (no hay `return`).\n",
    "\n",
    "* El llamado al *kernel* se realiza desde el host y con una sintaxis en la que se define el número de threads y bloques que serán utilizados para la ejecución del kernel. La sintaxis que se utiliza es con `<<< >>>` y en la primera entrada se coloca el número de bloques y en la segunda entrada el número de *threads*:\n",
    "\n",
    "\n",
    "```\n",
    "__global__ void mifun(int param){\n",
    "...\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int par;\n",
    "    mifun<<<N,5>>> (par); //N bloques de 5 threads\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Programa de hello world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello_world.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "}\n",
    "int main(void){\n",
    "    func<<<1,1>>>(); //1 bloque de 1 thread\n",
    "    printf(\"Hello world!\\n\");\n",
    "return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall hello_world.cu -o hello_world.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./hello_world.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* La función `main` se ejecuta en la CPU.\n",
    "\n",
    "* La función `func` es un *kernel* y es ejecutada por *threads* en el *device* (GPU), también llamados **CUDA threads**. Obsérvese que la función `func` inicia con `__global__` para diferenciarla de `main`. En este caso el *thread* que fue lanzado no realiza ninguna acción pues el cuerpo del kernel está vacío.\n",
    "\n",
    "* El *kernel* sólo puede tener un `return` tipo *void*: `__global__ void func` por lo que el *kernel* debe regresar sus resultados a través de sus argumentos.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Programa de hello world 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello_world_2.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_2.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    printf(\"Hello world del bloque %d del thread %d!\\n\", blockIdx.x, threadIdx.x);\n",
    "}\n",
    "int main(void){\n",
    "    func<<<2,3>>>(); //2 bloques de 3 threads cada uno\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Hola del cpu thread\\n\");\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall hello_world_2.cu -o hello_world_2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world del bloque 0 del thread 0!\n",
      "Hello world del bloque 0 del thread 1!\n",
      "Hello world del bloque 0 del thread 2!\n",
      "Hello world del bloque 1 del thread 0!\n",
      "Hello world del bloque 1 del thread 1!\n",
      "Hello world del bloque 1 del thread 2!\n",
      "Hola del cpu thread\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./hello_world_2.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* La extensión del archivo debe ser `.cu` aunque esto puede modificarse al compilar con `nvcc`: \n",
    "\n",
    "`$nvcc -x cu hello_world.c -o hello_world.out`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El llamado a la ejecución del kernel se realizó en el *host* y se lanzaron $2$ bloques (primera posición), cada uno con $3$ *threads*.\n",
    "\n",
    "* Se utiliza la función [cudaDeviceSynchronize](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d) para que el *cpu-thread* espere la finalización de la ejecución del kernel.\n",
    "\n",
    "* Los *CUDA threads* son divididos en bloques, **CUDA blocks** y todos los bloques se encuentran en un **grid**. En el lanzamiento del *kernel*  se debe especificar al hardware cuántos bloques tendrá nuestro *grid* y cuántos *threads* estarán en cada bloque. Las variables `blockIdx` y `threadIdx` hacen referencia a los **id**'s que tienen los bloques y los threads. El *id* del bloque dentro del *grid* y el *id* del thread dentro del bloque. La parte `.x` de `blockIdx.x` y `threadIdx.x` refiere a la **primera coordenada** del bloque en el *grid* y del *thread* en en el bloque. \n",
    "\n",
    "* La elección del número de bloques en un grid o el número de *threads* en un bloque no corresponde a alguna disposición del hardware, esto es, si se lanza un kernel con `<<< 1, 3 >>>` no implica que la GPU tenga en su hardware un bloque o 3 *threads*.\n",
    "\n",
    "* En una GPU podemos definir el *grid* de bloques y el bloque de *threads* utilizando el tipo de dato `dim3` el cual también es parte de CUDA C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello_world_3.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_3.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    printf(\"Hello world del bloque %d del thread %d!\\n\", blockIdx.x, threadIdx.x);\n",
    "}\n",
    "int main(void){\n",
    "    dim3 dimGrid(2,1,1); //2 bloques en el grid\n",
    "    dim3 dimBlock(3,1,1); //3 threads por bloque\n",
    "    func<<<dimGrid,dimBlock>>>(); \n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Hola del cpu thread\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall hello_world_3.cu -o hello_world_3.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world del bloque 1 del thread 0!\n",
      "Hello world del bloque 1 del thread 1!\n",
      "Hello world del bloque 1 del thread 2!\n",
      "Hello world del bloque 0 del thread 0!\n",
      "Hello world del bloque 0 del thread 1!\n",
      "Hello world del bloque 0 del thread 2!\n",
      "Hola del cpu thread\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./hello_world_3.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** obsérvese que puede definirse un grid de tres dimensiones y también un bloque de tres dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting thread_idxs.cu\n"
     ]
    }
   ],
   "source": [
    "%%file thread_idxs.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    if(threadIdx.x==0 && threadIdx.y==0 && threadIdx.z==0){\n",
    "        printf(\"blockIdx.x:%d\\n\",blockIdx.x);\n",
    "    }\n",
    "    printf(\"thread idx.x:%d\\n\",threadIdx.x);\n",
    "    printf(\"thread idx.y:%d\\n\",threadIdx.y);\n",
    "    printf(\"thread idx.z:%d\\n\",threadIdx.z);\n",
    "}\n",
    "int main(void){\n",
    "    dim3 dimGrid(1,1,1); //1 bloque en el grid\n",
    "    dim3 dimBlock(1,3,1); //3 threads por bloque\n",
    "    func<<<dimGrid,dimBlock>>>(); \n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall thread_idxs.cu -o thread_idxs.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockIdx.x:0\n",
      "thread idx.x:0\n",
      "thread idx.x:0\n",
      "thread idx.x:0\n",
      "thread idx.y:0\n",
      "thread idx.y:1\n",
      "thread idx.y:2\n",
      "thread idx.z:0\n",
      "thread idx.z:0\n",
      "thread idx.z:0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./thread_idxs.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting block_idxs.cu\n"
     ]
    }
   ],
   "source": [
    "%%file block_idxs.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    printf(\"blockIdx.x:%d\\n\",blockIdx.x);\n",
    "    printf(\"blockIdx.y:%d\\n\",blockIdx.y);\n",
    "    printf(\"blockIdx.z:%d\\n\",blockIdx.z);\n",
    "\n",
    "}\n",
    "int main(void){\n",
    "    dim3 dimGrid(1,2,2); //4 bloques en el grid\n",
    "    dim3 dimBlock(1,1,1); //1 thread por bloque\n",
    "    func<<<dimGrid,dimBlock>>>(); \n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall block_idxs.cu -o block_idxs.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockIdx.x:0\n",
      "blockIdx.x:0\n",
      "blockIdx.x:0\n",
      "blockIdx.x:0\n",
      "blockIdx.y:0\n",
      "blockIdx.y:1\n",
      "blockIdx.y:0\n",
      "blockIdx.y:1\n",
      "blockIdx.z:0\n",
      "blockIdx.z:1\n",
      "blockIdx.z:1\n",
      "blockIdx.z:0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./block_idxs.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting block_dims.cu\n"
     ]
    }
   ],
   "source": [
    "%%file block_dims.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    if(threadIdx.x==0 && threadIdx.y==0 && threadIdx.z==0 && blockIdx.z==1){\n",
    "    printf(\"blockDim.x:%d\\n\",blockDim.x);\n",
    "    printf(\"blockDim.y:%d\\n\",blockDim.y);\n",
    "    printf(\"blockDim.z:%d\\n\",blockDim.z);\n",
    "    }\n",
    "\n",
    "}\n",
    "int main(void){\n",
    "    dim3 dimGrid(2,2,2); //8 bloques en el grid\n",
    "    dim3 dimBlock(3,1,2); //6 threads por bloque\n",
    "    func<<<dimGrid,dimBlock>>>(); \n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall block_dims.cu -o block_dims.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockDim.x:3\n",
      "blockDim.x:3\n",
      "blockDim.x:3\n",
      "blockDim.x:3\n",
      "blockDim.y:1\n",
      "blockDim.y:1\n",
      "blockDim.y:1\n",
      "blockDim.y:1\n",
      "blockDim.z:2\n",
      "blockDim.z:2\n",
      "blockDim.z:2\n",
      "blockDim.z:2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./block_dims.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Programa de suma vectorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N bloques de 1 thread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma_vectorial.cu\n"
     ]
    }
   ],
   "source": [
    "%%file suma_vectorial.cu\n",
    "#include<stdio.h>\n",
    "#define N 10\n",
    "__global__ void suma_vect(int *a, int *b, int *c){\n",
    "    int block_id_x = blockIdx.x;\n",
    "    if(block_id_x<N) //aquí se asume que el valor de N \n",
    "                     //es menor al número máximo de bloques que se pueden lanzar\n",
    "                     //si fuese mayor, hay que hacer un ajuste\n",
    "        c[block_id_x] = a[block_id_x]+b[block_id_x];\n",
    "}\n",
    "int main(void){\n",
    "    int a[N], b[N],c[N];\n",
    "    int *device_a, *device_b, *device_c;\n",
    "    int i;\n",
    "    dim3 dimGrid(N,1,1); //N bloques en el grid\n",
    "    dim3 dimBlock(1,1,1); //1 threads por bloque \n",
    "    //alojando en device\n",
    "    cudaMalloc((void **)&device_a, sizeof(int)*N); \n",
    "    cudaMalloc((void **)&device_b, sizeof(int)*N);\n",
    "    cudaMalloc((void **)&device_c, sizeof(int)*N);\n",
    "    //llenando los arreglos con datos dummy:\n",
    "    for(i=0;i<N;i++){\n",
    "        a[i]=i;\n",
    "        b[i]=i*i;\n",
    "    }\n",
    "    //copiamos arreglos a, b a la GPU\n",
    "    cudaMemcpy(device_a,a,N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(device_b,b,N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "    //mandamos a llamar a suma_vect:\n",
    "    suma_vect<<<dimGrid,dimBlock>>>(device_a,device_b,device_c); //N bloques de 1 thread\n",
    "    cudaDeviceSynchronize();\n",
    "    //copia del resultado al arreglo c:\n",
    "    cudaMemcpy(c,device_c,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
    "    for(i=0;i<N;i++)\n",
    "        printf(\"%d+%d = %d\\n\",a[i],b[i],c[i]);\n",
    "    cudaFree(device_a);\n",
    "    cudaFree(device_b);\n",
    "    cudaFree(device_c);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall suma_vectorial.cu -o suma_vectorial.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0+0 = 0\n",
      "1+1 = 2\n",
      "2+4 = 6\n",
      "3+9 = 12\n",
      "4+16 = 20\n",
      "5+25 = 30\n",
      "6+36 = 42\n",
      "7+49 = 56\n",
      "8+64 = 72\n",
      "9+81 = 90\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./suma_vectorial.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obsérvese que se están utilizando apuntadores en la línea:\n",
    "\n",
    "```\n",
    "    int *device_a, *device_b, *device_c;\n",
    "```\n",
    "\n",
    "pero estos apuntadores no apuntan a una dirección de memoria en el *device* pues aunque NVIDIA añadió el *feature* de [Unified Memory](https://devblogs.nvidia.com/unified-memory-cuda-beginners/) (un espacio de memoria accesible para la CPU y la GPU) aquí no se está usando tal *feature*. Más bien se están utilizando los apuntadores anteriores para apuntar a un [struct](https://en.wikipedia.org/wiki/Struct_(C_programming_language)) de C en el que uno de sus tipos de datos es una dirección de memoria en la GPU.\n",
    "\n",
    "* Para alojar memoria en la GPU se utiliza el llamado a [cudaMalloc](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356) y para transferir datos del *host* al *device* o viceversa se llama a lafunción [cudaMemcpy](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8) con respectivos parámetros como `cudaMemcpyHostToDevice` o `cudaMemcpyDeviceToHost`. Obsérvese el uso de `(void **)` por la definición de la función `cudaMalloc`.\n",
    "\n",
    "* Para desalojar memoria en la GPU se utiliza el llamado a [cudaFree](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al instalar el *CUDA toolkit* o con el contenedor de docker (detallado al inicio de la nota) se cuenta con la línea de comando [nvprof](https://docs.nvidia.com/cuda/profiler-users-guide/index.html) para perfilamiento (aunque en la documentación se menciona que será reemplazada tal línea de comando por [NVIDIA Nsight Compute](https://developer.nvidia.com/nsight-compute) y [NVIDIA Nsight Systems](https://developer.nvidia.com/nsight-systems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0+0 = 0\n",
      "1+1 = 2\n",
      "2+4 = 6\n",
      "3+9 = 12\n",
      "4+16 = 20\n",
      "5+25 = 30\n",
      "6+36 = 42\n",
      "7+49 = 56\n",
      "8+64 = 72\n",
      "9+81 = 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==216== NVPROF is profiling process 216, command: ./suma_vectorial.out\n",
      "==216== Profiling application: ./suma_vectorial.out\n",
      "==216== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:    39.91  2.78e-06         1  2.78e-06  2.78e-06  2.78e-06  suma_vect(int*, int*, int*)\n",
      "                    35.32  2.46e-06         2  1.23e-06  9.28e-07  1.54e-06  [CUDA memcpy HtoD]\n",
      "                    24.77  1.73e-06         1  1.73e-06  1.73e-06  1.73e-06  [CUDA memcpy DtoH]\n",
      "      API calls:    99.37  0.289724         3  0.096575  6.04e-06  0.289709  cudaMalloc\n",
      "                     0.19  5.64e-04       194  2.91e-06  1.66e-07  1.16e-04  cuDeviceGetAttribute\n",
      "                     0.16  4.71e-04         2  2.35e-04  2.17e-04  2.54e-04  cuDeviceTotalMem\n",
      "                     0.11  3.17e-04         1  3.17e-04  3.17e-04  3.17e-04  cudaLaunchKernel\n",
      "                     0.10  2.82e-04         3  9.41e-05  5.50e-06  2.66e-04  cudaFree\n",
      "                     0.05  1.31e-04         2  6.57e-05  2.08e-05  1.10e-04  cuDeviceGetName\n",
      "                     0.02  6.48e-05         3  2.16e-05  9.17e-06  3.48e-05  cudaMemcpy\n",
      "                     0.00  7.00e-06         2  3.50e-06  2.86e-06  4.14e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  6.60e-06         1  6.60e-06  6.60e-06  6.60e-06  cudaDeviceSynchronize\n",
      "                     0.00  2.05e-06         4  5.13e-07  2.02e-07  1.28e-06  cuDeviceGet\n",
      "                     0.00  1.78e-06         3  5.94e-07  3.20e-07  1.04e-06  cuDeviceGetCount\n",
      "                     0.00  6.72e-07         2  3.36e-07  3.09e-07  3.63e-07  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "nvprof --normalized-time-unit s ./suma_vectorial.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unidades en las que se reporta, s: second, ms: millisecond, us: microsecond, ns: nanosecond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 bloque de N threads**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y en lugar de lanzar $N$ bloques de $1$ thread se puede lanzar $1$ bloque con $N$ threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma_vectorial_2.cu\n"
     ]
    }
   ],
   "source": [
    "%%file suma_vectorial_2.cu\n",
    "#include<stdio.h>\n",
    "#define N 10\n",
    "__global__ void suma_vect(int *a, int *b, int *c){\n",
    "    int thread_id_x = threadIdx.x;\n",
    "    if(thread_id_x<N) //aquí se asume que el valor de N \n",
    "                     //es menor al número máximo de threads que se pueden lanzar\n",
    "                    //si fuese mayor, hay que hacer un ajuste\n",
    "        c[thread_id_x] = a[thread_id_x]+b[thread_id_x];\n",
    "}\n",
    "int main(void){\n",
    "    int *device_a, *device_b, *device_c;\n",
    "    int i;\n",
    "    dim3 dimGrid(1,1,1); //1 bloques en el grid\n",
    "    dim3 dimBlock(N,1,1); //N threads por bloque \n",
    "    //alojando en device con Unified Memory\n",
    "    cudaMallocManaged(&device_a, sizeof(int)*N);\n",
    "    cudaMallocManaged(&device_b, sizeof(int)*N);\n",
    "    cudaMallocManaged(&device_c, sizeof(int)*N);\n",
    "    //llenando los arreglos:\n",
    "    for(i=0;i<N;i++){\n",
    "        device_a[i]=i;\n",
    "        device_b[i]=i*i;\n",
    "    }\n",
    "    suma_vect<<<dimGrid,dimBlock>>>(device_a,device_b,device_c); //1 bloque con N threads\n",
    "    cudaDeviceSynchronize();\n",
    "    for(i=0;i<N;i++)\n",
    "        printf(\"%d+%d = %d\\n\",device_a[i],device_b[i],device_c[i]);\n",
    "    cudaFree(device_a);\n",
    "    cudaFree(device_b);\n",
    "    cudaFree(device_c);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall suma_vectorial_2.cu -o suma_vectorial_2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0+0 = 0\n",
      "1+1 = 2\n",
      "2+4 = 6\n",
      "3+9 = 12\n",
      "4+16 = 20\n",
      "5+25 = 30\n",
      "6+36 = 42\n",
      "7+49 = 56\n",
      "8+64 = 72\n",
      "9+81 = 90\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./suma_vectorial_2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0+0 = 0\n",
      "1+1 = 2\n",
      "2+4 = 6\n",
      "3+9 = 12\n",
      "4+16 = 20\n",
      "5+25 = 30\n",
      "6+36 = 42\n",
      "7+49 = 56\n",
      "8+64 = 72\n",
      "9+81 = 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==266== NVPROF is profiling process 266, command: ./suma_vectorial_2.out\n",
      "==266== Profiling application: ./suma_vectorial_2.out\n",
      "==266== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:   100.00  3.26e-06         1  3.26e-06  3.26e-06  3.26e-06  suma_vect(int*, int*, int*)\n",
      "      API calls:    98.79  0.163188         3  0.054396  1.13e-05  0.163138  cudaMallocManaged\n",
      "                     0.43  7.13e-04       194  3.68e-06  1.63e-07  1.28e-04  cuDeviceGetAttribute\n",
      "                     0.30  4.98e-04         1  4.98e-04  4.98e-04  4.98e-04  cudaLaunchKernel\n",
      "                     0.29  4.72e-04         2  2.36e-04  2.17e-04  2.55e-04  cuDeviceTotalMem\n",
      "                     0.09  1.44e-04         3  4.81e-05  1.94e-05  8.86e-05  cudaFree\n",
      "                     0.08  1.30e-04         2  6.50e-05  2.30e-05  1.07e-04  cuDeviceGetName\n",
      "                     0.01  1.99e-05         1  1.99e-05  1.99e-05  1.99e-05  cudaDeviceSynchronize\n",
      "                     0.01  1.32e-05         4  3.30e-06  2.02e-07  1.21e-05  cuDeviceGet\n",
      "                     0.00  4.77e-06         2  2.38e-06  1.73e-06  3.05e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  1.54e-06         3  5.15e-07  2.12e-07  8.85e-07  cuDeviceGetCount\n",
      "                     0.00  7.91e-07         2  3.95e-07  3.11e-07  4.80e-07  cuDeviceGetUuid\n",
      "\n",
      "==266== Unified Memory profiling result:\n",
      "Device \"Tesla K20Xm (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "       1  8.0000KB  8.0000KB  8.0000KB  8.000000KB  3.1680e-06s  Host To Device\n",
      "       5  25.600KB  4.0000KB  60.000KB  128.0000KB  2.3168e-05s  Device To Host\n",
      "Total CPU Page faults: 2\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "nvprof --normalized-time-unit s ./suma_vectorial_2.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** obsérvese que el programa anterior utiliza la *Unified Memory* con la función [cudaMallocManaged](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente programa basado en [liga](https://devblogs.nvidia.com/how-query-device-properties-and-handle-errors-cuda-cc/) y [cudaDeviceProp Struct Reference](https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/22520209/programmatically-retrieve-maximum-number-of-blocks-per-multiprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing device_properties.cu\n"
     ]
    }
   ],
   "source": [
    "%%file device_properties.cu\n",
    "\n",
    "#include<stdio.h>\n",
    "\n",
    "int main(void){\n",
    "    cudaDeviceProp properties;\n",
    "    int count;\n",
    "    int i;\n",
    "    cudaGetDeviceCount(&count);\n",
    "    for(i=0;i<count;i++){\n",
    "        printf(\"----------------------\\n\");\n",
    "        cudaGetDeviceProperties(&properties, i);\n",
    "        printf(\"----device %d ----\\n\",i); \n",
    "        printf(\"Device Name: %s\\n\", properties.name);\n",
    "        printf(\"Compute capability: %d.%d\\n\", properties.major, properties.minor);\n",
    "        printf(\"Clock rate: %d\\n\", properties.clockRate);\n",
    "        printf(\"Unified memory: %d\\n\", properties.unifiedAddressing);\n",
    "        printf(\" ---Memory Information for device %d (results on bytes)---\\n\", i);\n",
    "        printf(\"Total global mem: %ld\\n\", properties.totalGlobalMem); \n",
    "        printf(\"Total constant Mem: %ld\\n\", properties.totalConstMem);\n",
    "        printf(\"Shared memory per thread block: %ld\\n\", properties.sharedMemPerBlock);\n",
    "        printf(\"Shared memory per SM: %ld\\n\",properties.sharedMemPerMultiprocessor );\n",
    "        printf(\" ---MP Information for device %d ---\\n\", i);\n",
    "        printf(\"SM count: %d\\n\", properties.multiProcessorCount);\n",
    "        printf(\"Threads in warp: %d\\n\", properties.warpSize);\n",
    "        printf(\"Max threads per SM: %d\\n\", properties.maxThreadsPerMultiProcessor);\n",
    "        printf(\"Max warps per SM: %d\\n\",properties.maxThreadsPerMultiProcessor/properties.warpSize);\n",
    "        printf(\"Max threads per block: %d\\n\", properties.maxThreadsPerBlock);\n",
    "        printf(\"Max thread dimensions: (%d, %d, %d)\\n\", properties.maxThreadsDim[0], properties.maxThreadsDim[1], properties.maxThreadsDim[2]);\n",
    "        printf(\"Max grid dimensions: (%d, %d, %d)\\n\", properties.maxGridSize[0], properties.maxGridSize[1], properties.maxGridSize[2]); \n",
    "    }\n",
    "    return 0;\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "nvcc --compiler-options -Wall device_properties.cu -o device_properties.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "----device 0 ----\n",
      "Device Name: Tesla K20Xm\n",
      "Compute capability: 3.5\n",
      "Clock rate: 732000\n",
      "Unified memory: 1\n",
      " ---Memory Information for device 0 (results on bytes)---\n",
      "Total global mem: 5977800704\n",
      "Total constant Mem: 65536\n",
      "Shared memory per thread block: 49152\n",
      "Shared memory per SM: 49152\n",
      " ---MP Information for device 0 ---\n",
      "SM count: 14\n",
      "Threads in warp: 32\n",
      "Max threads per SM: 2048\n",
      "Max warps per SM: 64\n",
      "Max threads per block: 1024\n",
      "Max thread dimensions: (1024, 1024, 64)\n",
      "Max grid dimensions: (2147483647, 65535, 65535)\n",
      "----------------------\n",
      "----device 1 ----\n",
      "Device Name: Tesla K20Xm\n",
      "Compute capability: 3.5\n",
      "Clock rate: 732000\n",
      "Unified memory: 1\n",
      " ---Memory Information for device 1 (results on bytes)---\n",
      "Total global mem: 5977800704\n",
      "Total constant Mem: 65536\n",
      "Shared memory per thread block: 49152\n",
      "Shared memory per SM: 49152\n",
      " ---MP Information for device 1 ---\n",
      "SM count: 14\n",
      "Threads in warp: 32\n",
      "Max threads per SM: 2048\n",
      "Max warps per SM: 64\n",
      "Max threads per block: 1024\n",
      "Max thread dimensions: (1024, 1024, 64)\n",
      "Max grid dimensions: (2147483647, 65535, 65535)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "./device_properties.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regla compuesta del rectángulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$n=10^3$** subintervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Rcf.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum ) {\n",
    "    double x=0.0;\n",
    "    if(threadIdx.x<=n-1){\n",
    "        x=a+(threadIdx.x+1/2.0)*h_hat;\n",
    "        data[threadIdx.x]=std::exp(-std::pow(x,2));\n",
    "    }\n",
    "    if(threadIdx.x==0){\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n=1e3; //número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin=clock();\n",
    "    Rcf<<<1,n>>>(d_data, a,h_hat,n,d_suma); //1 bloque de n threads\n",
    "    cudaDeviceSynchronize();\n",
    "    end=clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf.cu -o Rcf.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241634690490e-01\n",
      "Error relativo de la solución: 4.104931878976858e-08\n",
      "Tiempo de cálculo en la gpu 0.00035\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241634690490e-01\n",
      "Error relativo de la solución: 4.104931878976858e-08\n",
      "Tiempo de cálculo en la gpu 0.00043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1343== NVPROF is profiling process 1343, command: ./Rcf.out\n",
      "==1343== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version \n",
      "==1343== Profiling application: ./Rcf.out\n",
      "==1343== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:    97.33  8.27e-05         1  8.27e-05  8.27e-05  8.27e-05  Rcf(double*, double, double, int, double*)\n",
      "                     2.67  2.27e-06         1  2.27e-06  2.27e-06  2.27e-06  [CUDA memcpy DtoH]\n",
      "      API calls:    98.82  0.146833         2  0.073417  8.00e-06  0.146825  cudaMalloc\n",
      "                     0.37  5.44e-04       194  2.81e-06  1.78e-07  9.54e-05  cuDeviceGetAttribute\n",
      "                     0.32  4.78e-04         2  2.39e-04  2.37e-04  2.40e-04  cuDeviceTotalMem\n",
      "                     0.23  3.36e-04         1  3.36e-04  3.36e-04  3.36e-04  cudaLaunchKernel\n",
      "                     0.09  1.33e-04         2  6.66e-05  1.15e-05  1.22e-04  cudaFree\n",
      "                     0.09  1.30e-04         2  6.50e-05  2.24e-05  1.08e-04  cuDeviceGetName\n",
      "                     0.06  8.59e-05         1  8.59e-05  8.59e-05  8.59e-05  cudaDeviceSynchronize\n",
      "                     0.02  2.97e-05         1  2.97e-05  2.97e-05  2.97e-05  cudaMemcpy\n",
      "                     0.00  5.25e-06         2  2.63e-06  1.85e-06  3.40e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  1.68e-06         4  4.20e-07  2.28e-07  7.27e-07  cuDeviceGet\n",
      "                     0.00  1.50e-06         3  5.00e-07  2.03e-07  7.54e-07  cuDeviceGetCount\n",
      "                     0.00  7.61e-07         2  3.80e-07  3.44e-07  4.17e-07  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof --normalized-time-unit s ./Rcf.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n=1025$ subintervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Rcf2.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf2.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum ) {\n",
    "    double x=0.0;\n",
    "    if(threadIdx.x<=n-1){\n",
    "        x=a+(threadIdx.x+1/2.0)*h_hat;\n",
    "        data[threadIdx.x]=std::exp(-std::pow(x,2));\n",
    "    }\n",
    "    if(threadIdx.x==0){\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n=1025; //número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin=clock();\n",
    "    Rcf<<<1,n>>>(d_data, a,h_hat,n,d_suma); //1 bloque de n threads\n",
    "    cudaDeviceSynchronize();\n",
    "    end=clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf2.cu -o Rcf2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 0.000000000000000e+00\n",
      "Error relativo de la solución: 1.000000000000000e+00\n",
      "Tiempo de cálculo en la gpu 0.00001\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf2.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese error relativo de $100\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo lo arreglamos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Rcf3.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf3.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum) {\n",
    "    double x=0.0;\n",
    "    int stride=0;\n",
    "    if(threadIdx.x<=n-1){\n",
    "        x=a+(threadIdx.x+1/2.0)*h_hat;\n",
    "        data[threadIdx.x]=std::exp(-std::pow(x,2));\n",
    "    }\n",
    "    if(threadIdx.x==0){\n",
    "        stride=blockDim.x;\n",
    "        x=a+(threadIdx.x+stride+1/2.0)*h_hat;\n",
    "        data[threadIdx.x+stride]=std::exp(-std::pow(x,2));\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n_threads_per_block=1024; \n",
    "    int n_bloques=2;\n",
    "    int n=1025;//número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin=clock();\n",
    "    Rcf<<<n_bloques,n_threads_per_block>>>(d_data, a,h_hat,n,d_suma); \n",
    "    cudaDeviceSynchronize();\n",
    "    end=clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf3.cu -o Rcf3.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241619918411e-01\n",
      "Error relativo de la solución: 3.907133247860604e-08\n",
      "Tiempo de cálculo en la gpu 0.00034\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf3.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Rcf4.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf4.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum) {\n",
    "    double x=0.0;\n",
    "    int stride=0;\n",
    "    int i;\n",
    "    stride=blockDim.x;\n",
    "    for(i=threadIdx.x;i<=n-1;i+=stride){\n",
    "        if(i<=n-1){\n",
    "            x=a+(i+1/2.0)*h_hat;\n",
    "            data[i]=std::exp(-std::pow(x,2));\n",
    "        }\n",
    "    }\n",
    "    if(threadIdx.x==0){\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n_threads_per_block=1024; \n",
    "    int n_bloques=2;\n",
    "    int n=n_threads_per_block*n_bloques;//número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin=clock();\n",
    "    Rcf<<<n_bloques,n_threads_per_block>>>(d_data, a,h_hat,n,d_suma); \n",
    "    cudaDeviceSynchronize();\n",
    "    end=clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf4.cu -o Rcf4.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241401215338e-01\n",
      "Error relativo de la solución: 9.786918140590463e-09\n",
      "Tiempo de cálculo en la gpu 0.00046\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf4.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Más nodos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Rcf5.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf5.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum ) {\n",
    "    double x=0.0;\n",
    "    int idx;\n",
    "    idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if(idx<=n-1){\n",
    "        x=a+(idx+1/2.0)*h_hat;\n",
    "        data[idx]=std::exp(-std::pow(x,2));\n",
    "    }\n",
    "    if(idx==0){\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n_threads_per_block=1024; \n",
    "    int n_bloques=1000;\n",
    "    double objetivo=0.7468241328124271;\n",
    "    int n=n_bloques*n_threads_per_block;//número de subintervalos\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin = clock();\n",
    "    Rcf<<<n_bloques,n_threads_per_block>>>(d_data, a,h_hat,n,d_suma); \n",
    "    cudaDeviceSynchronize();\n",
    "    end = clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf5.cu -o Rcf5.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241328124601e-01\n",
      "Error relativo de la solución: 4.415179207880368e-14\n",
      "Tiempo de cálculo en la gpu 0.11359\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf5.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241328124601e-01\n",
      "Error relativo de la solución: 4.415179207880368e-14\n",
      "Tiempo de cálculo en la gpu 0.11382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==2537== NVPROF is profiling process 2537, command: ./Rcf5.out\n",
      "==2537== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version \n",
      "==2537== Profiling application: ./Rcf5.out\n",
      "==2537== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:   100.00  0.113309         1  0.113309  0.113309  0.113309  Rcf(double*, double, double, int, double*)\n",
      "                     0.00  2.37e-06         1  2.37e-06  2.37e-06  2.37e-06  [CUDA memcpy DtoH]\n",
      "      API calls:    56.61  0.151360         2  0.075680  1.41e-04  0.151218  cudaMalloc\n",
      "                    42.38  0.113325         1  0.113325  0.113325  0.113325  cudaDeviceSynchronize\n",
      "                     0.42  1.13e-03         2  5.63e-04  2.77e-04  8.50e-04  cudaFree\n",
      "                     0.20  5.38e-04       194  2.77e-06  1.85e-07  1.06e-04  cuDeviceGetAttribute\n",
      "                     0.19  5.06e-04         2  2.53e-04  2.49e-04  2.57e-04  cuDeviceTotalMem\n",
      "                     0.13  3.43e-04         1  3.43e-04  3.43e-04  3.43e-04  cudaLaunchKernel\n",
      "                     0.04  9.90e-05         2  4.95e-05  2.02e-05  7.88e-05  cuDeviceGetName\n",
      "                     0.02  6.17e-05         1  6.17e-05  6.17e-05  6.17e-05  cudaMemcpy\n",
      "                     0.00  9.22e-06         2  4.61e-06  4.26e-06  4.96e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  1.82e-06         3  6.06e-07  2.91e-07  1.09e-06  cuDeviceGetCount\n",
      "                     0.00  1.77e-06         4  4.42e-07  2.26e-07  8.65e-07  cuDeviceGet\n",
      "                     0.00  7.80e-07         2  3.90e-07  3.06e-07  4.74e-07  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof --normalized-time-unit s ./Rcf5.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**\n",
    "\n",
    "1. N. Matloff, Parallel Computing for Data Science. With Examples in R, C++ and CUDA, 2014.\n",
    "\n",
    "2. [CUDA](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA)\n",
    "\n",
    "3. [2.3.CUDA](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.3.CUDA.ipynb)\n",
    "\n",
    "Para más sobre *Unified Memory* revisar:\n",
    "\n",
    "* [Even easier introduction to cuda](https://devblogs.nvidia.com/even-easier-introduction-cuda/)\n",
    "\n",
    "* [Unified memory cuda beginners](https://devblogs.nvidia.com/unified-memory-cuda-beginners/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
