{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker run -dit --name nvidia-10.1-container --gpus all nvidia/cuda:10.1-devel-ubuntu18.04 bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvcc --compiler-options -Wall Rcf.cu -o Rcf.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum ) {\n",
    "double x=0.0;\n",
    "\n",
    "if(threadIdx.x<=n-1){\n",
    "x=a+(threadIdx.x+1/2.0)*h_hat;\n",
    "data[threadIdx.x]=std::exp(-std::pow(x,2));\n",
    "}\n",
    "    *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "  //*sum = thrust::reduce(thrust::seq, data , data + n, (double)0, thrust::plus<double>());\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n=1e3; //número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    Rcf<<<1,n>>>(d_data, a,h_hat,n,d_suma); //1 bloque de n threads\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integral de 0.000000 a 1.000000 = 7.468241634690490e-01\n",
    "\n",
    "Error relativo de la solución: 4.104931878976858e-08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.nvidia.com/cuda/cutensor/api/cutensor.html#reduction-operations\n",
    "https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuTENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://devblogs.nvidia.com/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/14760893/using-cuda-math-functions-in-a-global-function-nsight-eclipse-edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://thrust.github.io/doc/group__reductions_ga6ac0fe1561f58692e85112bd1145ddff.html\n",
    "\n",
    "https://stackoverflow.com/questions/20324277/reduction-in-cuda\n",
    "https://github.com/thrust/thrust/issues/949\n",
    "https://stackoverflow.com/questions/5510715/thrust-inside-user-written-kernels\n",
    "\n",
    "http://thrust.github.io/\n",
    "\n",
    "https://devtalk.nvidia.com/default/topic/1048650/cuda-programming-and-performance/question-about-thrust-library-with-kernel/\n",
    "\n",
    "https://docs.nvidia.com/cuda/thrust/index.html\n",
    "\n",
    "\n",
    "https://github.com/thrust/thrust/wiki/Quick-Start-Guide\n",
    "\n",
    "https://github.com/thrust/thrust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/moderngpu/moderngpu/wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://nvlabs.github.io/cub/#sec6\n",
    "\n",
    "https://nvlabs.github.io/cub/structcub_1_1_device_reduce.html\n",
    "http://nvlabs.github.io/cub/index.html\n",
    "https://github.com/NVlabs/cub\n",
    "\n",
    "https://stackoverflow.com/questions/42525713/cuda-how-to-sum-all-elements-of-an-array-into-one-number-within-the-gpu\n",
    "http://nvlabs.github.io/cub/classcub_1_1_block_reduce.html\n",
    "\n",
    "https://nvlabs.github.io/cub/structcub_1_1_device_reduce.html#aa4adabeb841b852a7a5ecf4f99a2daeb\n",
    "\n",
    "https://devtalk.nvidia.com/default/topic/1062732/gpu-accelerated-libraries/cub-reduction-with-complex-number-and-multiplication/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker run -dit --name nvidia-10.1-container --gpus all nvidia/cuda:10.1-devel-ubuntu18.04 bash\n",
    "\n",
    "\n",
    "sudo docker exec -it nvidia-10.1-container bash\n",
    "\n",
    "apt-get install wget unzip nano\n",
    "\n",
    "wget https://github.com/NVlabs/cub/archive/1.8.0.zip\n",
    "\n",
    "unzip 1.8.0.zip\n",
    "\n",
    "\n",
    "nvcc --compiler-options -Wall suma.cu -o suma.out -I cub-1.8.0/cub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvcc --compiler-options -Wall suma.cu -o suma.out -I cub-1.8.0/cub/\n",
    "\n",
    "\n",
    "#include<stdio.h>\n",
    "#include \"cub-1.8.0/cub/cub.cuh\"\n",
    "void suma(int a, int b, int *c){\n",
    "  void *d_temp_storage = NULL;\n",
    "  size_t temp_storage_bytes = 0;\n",
    "  int *d_in;\n",
    "  int num_items=2;\n",
    "  int i;\n",
    "\n",
    "cudaMallocManaged((void **)&d_in,sizeof(int)*num_items);\n",
    "for(i=0;i<num_items;i++)\n",
    " d_in[i] = i+5;\n",
    "\n",
    "cub::DeviceReduce::Sum(d_temp_storage, temp_storage_bytes, d_in, c, num_items);\n",
    "cudaMalloc(&d_temp_storage, temp_storage_bytes);\n",
    "cub::DeviceReduce::Sum(d_temp_storage, temp_storage_bytes, d_in, c, num_items);\n",
    "cudaFree(&d_temp_storage);\n",
    "cudaFree(d_in);\n",
    "\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "\tint c=0;\n",
    "\tint *device_c;\n",
    "\tcudaMalloc((void **)&device_c,sizeof(int));\n",
    "        cudaSetDeviceFlags(cudaDeviceScheduleBlockingSync);\n",
    "\tsuma(2,7,device_c);\n",
    "\tcudaMemcpy(&c, device_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\tprintf(\"2+7 = %d\\n\", c);\n",
    "\tcudaFree(device_c);\n",
    "\treturn 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/25353749/getting-cub-devicescan-to-work-when-called-from-a-kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Maybe see:\n",
    "\n",
    "https://stackoverflow.com/questions/25353749/getting-cub-devicescan-to-work-when-called-from-a-kernel\n",
    "\n",
    "#include<stdio.h>\n",
    "#include \"cub-1.8.0/cub/cub.cuh\"\n",
    "\n",
    "\n",
    "__global__ void suma(int a, int b, int *c){\n",
    "  void *d_temp_storage = NULL;\n",
    "  size_t temp_storage_bytes = 0;\n",
    "  int *d_in;\n",
    "  int num_items=2;\n",
    "  int i;\n",
    "\n",
    "cudaMallocManaged((void **)&d_in,sizeof(int)*num_items);\n",
    "for(i=0;i<num_items;i++)\n",
    " d_in[i] = i+1;\n",
    "\n",
    "cub::DeviceReduce::Sum(d_temp_storage, temp_storage_bytes, d_in, c, num_items);\n",
    "cudaMalloc(&d_temp_storage, temp_storage_bytes);\n",
    "cub::DeviceReduce::Sum(d_temp_storage, temp_storage_bytes, d_in, c, num_items);\n",
    "cudaFree(&d_temp_storage);\n",
    "cudaFree(d_in);\n",
    "\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "\tint c=0;\n",
    "\tint *device_c;\n",
    "\tcudaMalloc((void **)&device_c,sizeof(int));\n",
    "        cudaSetDeviceFlags(cudaDeviceScheduleBlockingSync);\n",
    "\tsuma<<<1,1>>>(2,7,device_c);\n",
    "\tcudaMemcpy(&c, device_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\tprintf(\"2+7 = %d\\n\", c);\n",
    "\tcudaFree(device_c);\n",
    "\treturn 0;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
