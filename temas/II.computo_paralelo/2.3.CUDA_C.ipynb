{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga](https://www.dropbox.com/s/yjijtfuky3s5dfz/2.5.Compute_Unified_Device_Architecture.pdf?dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notas para contenedor de docker:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comando de docker para ejecución de la nota de forma local:\n",
    "\n",
    "nota: cambiar `<ruta a mi directorio>` por la ruta de directorio que se desea mapear a `/datos` dentro del contenedor de docker.\n",
    "\n",
    "```\n",
    "docker run --gpus all --rm -v $(pwd):/datos --name jupyterlab_nvidia_cuda_c_container -p 8888:8888 -d palmoreck/jupyterlab_nvidia_cuda_c:1.1.0_10.2\n",
    "```\n",
    "\n",
    "password para jupyterlab: `qwerty`\n",
    "\n",
    "Detener el contenedor de docker:\n",
    "\n",
    "```\n",
    "docker stop jupyterlab_nvidia_cuda_c_container\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentación de la imagen de docker `palmoreck/jupyterlab_nvidia_cuda_c:1.1.0_10.2` en [liga](https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/nvidia/cuda_c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota: si se desean ejecutar los ejemplos que se presentan a continuación, es necesario tener una tarjeta gráfica NVIDIA.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA C y generalidades de CUDA y GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consiste en extensiones al lenguaje C y en una *runtime library*. Ver [2.3.CUDA](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.3.CUDA.ipynb) para más información.\n",
    "\n",
    "### Kernel\n",
    "\n",
    "* En CUDA C se define una función que se ejecuta en el **device\\*** y que se le nombra **kernel**. El *kernel* inicia con la sintaxis:\n",
    "\n",
    "```\n",
    "__global__ void mifun(int param){\n",
    "...\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "y siempre es tipo `void` (no hay `return`).\n",
    "\n",
    "* El llamado al *kernel* se realiza desde el **host\\*** y con una sintaxis en la que se define el número de threads, llamados **CUDA threads** (que son distintos a los *CPU threads*), y bloques, nombrados **CUDA blocks**, que serán utilizados para la ejecución del kernel. La sintaxis que se utiliza es con `<<< >>>` y en la primera entrada se coloca el número de *CUDA blocks* y en la segunda entrada el número de *CUDA threads*:\n",
    "\n",
    "\n",
    "```\n",
    "__global__ void mifun(int param){\n",
    "...\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    int par;\n",
    "    mifun<<<N,5>>> (par); //N bloques de 5 threads\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "\\* Los nombres de *host* y *device* hacen referencia a la *CPU* y a la *GPU*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Programa de hello world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello_world.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "}\n",
    "int main(void){\n",
    "    func<<<1,1>>>(); //1 bloque de 1 thread\n",
    "    printf(\"Hello world!\\n\");\n",
    "return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall hello_world.cu -o hello_world.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./hello_world.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* La función `main` se ejecuta en la CPU.\n",
    "\n",
    "* `func` es un *kernel* y es ejecutada por los *CUDA threads* en el **device** (GPU). Obsérvese que tal función inicia con la sintaxis `__global__`. En este caso el *CUDA thread* que fue lanzado no realiza ninguna acción pues el cuerpo del kernel está vacío.\n",
    "\n",
    "* El *kernel* sólo puede tener un `return` tipo *void*: `__global__ void func` por lo que el *kernel* debe regresar sus resultados a través de sus argumentos.\n",
    " \n",
    "* La extensión del archivo debe ser `.cu` aunque esto puede modificarse al compilar con `nvcc`: \n",
    "\n",
    "`$nvcc -x cu hello_world.c -o hello_world.out`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Bloques de threads? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los *CUDA threads* son divididos los **CUDA blocks** y éstos se encuentran en un **grid**. En el lanzamiento del *kernel* se debe especificar al hardware cuántos *CUDA blocks* tendrá nuestro *grid* y cuántos *CUDA threads* estarán en cada bloque. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Programa de hello world 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello_world_2.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_2.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    printf(\"Hello world del bloque %d del thread %d!\\n\", blockIdx.x, threadIdx.x);\n",
    "}\n",
    "int main(void){\n",
    "    func<<<2,3>>>(); //2 bloques de 3 threads cada uno\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Hola del cpu thread\\n\");\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall hello_world_2.cu -o hello_world_2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world del bloque 1 del thread 0!\n",
      "Hello world del bloque 1 del thread 1!\n",
      "Hello world del bloque 1 del thread 2!\n",
      "Hello world del bloque 0 del thread 0!\n",
      "Hello world del bloque 0 del thread 1!\n",
      "Hello world del bloque 0 del thread 2!\n",
      "Hola del cpu thread\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./hello_world_2.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* En lo que continúa el nombre *thread* hace referencia a *CUDA thread* y el nombre bloque a *CUDA block*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El llamado a la ejecución del kernel se realizó en el **host** (CPU) y se lanzaron $2$ bloques (primera posición en la sintaxis <<<>>>), cada uno con $3$ *threads*.\n",
    "\n",
    "* Se utiliza la función [cudaDeviceSynchronize](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d) para que el *cpu-thread* espere la finalización de la ejecución del kernel.\n",
    "\n",
    "* En el ejemplo anterior, las variables `blockIdx` y `threadIdx` hacen referencia a los **id**'s que tienen los bloques y los threads: el *id* del bloque dentro del *grid* y el *id* del thread dentro del bloque. La parte `.x` de las variables: `blockIdx.x` y `threadIdx.x` refieren a la **primera coordenada** del bloque en el *grid* y a la **primera coordenada** del *thread* en en el bloque. \n",
    "\n",
    "* La elección del número de bloques en un grid o el número de *threads* en un bloque no corresponde a alguna disposición del hardware, esto es, si se lanza un kernel con `<<< 1, 3 >>>` no implica que la GPU tenga en su hardware un bloque o 3 *threads*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Grid's y bloques 3-dimensionales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una GPU podemos definir el *grid* de bloques y el bloque de *threads* utilizando el tipo de dato `dim3` el cual también es parte de CUDA C:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello_world_3.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_world_3.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    printf(\"Hello world del bloque %d del thread %d!\\n\", blockIdx.y, threadIdx.z);\n",
    "}\n",
    "int main(void){\n",
    "    dim3 dimGrid(1,2,1); //2 bloques en el grid\n",
    "    dim3 dimBlock(1,1,3); //3 threads por bloque\n",
    "    func<<<dimGrid,dimBlock>>>(); \n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Hola del cpu thread\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall hello_world_3.cu -o hello_world_3.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world del bloque 1 del thread 0!\n",
      "Hello world del bloque 1 del thread 1!\n",
      "Hello world del bloque 1 del thread 2!\n",
      "Hello world del bloque 0 del thread 0!\n",
      "Hello world del bloque 0 del thread 1!\n",
      "Hello world del bloque 0 del thread 2!\n",
      "Hola del cpu thread\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./hello_world_3.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing thread_idxs.cu\n"
     ]
    }
   ],
   "source": [
    "%%file thread_idxs.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    if(threadIdx.x==0 && threadIdx.y==0 && threadIdx.z==0){\n",
    "        printf(\"blockIdx.x:%d\\n\",blockIdx.x);\n",
    "    }\n",
    "    printf(\"thread idx.x:%d\\n\",threadIdx.x);\n",
    "    printf(\"thread idx.y:%d\\n\",threadIdx.y);\n",
    "    printf(\"thread idx.z:%d\\n\",threadIdx.z);\n",
    "}\n",
    "int main(void){\n",
    "    dim3 dimGrid(1,1,1); //1 bloque en el grid\n",
    "    dim3 dimBlock(1,3,1); //3 threads por bloque\n",
    "    func<<<dimGrid,dimBlock>>>(); \n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall thread_idxs.cu -o thread_idxs.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockIdx.x:0\n",
      "thread idx.x:0\n",
      "thread idx.x:0\n",
      "thread idx.x:0\n",
      "thread idx.y:0\n",
      "thread idx.y:1\n",
      "thread idx.y:2\n",
      "thread idx.z:0\n",
      "thread idx.z:0\n",
      "thread idx.z:0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./thread_idxs.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing block_idxs.cu\n"
     ]
    }
   ],
   "source": [
    "%%file block_idxs.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    printf(\"blockIdx.x:%d\\n\",blockIdx.x);\n",
    "    printf(\"blockIdx.y:%d\\n\",blockIdx.y);\n",
    "    printf(\"blockIdx.z:%d\\n\",blockIdx.z);\n",
    "\n",
    "}\n",
    "int main(void){\n",
    "    dim3 dimGrid(1,2,2); //4 bloques en el grid\n",
    "    dim3 dimBlock(1,1,1); //1 thread por bloque\n",
    "    func<<<dimGrid,dimBlock>>>(); \n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall block_idxs.cu -o block_idxs.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockIdx.x:0\n",
      "blockIdx.x:0\n",
      "blockIdx.x:0\n",
      "blockIdx.x:0\n",
      "blockIdx.y:0\n",
      "blockIdx.y:1\n",
      "blockIdx.y:1\n",
      "blockIdx.y:0\n",
      "blockIdx.z:0\n",
      "blockIdx.z:0\n",
      "blockIdx.z:1\n",
      "blockIdx.z:1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./block_idxs.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar la variable `blockDim` para cada coordenada `x, y` o `z` y obtener la dimensión de los bloques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing block_dims.cu\n"
     ]
    }
   ],
   "source": [
    "%%file block_dims.cu\n",
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    if(threadIdx.x==0 && threadIdx.y==0 && threadIdx.z==0 && blockIdx.z==1){\n",
    "    printf(\"blockDim.x:%d\\n\",blockDim.x);\n",
    "    printf(\"blockDim.y:%d\\n\",blockDim.y);\n",
    "    printf(\"blockDim.z:%d\\n\",blockDim.z);\n",
    "    }\n",
    "\n",
    "}\n",
    "int main(void){\n",
    "    dim3 dimGrid(2,2,2); //8 bloques en el grid\n",
    "    dim3 dimBlock(3,1,2); //6 threads por bloque\n",
    "    func<<<dimGrid,dimBlock>>>(); \n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "nvcc --compiler-options -Wall block_dims.cu -o block_dims.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockDim.x:3\n",
      "blockDim.x:3\n",
      "blockDim.x:3\n",
      "blockDim.x:3\n",
      "blockDim.y:1\n",
      "blockDim.y:1\n",
      "blockDim.y:1\n",
      "blockDim.y:1\n",
      "blockDim.z:2\n",
      "blockDim.z:2\n",
      "blockDim.z:2\n",
      "blockDim.z:2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./block_dims.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alojamiento de memoria en el device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para alojar memoria en el *device* se utiliza el llamado a [cudaMalloc](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1g37d37965bfb4803b6d4e59ff26856356) y para transferir datos del *host* al *device* o viceversa se llama a lafunción [cudaMemcpy](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1gc263dbe6574220cc776b45438fc351e8) con respectivos parámetros como `cudaMemcpyHostToDevice` o `cudaMemcpyDeviceToHost`. \n",
    "\n",
    "Para desalojar memoria del *device* se utiliza el llamado a [cudaFree](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Programa de suma vectorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N bloques de 1 thread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma_vectorial.cu\n"
     ]
    }
   ],
   "source": [
    "%%file suma_vectorial.cu\n",
    "#include<stdio.h>\n",
    "#define N 10\n",
    "__global__ void suma_vect(int *a, int *b, int *c){\n",
    "    int block_id_x = blockIdx.x;\n",
    "    if(block_id_x<N) //aquí se asume que el valor de N \n",
    "                     //es menor al número máximo de bloques que se pueden lanzar\n",
    "                     //si fuese mayor, hay que hacer un ajuste\n",
    "        c[block_id_x] = a[block_id_x]+b[block_id_x];\n",
    "}\n",
    "int main(void){\n",
    "    int a[N], b[N],c[N];\n",
    "    int *device_a, *device_b, *device_c;\n",
    "    int i;\n",
    "    dim3 dimGrid(N,1,1); //N bloques en el grid\n",
    "    dim3 dimBlock(1,1,1); //1 threads por bloque \n",
    "    //alojando en device\n",
    "    cudaMalloc((void **)&device_a, sizeof(int)*N); \n",
    "    cudaMalloc((void **)&device_b, sizeof(int)*N);\n",
    "    cudaMalloc((void **)&device_c, sizeof(int)*N);\n",
    "    //llenando los arreglos con datos dummy:\n",
    "    for(i=0;i<N;i++){\n",
    "        a[i]=i;\n",
    "        b[i]=i*i;\n",
    "    }\n",
    "    //copiamos arreglos a, b a la GPU\n",
    "    cudaMemcpy(device_a,a,N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(device_b,b,N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "    //mandamos a llamar a suma_vect:\n",
    "    suma_vect<<<dimGrid,dimBlock>>>(device_a,device_b,device_c); //N bloques de 1 thread\n",
    "    cudaDeviceSynchronize();\n",
    "    //copia del resultado al arreglo c:\n",
    "    cudaMemcpy(c,device_c,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
    "    for(i=0;i<N;i++)\n",
    "        printf(\"%d+%d = %d\\n\",a[i],b[i],c[i]);\n",
    "    cudaFree(device_a);\n",
    "    cudaFree(device_b);\n",
    "    cudaFree(device_c);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall suma_vectorial.cu -o suma_vectorial.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0+0 = 0\n",
      "1+1 = 2\n",
      "2+4 = 6\n",
      "3+9 = 12\n",
      "4+16 = 20\n",
      "5+25 = 30\n",
      "6+36 = 42\n",
      "7+49 = 56\n",
      "8+64 = 72\n",
      "9+81 = 90\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./suma_vectorial.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obsérvese que se están utilizando apuntadores en la línea:\n",
    "\n",
    "```\n",
    "    int *device_a, *device_b, *device_c;\n",
    "```\n",
    "\n",
    "pero estos apuntadores no apuntan a una dirección de memoria en el *device* pues aunque NVIDIA añadió el *feature* de [Unified Memory](https://devblogs.nvidia.com/unified-memory-cuda-beginners/) (un espacio de memoria accesible para el *host* y el *device*) aquí no se está usando tal *feature*. Más bien se están utilizando los apuntadores anteriores para apuntar a un [struct](https://en.wikipedia.org/wiki/Struct_(C_programming_language)) de C en el que uno de sus tipos de datos es una dirección de memoria en el *device*.\n",
    "\n",
    "* Obsérvese el uso de `(void **)` por la definición de la función `cudaMalloc`.\n",
    "\n",
    "* Obsérvese que en el programa anterior se coloca en comentario que se asume que $N$ el número de datos en el arreglo es menor al número de *CUDA blocks* que es posible lanzar. Esto como veremos más adelante es importante considerar pues aunque en un *device* se pueden lanzar muchos bloques y muchos threads, se tienen límites en el número de éstos que es posible lanzar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Perfilamiento en CUDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al instalar el *CUDA toolkit* en sus máquinas o bien si utilizan el contenedor de docker (descrito al inicio de la nota) se instala la línea de comando [nvprof](https://docs.nvidia.com/cuda/profiler-users-guide/index.html) para perfilamiento. Se puede ejecutar con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0+0 = 0\n",
      "1+1 = 2\n",
      "2+4 = 6\n",
      "3+9 = 12\n",
      "4+16 = 20\n",
      "5+25 = 30\n",
      "6+36 = 42\n",
      "7+49 = 56\n",
      "8+64 = 72\n",
      "9+81 = 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==341== NVPROF is profiling process 341, command: ./suma_vectorial.out\n",
      "==341== Profiling application: ./suma_vectorial.out\n",
      "==341== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:    46.00  2.21e-06         1  2.21e-06  2.21e-06  2.21e-06  suma_vect(int*, int*, int*)\n",
      "                    30.67  1.47e-06         2  7.36e-07  5.44e-07  9.28e-07  [CUDA memcpy HtoD]\n",
      "                    23.33  1.12e-06         1  1.12e-06  1.12e-06  1.12e-06  [CUDA memcpy DtoH]\n",
      "      API calls:    99.66  0.091447         3  0.030482  4.89e-06  0.091436  cudaMalloc\n",
      "                     0.13  1.20e-04        97  1.24e-06  1.81e-07  4.94e-05  cuDeviceGetAttribute\n",
      "                     0.06  5.82e-05         3  1.94e-05  3.49e-06  4.85e-05  cudaFree\n",
      "                     0.05  4.67e-05         1  4.67e-05  4.67e-05  4.67e-05  cuDeviceTotalMem\n",
      "                     0.03  3.06e-05         3  1.02e-05  5.24e-06  1.39e-05  cudaMemcpy\n",
      "                     0.03  2.55e-05         1  2.55e-05  2.55e-05  2.55e-05  cuDeviceGetName\n",
      "                     0.02  1.85e-05         1  1.85e-05  1.85e-05  1.85e-05  cudaLaunchKernel\n",
      "                     0.01  5.00e-06         1  5.00e-06  5.00e-06  5.00e-06  cudaDeviceSynchronize\n",
      "                     0.00  2.29e-06         3  7.64e-07  2.46e-07  1.66e-06  cuDeviceGetCount\n",
      "                     0.00  2.20e-06         1  2.20e-06  2.20e-06  2.20e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  9.20e-07         2  4.60e-07  2.04e-07  7.16e-07  cuDeviceGet\n",
      "                     0.00  2.67e-07         1  2.67e-07  2.67e-07  2.67e-07  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "nvprof --normalized-time-unit s ./suma_vectorial.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* Las unidades en las que se reporta son s: second, ms: millisecond, us: microsecond, ns: nanosecond.\n",
    "\n",
    "* En la documentación de NVIDIA se menciona que `nvprof` será reemplazada próximamente por [NVIDIA Nsight Compute](https://developer.nvidia.com/nsight-compute) y [NVIDIA Nsight Systems](https://developer.nvidia.com/nsight-systems).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior se lanzaron $N$ bloques con $1$ *thread* cada uno y a continuación se lanza $1$ bloque con $N$ *threads*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing suma_vectorial_2.cu\n"
     ]
    }
   ],
   "source": [
    "%%file suma_vectorial_2.cu\n",
    "#include<stdio.h>\n",
    "#define N 10\n",
    "__global__ void suma_vect(int *a, int *b, int *c){\n",
    "    int thread_id_x = threadIdx.x;\n",
    "    if(thread_id_x<N) //aquí se asume que el valor de N \n",
    "                     //es menor al número máximo de threads que se pueden lanzar\n",
    "                    //si fuese mayor, hay que hacer un ajuste\n",
    "        c[thread_id_x] = a[thread_id_x]+b[thread_id_x];\n",
    "}\n",
    "int main(void){\n",
    "    int *device_a, *device_b, *device_c;\n",
    "    int i;\n",
    "    dim3 dimGrid(1,1,1); //1 bloques en el grid\n",
    "    dim3 dimBlock(N,1,1); //N threads por bloque \n",
    "    //alojando en device con Unified Memory\n",
    "    cudaMallocManaged(&device_a, sizeof(int)*N);\n",
    "    cudaMallocManaged(&device_b, sizeof(int)*N);\n",
    "    cudaMallocManaged(&device_c, sizeof(int)*N);\n",
    "    //llenando los arreglos:\n",
    "    for(i=0;i<N;i++){\n",
    "        device_a[i]=i;\n",
    "        device_b[i]=i*i;\n",
    "    }\n",
    "    suma_vect<<<dimGrid,dimBlock>>>(device_a,device_b,device_c); //1 bloque con N threads\n",
    "    cudaDeviceSynchronize();\n",
    "    for(i=0;i<N;i++)\n",
    "        printf(\"%d+%d = %d\\n\",device_a[i],device_b[i],device_c[i]);\n",
    "    cudaFree(device_a);\n",
    "    cudaFree(device_b);\n",
    "    cudaFree(device_c);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall suma_vectorial_2.cu -o suma_vectorial_2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0+0 = 0\n",
      "1+1 = 2\n",
      "2+4 = 6\n",
      "3+9 = 12\n",
      "4+16 = 20\n",
      "5+25 = 30\n",
      "6+36 = 42\n",
      "7+49 = 56\n",
      "8+64 = 72\n",
      "9+81 = 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==388== NVPROF is profiling process 388, command: ./suma_vectorial_2.out\n",
      "==388== Profiling application: ./suma_vectorial_2.out\n",
      "==388== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:   100.00  2.62e-06         1  2.62e-06  2.62e-06  2.62e-06  suma_vect(int*, int*, int*)\n",
      "      API calls:    99.53  0.155055         3  0.051685  1.24e-05  0.155003  cudaMallocManaged\n",
      "                     0.18  2.88e-04         1  2.88e-04  2.88e-04  2.88e-04  cudaLaunchKernel\n",
      "                     0.12  1.82e-04        97  1.88e-06  2.60e-07  7.44e-05  cuDeviceGetAttribute\n",
      "                     0.07  1.17e-04         3  3.89e-05  1.28e-05  7.48e-05  cudaFree\n",
      "                     0.04  6.62e-05         1  6.62e-05  6.62e-05  6.62e-05  cuDeviceTotalMem\n",
      "                     0.03  4.38e-05         1  4.38e-05  4.38e-05  4.38e-05  cudaDeviceSynchronize\n",
      "                     0.02  3.42e-05         1  3.42e-05  3.42e-05  3.42e-05  cuDeviceGetName\n",
      "                     0.00  2.78e-06         1  2.78e-06  2.78e-06  2.78e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  2.16e-06         3  7.19e-07  3.65e-07  1.32e-06  cuDeviceGetCount\n",
      "                     0.00  1.11e-06         2  5.55e-07  3.54e-07  7.57e-07  cuDeviceGet\n",
      "                     0.00  4.19e-07         1  4.19e-07  4.19e-07  4.19e-07  cuDeviceGetUuid\n",
      "\n",
      "==388== Unified Memory profiling result:\n",
      "Device \"GeForce GTX 750 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "       1  8.0000KB  8.0000KB  8.0000KB  8.000000KB  1.9840e-06s  Host To Device\n",
      "       5  25.600KB  4.0000KB  60.000KB  128.0000KB  1.4240e-05s  Device To Host\n",
      "Total CPU Page faults: 2\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "nvprof --normalized-time-unit s ./suma_vectorial_2.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* El programa anterior utiliza la [Unified Memory](https://devblogs.nvidia.com/unified-memory-cuda-beginners/) con la función [cudaMallocManaged](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__HIGHLEVEL.html#group__CUDART__HIGHLEVEL_1gcf6b9b1019e73c5bc2b39b39fe90816e). La *Unified Memory* es un *feature* que se añadió a CUDA desde las arquitecturas de **Kepler** y **Maxwell** pero que ha ido mejorando (por ejemplo añadiendo [page faulting](https://en.wikipedia.org/wiki/Page_fault) and [migration](https://www.kernel.org/doc/html/latest/vm/page_migration.html)) en las arquitecturas siguientes a la de *Kepler*: la arquitectura Pascal y Volta. Por esto en el *output* anterior de *nvprof* aparece una sección de *page fault*. \n",
    "\n",
    "* Obsérvese que en el programa anterior se comenta que se asume que $N$ el número de datos en el arreglo es menor al número de *threads* que es posible lanzar. Esto como veremos más adelante es importante considerar pues aunque en el *device* se pueden lanzar muchos bloques y muchos threads, se tienen límites en el número de éstos que es posible lanzar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Tenemos que inicializar los datos en la CPU y copiarlos hacia la GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En realidad no tenemos que realizarlo para el ejemplo de `suma_vectorial.cu` anterior. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting suma_vectorial_3.cu\n"
     ]
    }
   ],
   "source": [
    "%%file suma_vectorial_3.cu\n",
    "#include<stdio.h>\n",
    "#define N 10\n",
    "__global__ void init(int *a, int *b){\n",
    "    int thread_id_x = threadIdx.x;\n",
    "    a[thread_id_x]=thread_id_x;\n",
    "    b[thread_id_x]=thread_id_x*thread_id_x;\n",
    "}\n",
    "\n",
    "__global__ void suma_vect(int *a, int *b, int *c){\n",
    "    int thread_id_x = threadIdx.x;\n",
    "    if(thread_id_x<N) //aquí se asume que el valor de N \n",
    "                     //es menor al número máximo de threads que se pueden lanzar\n",
    "                    //si fuese mayor, hay que hacer un ajuste\n",
    "        c[thread_id_x] = a[thread_id_x]+b[thread_id_x];\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "    int *device_a, *device_b, *device_c;\n",
    "    int i;\n",
    "    dim3 dimGrid(1,1,1); //1 bloques en el grid\n",
    "    dim3 dimBlock(N,1,1); //N threads por bloque \n",
    "    //alojando en device con Unified Memory\n",
    "    cudaMallocManaged(&device_a, sizeof(int)*N);\n",
    "    cudaMallocManaged(&device_b, sizeof(int)*N);\n",
    "    cudaMallocManaged(&device_c, sizeof(int)*N);\n",
    "    //llenando los arreglos:\n",
    "    init<<<dimGrid,dimBlock>>>(device_a,device_b);\n",
    "    //llamando al kernel suma_vect\n",
    "    suma_vect<<<dimGrid,dimBlock>>>(device_a,device_b,device_c); //1 bloque con N threads\n",
    "    cudaDeviceSynchronize();\n",
    "    for(i=0;i<N;i++)\n",
    "        printf(\"%d+%d = %d\\n\",device_a[i],device_b[i],device_c[i]);\n",
    "    cudaFree(device_a);\n",
    "    cudaFree(device_b);\n",
    "    cudaFree(device_c);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall suma_vectorial_3.cu -o suma_vectorial_3.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0+0 = 0\n",
      "1+1 = 2\n",
      "2+4 = 6\n",
      "3+9 = 12\n",
      "4+16 = 20\n",
      "5+25 = 30\n",
      "6+36 = 42\n",
      "7+49 = 56\n",
      "8+64 = 72\n",
      "9+81 = 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==453== NVPROF is profiling process 453, command: ./suma_vectorial_3.out\n",
      "==453== Profiling application: ./suma_vectorial_3.out\n",
      "==453== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:    53.19  2.40e-06         1  2.40e-06  2.40e-06  2.40e-06  init(int*, int*)\n",
      "                    46.81  2.11e-06         1  2.11e-06  2.11e-06  2.11e-06  suma_vect(int*, int*, int*)\n",
      "      API calls:    99.58  0.150098         3  0.050033  1.49e-05  0.150043  cudaMallocManaged\n",
      "                     0.19  2.89e-04        97  2.98e-06  2.88e-07  1.58e-04  cuDeviceGetAttribute\n",
      "                     0.08  1.24e-04         3  4.15e-05  1.72e-05  7.28e-05  cudaFree\n",
      "                     0.07  1.03e-04         2  5.17e-05  1.19e-05  9.16e-05  cudaLaunchKernel\n",
      "                     0.05  6.84e-05         1  6.84e-05  6.84e-05  6.84e-05  cuDeviceTotalMem\n",
      "                     0.02  2.79e-05         1  2.79e-05  2.79e-05  2.79e-05  cuDeviceGetName\n",
      "                     0.01  1.65e-05         1  1.65e-05  1.65e-05  1.65e-05  cudaDeviceSynchronize\n",
      "                     0.00  2.22e-06         3  7.41e-07  3.79e-07  1.12e-06  cuDeviceGetCount\n",
      "                     0.00  2.13e-06         1  2.13e-06  2.13e-06  2.13e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  1.24e-06         2  6.22e-07  3.78e-07  8.66e-07  cuDeviceGet\n",
      "                     0.00  5.02e-07         1  5.02e-07  5.02e-07  5.02e-07  cuDeviceGetUuid\n",
      "\n",
      "==453== Unified Memory profiling result:\n",
      "Device \"GeForce GTX 750 (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "       3  21.333KB  4.0000KB  52.000KB  64.00000KB  6.8480e-06s  Device To Host\n",
      "Total CPU Page faults: 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof --normalized-time-unit s ./suma_vectorial_3.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura de una GPU y límites en número de threads y bloques que podemos lanzar en el kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un *device* está compuesto por arreglos de **streaming multiprocessors SM's** (también denotados como MP's) y en cada *SM* encontramos un número (determinado por la arquitectura del device) de **streaming processors SP's** que comparten el caché y unidades de control (que están dentro de cada SM):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/oxx55upoayfmliw/SMS_CUDA.png?dl=0\" heigth=\"700\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dibujo anterior se muestran las SM's en color rojo y los SP's en morado. Hay dos SM's por cada bloque anaranjado y ocho SP's por cada SM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los bloques de threads son **asignados a cada SM por el CUDA runtime system** y hay un límite de bloques que pueden ser asignados a cada SM. Ver [maximum number of blocks per multiprocessor](https://stackoverflow.com/questions/22520209/programmatically-retrieve-maximum-number-of-blocks-per-multiprocessor).\n",
    "\n",
    "Para obtener propiedades de los *devices* que se encuentran en mi sistema se puede utilizar el siguiente programa que está basado en [liga](https://devblogs.nvidia.com/how-query-device-properties-and-handle-errors-cuda-cc/) y [cudaDeviceProp Struct Reference](https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting device_properties.cu\n"
     ]
    }
   ],
   "source": [
    "%%file device_properties.cu\n",
    "\n",
    "#include<stdio.h>\n",
    "\n",
    "int main(void){\n",
    "    cudaDeviceProp properties;\n",
    "    int count;\n",
    "    int i;\n",
    "    cudaGetDeviceCount(&count);\n",
    "    for(i=0;i<count;i++){\n",
    "        printf(\"----------------------\\n\");\n",
    "        cudaGetDeviceProperties(&properties, i);\n",
    "        printf(\"----device %d ----\\n\",i); \n",
    "        printf(\"Device Name: %s\\n\", properties.name);\n",
    "        printf(\"Compute capability: %d.%d\\n\", properties.major, properties.minor);\n",
    "        printf(\"Clock rate: %d\\n\", properties.clockRate);\n",
    "        printf(\"Unified memory: %d\\n\", properties.unifiedAddressing);\n",
    "        printf(\" ---Memory Information for device %d (results on bytes)---\\n\", i);\n",
    "        printf(\"Total global mem: %ld\\n\", properties.totalGlobalMem); \n",
    "        printf(\"Total constant Mem: %ld\\n\", properties.totalConstMem);\n",
    "        printf(\"Shared memory per thread block: %ld\\n\", properties.sharedMemPerBlock);\n",
    "        printf(\"Shared memory per SM: %ld\\n\",properties.sharedMemPerMultiprocessor );\n",
    "        printf(\" ---MP Information for device %d ---\\n\", i);\n",
    "        printf(\"SM count: %d\\n\", properties.multiProcessorCount);\n",
    "        printf(\"Threads in warp: %d\\n\", properties.warpSize);\n",
    "        printf(\"Max threads per SM: %d\\n\", properties.maxThreadsPerMultiProcessor);\n",
    "        printf(\"Max warps per SM: %d\\n\",properties.maxThreadsPerMultiProcessor/properties.warpSize);\n",
    "        printf(\"Max threads per block: %d\\n\", properties.maxThreadsPerBlock);\n",
    "        printf(\"Max thread dimensions: (%d, %d, %d)\\n\", properties.maxThreadsDim[0], properties.maxThreadsDim[1], properties.maxThreadsDim[2]);\n",
    "        printf(\"Max grid dimensions: (%d, %d, %d)\\n\", properties.maxGridSize[0], properties.maxGridSize[1], properties.maxGridSize[2]); \n",
    "    }\n",
    "    return 0;\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "nvcc --compiler-options -Wall device_properties.cu -o device_properties.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "----device 0 ----\n",
      "Device Name: Tesla K20Xm\n",
      "Compute capability: 3.5\n",
      "Clock rate: 732000\n",
      "Unified memory: 1\n",
      " ---Memory Information for device 0 (results on bytes)---\n",
      "Total global mem: 5977800704\n",
      "Total constant Mem: 65536\n",
      "Shared memory per thread block: 49152\n",
      "Shared memory per SM: 49152\n",
      " ---MP Information for device 0 ---\n",
      "SM count: 14\n",
      "Threads in warp: 32\n",
      "Max threads per SM: 2048\n",
      "Max warps per SM: 64\n",
      "Max threads per block: 1024\n",
      "Max thread dimensions: (1024, 1024, 64)\n",
      "Max grid dimensions: (2147483647, 65535, 65535)\n",
      "----------------------\n",
      "----device 1 ----\n",
      "Device Name: Tesla K20Xm\n",
      "Compute capability: 3.5\n",
      "Clock rate: 732000\n",
      "Unified memory: 1\n",
      " ---Memory Information for device 1 (results on bytes)---\n",
      "Total global mem: 5977800704\n",
      "Total constant Mem: 65536\n",
      "Shared memory per thread block: 49152\n",
      "Shared memory per SM: 49152\n",
      " ---MP Information for device 1 ---\n",
      "SM count: 14\n",
      "Threads in warp: 32\n",
      "Max threads per SM: 2048\n",
      "Max warps per SM: 64\n",
      "Max threads per block: 1024\n",
      "Max thread dimensions: (1024, 1024, 64)\n",
      "Max grid dimensions: (2147483647, 65535, 65535)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./device_properties.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* Obsérvese del *output* anterior que el sistema tiene dos *devices* con las mismas capacidades.\n",
    "\n",
    "* En un *device* encontramos diferentes tipos de memoria: global, constante, *shared* y *texture*.\n",
    "\n",
    "* Los bloques de threads que son asignados a una SM son divididos en **warps** que es la unidad de *thread scheduling* que tiene el *CUDA run time system*. El *output* anterior indica que son divisiones de $32$ threads: un warp consta de $32$ threads.\n",
    "\n",
    "* El número máximo de threads por SM es de $2048$ o bien $2048/32 = 64$ warps.\n",
    "\n",
    "* El *output* anterior muestra los límites para número de bloques en las tres dimensiones de un grid y el número de threads en las tres dimensiones en un bloque.\n",
    "\n",
    "* Un bloque puede tener como máximo $1024$ threads en cualquier configuración: por ejemplo $(1024,1,1), (32,1,32), (4,4,64)$.\n",
    "\n",
    "* Por los puntos anteriores si lanzamos bloques de $1024$ threads entonces sólo $2$ bloques pueden residir en una SM en un instante. Con esta configuración alcanzaríamos $1024/32=32$ warps por cada bloque y como lanzamos $2$ bloques alcanzaríamos $64$ warps (que es el máximo de warps por SM que podemos lanzar). Otra configuración para alcanzar el máximo número de warps es considerar $4$ bloques de $512$ threads pues tendríamos $512/32=16$ warps por bloque y en total serían $16*4$ (warps $\\times$ bloques) $=64$ warps. Entre los datos que hay que elegir en los programas de CUDA C se tienen las configuraciones en el número de threads y el número de bloques a lanzar. La idea es alcanzar el máximo número de warps en cada SM que soporta nuestro device en un instante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regla compuesta del rectángulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Los siguientes tiempos se calcularon con una GPU de las siguientes características:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "----device 0 ----\n",
      "Device Name: GeForce GTX 750\n",
      "Compute capability: 5.0\n",
      "Clock rate: 1293500\n",
      "Unified memory: 1\n",
      " ---Memory Information for device 0 (results on bytes)---\n",
      "Total global mem: 1025769472\n",
      "Total constant Mem: 65536\n",
      "Shared memory per thread block: 49152\n",
      "Shared memory per SM: 65536\n",
      " ---MP Information for device 0 ---\n",
      "SM count: 4\n",
      "Threads in warp: 32\n",
      "Max threads per SM: 2048\n",
      "Max warps per SM: 64\n",
      "Max threads per block: 1024\n",
      "Max thread dimensions: (1024, 1024, 64)\n",
      "Max grid dimensions: (2147483647, 65535, 65535)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "./device_properties.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$n=10^3$** subintervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Rcf.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum ) {\n",
    "    double x=0.0;\n",
    "    if(threadIdx.x<=n-1){\n",
    "        x=a+(threadIdx.x+1/2.0)*h_hat;\n",
    "        data[threadIdx.x]=std::exp(-std::pow(x,2));\n",
    "    }\n",
    "    if(threadIdx.x==0){\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n=1e3; //número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin=clock();\n",
    "    Rcf<<<1,n>>>(d_data, a,h_hat,n,d_suma); //1 bloque de n threads\n",
    "    cudaDeviceSynchronize();\n",
    "    end=clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf.cu -o Rcf.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241634690490e-01\n",
      "Error relativo de la solución: 4.104931878976858e-08\n",
      "Tiempo de cálculo en la gpu 0.00010\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241634690490e-01\n",
      "Error relativo de la solución: 4.104931878976858e-08\n",
      "Tiempo de cálculo en la gpu 0.00010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==906== NVPROF is profiling process 906, command: ./Rcf.out\n",
      "==906== Profiling application: ./Rcf.out\n",
      "==906== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:    98.01  6.95e-05         1  6.95e-05  6.95e-05  6.95e-05  Rcf(double*, double, double, int, double*)\n",
      "                     1.99  1.41e-06         1  1.41e-06  1.41e-06  1.41e-06  [CUDA memcpy DtoH]\n",
      "      API calls:    99.52  0.087564         2  0.043782  5.85e-06  0.087558  cudaMalloc\n",
      "                     0.18  1.62e-04        97  1.67e-06  2.78e-07  6.29e-05  cuDeviceGetAttribute\n",
      "                     0.08  7.22e-05         1  7.22e-05  7.22e-05  7.22e-05  cudaDeviceSynchronize\n",
      "                     0.08  6.83e-05         1  6.83e-05  6.83e-05  6.83e-05  cuDeviceTotalMem\n",
      "                     0.06  5.32e-05         2  2.66e-05  5.93e-06  4.73e-05  cudaFree\n",
      "                     0.03  2.46e-05         1  2.46e-05  2.46e-05  2.46e-05  cuDeviceGetName\n",
      "                     0.03  2.39e-05         1  2.39e-05  2.39e-05  2.39e-05  cudaLaunchKernel\n",
      "                     0.02  1.52e-05         1  1.52e-05  1.52e-05  1.52e-05  cudaMemcpy\n",
      "                     0.00  2.03e-06         3  6.76e-07  3.53e-07  1.29e-06  cuDeviceGetCount\n",
      "                     0.00  1.72e-06         1  1.72e-06  1.72e-06  1.72e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  1.24e-06         2  6.22e-07  3.07e-07  9.37e-07  cuDeviceGet\n",
      "                     0.00  4.57e-07         1  4.57e-07  4.57e-07  4.57e-07  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof --normalized-time-unit s ./Rcf.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n=1025$ subintervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Rcf2.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf2.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum ) {\n",
    "    double x=0.0;\n",
    "    if(threadIdx.x<=n-1){\n",
    "        x=a+(threadIdx.x+1/2.0)*h_hat;\n",
    "        data[threadIdx.x]=std::exp(-std::pow(x,2));\n",
    "    }\n",
    "    if(threadIdx.x==0){\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n=1025; //número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin=clock();\n",
    "    Rcf<<<1,n>>>(d_data, a,h_hat,n,d_suma); //1 bloque de n threads\n",
    "    cudaDeviceSynchronize();\n",
    "    end=clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf2.cu -o Rcf2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 0.000000000000000e+00\n",
      "Error relativo de la solución: 1.000000000000000e+00\n",
      "Tiempo de cálculo en la gpu 0.00001\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf2.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese error relativo de $100\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo lo arreglamos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Rcf3.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf3.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum) {\n",
    "    double x=0.0;\n",
    "    int stride=0;\n",
    "    if(threadIdx.x<=n-1){\n",
    "        x=a+(threadIdx.x+1/2.0)*h_hat;\n",
    "        data[threadIdx.x]=std::exp(-std::pow(x,2));\n",
    "    }\n",
    "    if(threadIdx.x==0){\n",
    "        stride=blockDim.x;\n",
    "        x=a+(threadIdx.x+stride+1/2.0)*h_hat;\n",
    "        data[threadIdx.x+stride]=std::exp(-std::pow(x,2));\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n_threads_per_block=1024; \n",
    "    int n_bloques=2;\n",
    "    int n=1025;//número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin=clock();\n",
    "    Rcf<<<n_bloques,n_threads_per_block>>>(d_data, a,h_hat,n,d_suma); \n",
    "    cudaDeviceSynchronize();\n",
    "    end=clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf3.cu -o Rcf3.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241619918411e-01\n",
      "Error relativo de la solución: 3.907133247860604e-08\n",
      "Tiempo de cálculo en la gpu 0.00009\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf3.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero en la propuesta anterior lanzamos $2*1024$ (bloques $\\times$ número de *threads*) $=2048$ *threads* y sólo ocupamos $1025$ threads. Entonces podemos cambiar el código anterior para aprovechar los $2048$ *threads* como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Rcf4.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf4.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum) {\n",
    "    double x=0.0;\n",
    "    int stride=0;\n",
    "    int i;\n",
    "    stride=blockDim.x;\n",
    "    for(i=threadIdx.x;i<=n-1;i+=stride){\n",
    "        if(i<=n-1){\n",
    "            x=a+(i+1/2.0)*h_hat;\n",
    "            data[i]=std::exp(-std::pow(x,2));\n",
    "        }\n",
    "    }\n",
    "    if(threadIdx.x==0){\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n_threads_per_block=1024; \n",
    "    int n_bloques=2;\n",
    "    int n=n_threads_per_block*n_bloques;//número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin=clock();\n",
    "    Rcf<<<n_bloques,n_threads_per_block>>>(d_data, a,h_hat,n,d_suma); \n",
    "    cudaDeviceSynchronize();\n",
    "    end=clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf4.cu -o Rcf4.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241401215338e-01\n",
      "Error relativo de la solución: 9.786918140590463e-09\n",
      "Tiempo de cálculo en la gpu 0.00016\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf4.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero todavía podemos hacer aún mejor sin el *for*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file Rcf5.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum ) {\n",
    "    double x=0.0;\n",
    "    int idx;\n",
    "    idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if(idx<=n-1){\n",
    "        x=a+(idx+1/2.0)*h_hat;\n",
    "        data[idx]=std::exp(-std::pow(x,2));\n",
    "    }\n",
    "    if(idx==0){\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n_threads_per_block=1024; \n",
    "    int n_bloques=2;\n",
    "    double objetivo=0.7468241328124271;\n",
    "    int n=n_bloques*n_threads_per_block;//número de subintervalos\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin = clock();\n",
    "    Rcf<<<n_bloques,n_threads_per_block>>>(d_data, a,h_hat,n,d_suma); \n",
    "    cudaDeviceSynchronize();\n",
    "    end = clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf5.cu -o Rcf5.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241328124601e-01\n",
      "Error relativo de la solución: 4.415179207880368e-14\n",
      "Tiempo de cálculo en la gpu 0.06143\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf5.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241328124601e-01\n",
      "Error relativo de la solución: 4.415179207880368e-14\n",
      "Tiempo de cálculo en la gpu 0.06147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1075== NVPROF is profiling process 1075, command: ./Rcf5.out\n",
      "==1075== Profiling application: ./Rcf5.out\n",
      "==1075== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:   100.00  0.061430         1  0.061430  0.061430  0.061430  Rcf(double*, double, double, int, double*)\n",
      "                     0.00  1.54e-06         1  1.54e-06  1.54e-06  1.54e-06  [CUDA memcpy DtoH]\n",
      "      API calls:    58.84  0.089133         2  0.044567  6.09e-05  0.089072  cudaMalloc\n",
      "                    40.55  0.061434         1  0.061434  0.061434  0.061434  cudaDeviceSynchronize\n",
      "                     0.41  6.14e-04         2  3.07e-04  5.62e-05  5.58e-04  cudaFree\n",
      "                     0.11  1.63e-04        97  1.68e-06  2.76e-07  6.29e-05  cuDeviceGetAttribute\n",
      "                     0.04  6.80e-05         1  6.80e-05  6.80e-05  6.80e-05  cuDeviceTotalMem\n",
      "                     0.02  2.58e-05         1  2.58e-05  2.58e-05  2.58e-05  cuDeviceGetName\n",
      "                     0.02  2.44e-05         1  2.44e-05  2.44e-05  2.44e-05  cudaLaunchKernel\n",
      "                     0.01  1.72e-05         1  1.72e-05  1.72e-05  1.72e-05  cudaMemcpy\n",
      "                     0.00  2.82e-06         1  2.82e-06  2.82e-06  2.82e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  2.12e-06         3  7.06e-07  3.19e-07  1.07e-06  cuDeviceGetCount\n",
      "                     0.00  1.23e-06         2  6.15e-07  3.59e-07  8.71e-07  cuDeviceGet\n",
      "                     0.00  4.47e-07         1  4.47e-07  4.47e-07  4.47e-07  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof --normalized-time-unit s ./Rcf5.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Más nodos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Rcf5.cu\n"
     ]
    }
   ],
   "source": [
    "%%file Rcf6.cu\n",
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum ) {\n",
    "    double x=0.0;\n",
    "    int idx;\n",
    "    idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if(idx<=n-1){\n",
    "        x=a+(idx+1/2.0)*h_hat;\n",
    "        data[idx]=std::exp(-std::pow(x,2));\n",
    "    }\n",
    "    if(idx==0){\n",
    "        *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n_threads_per_block=1024; \n",
    "    int n_bloques=1024;\n",
    "    double objetivo=0.7468241328124271;\n",
    "    int n=n_bloques*n_threads_per_block;//número de subintervalos\n",
    "    double time_spent;\n",
    "    clock_t begin,end;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    begin = clock();\n",
    "    Rcf<<<n_bloques,n_threads_per_block>>>(d_data, a,h_hat,n,d_suma); \n",
    "    cudaDeviceSynchronize();\n",
    "    end = clock();\n",
    "    time_spent = (double)(end - begin) / CLOCKS_PER_SEC;\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    printf(\"Tiempo de cálculo en la gpu %.5f\\n\", time_spent);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc --compiler-options -Wall Rcf6.cu -o Rcf6.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241328124601e-01\n",
      "Error relativo de la solución: 4.415179207880368e-14\n",
      "Tiempo de cálculo en la gpu 0.06143\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./Rcf6.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral de 0.000000 a 1.000000 = 7.468241328124601e-01\n",
      "Error relativo de la solución: 4.415179207880368e-14\n",
      "Tiempo de cálculo en la gpu 0.06147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1075== NVPROF is profiling process 1075, command: ./Rcf5.out\n",
      "==1075== Profiling application: ./Rcf5.out\n",
      "==1075== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "                        %         s                   s         s         s\n",
      " GPU activities:   100.00  0.061430         1  0.061430  0.061430  0.061430  Rcf(double*, double, double, int, double*)\n",
      "                     0.00  1.54e-06         1  1.54e-06  1.54e-06  1.54e-06  [CUDA memcpy DtoH]\n",
      "      API calls:    58.84  0.089133         2  0.044567  6.09e-05  0.089072  cudaMalloc\n",
      "                    40.55  0.061434         1  0.061434  0.061434  0.061434  cudaDeviceSynchronize\n",
      "                     0.41  6.14e-04         2  3.07e-04  5.62e-05  5.58e-04  cudaFree\n",
      "                     0.11  1.63e-04        97  1.68e-06  2.76e-07  6.29e-05  cuDeviceGetAttribute\n",
      "                     0.04  6.80e-05         1  6.80e-05  6.80e-05  6.80e-05  cuDeviceTotalMem\n",
      "                     0.02  2.58e-05         1  2.58e-05  2.58e-05  2.58e-05  cuDeviceGetName\n",
      "                     0.02  2.44e-05         1  2.44e-05  2.44e-05  2.44e-05  cudaLaunchKernel\n",
      "                     0.01  1.72e-05         1  1.72e-05  1.72e-05  1.72e-05  cudaMemcpy\n",
      "                     0.00  2.82e-06         1  2.82e-06  2.82e-06  2.82e-06  cuDeviceGetPCIBusId\n",
      "                     0.00  2.12e-06         3  7.06e-07  3.19e-07  1.07e-06  cuDeviceGetCount\n",
      "                     0.00  1.23e-06         2  6.15e-07  3.59e-07  8.71e-07  cuDeviceGet\n",
      "                     0.00  4.47e-07         1  4.47e-07  4.47e-07  4.47e-07  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof --normalized-time-unit s ./Rcf6.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero todavía para esta tarjeta podemos lanzar hasta $2048$ threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs: en una GPU con las siguientes características:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "----------------------\n",
    "----device 0 ----\n",
    "Device Name: Tesla K20Xm\n",
    "Compute capability: 3.5\n",
    "Clock rate: 732000\n",
    "Unified memory: 1\n",
    " ---Memory Information for device 0 (results on bytes)---\n",
    "Total global mem: 5977800704\n",
    "Total constant Mem: 65536\n",
    "Shared memory per thread block: 49152\n",
    "Shared memory per SM: 49152\n",
    " ---MP Information for device 0 ---\n",
    "SM count: 14\n",
    "Threads in warp: 32\n",
    "Max threads per SM: 2048\n",
    "Max warps per SM: 64\n",
    "Max threads per block: 1024\n",
    "Max thread dimensions: (1024, 1024, 64)\n",
    "Max grid dimensions: (2147483647, 65535, 65535)\n",
    "----------------------\n",
    "----device 1 ----\n",
    "Device Name: Tesla K20Xm\n",
    "Compute capability: 3.5\n",
    "Clock rate: 732000\n",
    "Unified memory: 1\n",
    " ---Memory Information for device 1 (results on bytes)---\n",
    "Total global mem: 5977800704\n",
    "Total constant Mem: 65536\n",
    "Shared memory per thread block: 49152\n",
    "Shared memory per SM: 49152\n",
    " ---MP Information for device 1 ---\n",
    "SM count: 14\n",
    "Threads in warp: 32\n",
    "Max threads per SM: 2048\n",
    "Max warps per SM: 64\n",
    "Max threads per block: 1024\n",
    "Max thread dimensions: (1024, 1024, 64)\n",
    "Max grid dimensions: (2147483647, 65535, 65535)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se obtuvo:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%bash\n",
    "./Rcf5.out\n",
    "Integral de 0.000000 a 1.000000 = 7.468241328124601e-01\n",
    "Error relativo de la solución: 4.415179207880368e-14\n",
    "Tiempo de cálculo en la gpu 0.11382\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas de comprehensión:**\n",
    "\n",
    "\n",
    "Supón que tienes una tarjeta GT200 cuyas características son:\n",
    "\n",
    "    * Máximo número de threads que soporta una SM en un mismo instante en el tiempo: 1024\n",
    "    * Máximo número de threads en un bloque: 512\n",
    "    * Máximo número de bloques por SM: 8\n",
    "    * Número de SM’s que tiene esta GPU: 30\n",
    "\n",
    "Responde:\n",
    "\n",
    "    a) ¿Cuál es la máxima cantidad de threads que puede soportar esta GPU en un mismo instante en el tiempo?\n",
    "    b) ¿Cuál es la máxima cantidad de warps por SM que puede soportar esta GPU en un mismo instante en el tiempo?\n",
    "    c) ¿Cuáles configuraciones de bloques y threads siguientes aprovechan la máxima cantidad de warps en una SM de esta GPU para un mismo instante en el tiempo?\n",
    "    \n",
    "        1.Una configuración del tipo: bloques de 64 threads y 16 bloques.\n",
    "        2.Una configuración del tipo: bloques de 1024 threads y 1 bloque.\n",
    "        3.Una configuración del tipo: bloques de 256 threads y 4 bloques.\n",
    "        4.Una configuración del tipo: bloques de 512 threads y 8 bloques.\n",
    "\n",
    "\\*Debes considerar las restricciones/características de la GPU dadas para responder pues algunas configuraciones infringen las mismas. No estamos considerando registers o shared memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**\n",
    "\n",
    "1. N. Matloff, Parallel Computing for Data Science. With Examples in R, C++ and CUDA, 2014.\n",
    "\n",
    "2. [CUDA](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA)\n",
    "\n",
    "3. [2.3.CUDA](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.3.CUDA.ipynb)\n",
    "\n",
    "Para más sobre *Unified Memory* revisar:\n",
    "\n",
    "* [Even easier introduction to cuda](https://devblogs.nvidia.com/even-easier-introduction-cuda/)\n",
    "\n",
    "* [Unified memory cuda beginners](https://devblogs.nvidia.com/unified-memory-cuda-beginners/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
