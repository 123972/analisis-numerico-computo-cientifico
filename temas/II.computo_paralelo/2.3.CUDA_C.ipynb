{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker run -dit --name nvidia-10.1-container --gpus all nvidia/cuda:10.1-devel-ubuntu18.04 bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Programa de hello world\n",
    "\n",
    "`hello_world.cu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include<stdio.h>\n",
    "__global__ void func(void){\n",
    "    printf(\"Hello world del bloque %d del thread %d!\\n\", blockIdx.x, threadIdx.x);\n",
    "}\n",
    "int main(void){\n",
    "    func<<<3,3>>>(); //3 bloques de 3 threads cada uno\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"Hola del cpu thread\\n\");\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilación: `$nvcc hello_world.cu -o hello_world.out`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecución: `$./hello_world.out`:\n",
    "\n",
    "```\n",
    "Hello world del bloque 1 del thread 0!\n",
    "Hello world del bloque 1 del thread 1!\n",
    "Hello world del bloque 1 del thread 2!\n",
    "Hello world del bloque 0 del thread 0!\n",
    "Hello world del bloque 0 del thread 1!\n",
    "Hello world del bloque 0 del thread 2!\n",
    "Hello world del bloque 2 del thread 0!\n",
    "Hello world del bloque 2 del thread 1!\n",
    "Hello world del bloque 2 del thread 2!\n",
    "Hola del cpu thread\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentarios respecto al programa de `hello_world.cu` anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La extensión del archivo debe ser `.cu` aunque esto puede modificarse al compilar con `nvcc`: \n",
    "\n",
    "`$nvcc -x cu hello_world.c -o hello_world.out`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La función `main` se ejecuta en la CPU.\n",
    "\n",
    "* La función `func` es un *kernel*, lo cual significa que es una función que será ejecutada por *threads* en el *device* (GPU), también llamados *CUDA threads*. Obsérvese que la función `func` inicia con `__global__` para diferenciarla de `main`.\n",
    "\n",
    "* El llamado a la ejecución del kernel se realiza en el *host* a partir del uso de la sintaxis: `<<< , >>>`. Como se lanzó el programa anterior fueron con $3$ bloques (primera posición), cada uno con $3$ *threads*.\n",
    "\n",
    "* El *kernel* sólo puede tener un `return` tipo *void*: `__global__ void func` por lo que el *kernel* debe regresar sus resultados a través de sus argumentos.\n",
    "\n",
    "* Se utiliza la función [cudaDeviceSynchronize](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1g10e20b05a95f638a4071a655503df25d) para que el *cpu-thread* espere la finalización de la ejecución del kernel.\n",
    "\n",
    "* Los *CUDA threads* son divididos en bloques y todos los bloques se encuentran en un *grid*. En el lanzamiento del *kernel*  se debe especificar al hardware cuántos bloques tendrá nuestro *grid* y cuántos *threads* estarán en cada bloque. Las variables `blockIdx` y `threadIdx` hacen referencia a los **id**'s que tienen los bloques y los threads. El *id* del bloque dentro del *grid* y el *id* del thread dentro del bloque. La parte `.x` de `blockIdx.x` y `threadIdx.x` refiere a la primera coordenada del bloque y del *thread* en el *grid* y en el bloque respectivamente. \n",
    "\n",
    "**Comentario:** la elección del número de bloques en un grid o el número de *threads* en un bloque no corresponde a alguna disposición del hardware, esto es, si se lanza un kernel con `<<< 1, 3 >>>` no implica que la GPU tenga un bloque o 3 *threads*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Programa de suma vectorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`suma_vectorial.cu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include<stdio.h>\n",
    "#define N 10\n",
    "__global__ void suma_vect(int *a, int *b, int *c){\n",
    "    int tid = blockIdx.x;\n",
    "    if(tid<N) //suposición N menor al número máximo de bloques que se pueden lanzar\n",
    "    c[tid] = a[tid]+b[tid];\n",
    "}\n",
    "int main(void){\n",
    "    int a[N], b[N],c[N];\n",
    "    int *device_a, *device_b, *device_c;\n",
    "    int i;\n",
    "    //alojando en device\n",
    "    cudaMalloc((void **)&device_a, sizeof(int)*N);\n",
    "    cudaMalloc((void **)&device_b, sizeof(int)*N);\n",
    "    cudaMalloc((void **)&device_c, sizeof(int)*N);\n",
    "    //llenando los arreglos:\n",
    "    for(i=0;i<N;i++){\n",
    "        a[i]=i;\n",
    "        b[i]=i*i;\n",
    "    }\n",
    "    //copiamos arreglos a, b a la GPU\n",
    "    cudaMemcpy(device_a,a,N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(device_b,b,N*sizeof(int), cudaMemcpyHostToDevice);\n",
    "    //mandamos a llamar a suma_vect:\n",
    "    suma_vect<<<N,1>>>(device_a,device_b,device_c); //N bloques de 1 thread\n",
    "    cudaDeviceSynchronize();\n",
    "    //copia del resultado al arreglo c:\n",
    "    cudaMemcpy(c,device_c,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
    "    for(i=0;i<N;i++)\n",
    "        printf(\"%d+%d = %d\\n\",a[i],b[i],c[i]);\n",
    "    cudaFree(device_a);\n",
    "    cudaFree(device_b);\n",
    "    cudaFree(device_c);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentarios respecto al programa de `suma_vectorial.cu` anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regla compuesta del rectángulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvcc --compiler-options -Wall Rcf.cu -o Rcf.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include<stdio.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "\n",
    "__global__ void Rcf(double *data, double a, double h_hat, int n, double *sum ) {\n",
    "double x=0.0;\n",
    "\n",
    "if(threadIdx.x<=n-1){\n",
    "x=a+(threadIdx.x+1/2.0)*h_hat;\n",
    "data[threadIdx.x]=std::exp(-std::pow(x,2));\n",
    "}\n",
    "    *sum = thrust::reduce(thrust::device, data , data + n, (double)0, thrust::plus<double>());\n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char *argv[]){\n",
    "    double suma=0.0;\n",
    "    double *d_data;\n",
    "    double *d_suma;\n",
    "    double a=0.0, b=1.0;\n",
    "    double h_hat;\n",
    "    int n=1e3; //número de subintervalos\n",
    "    double objetivo=0.7468241328124271;\n",
    "    cudaMalloc((void **)&d_data,sizeof(double)*n);\n",
    "    cudaMalloc((void**)&d_suma,sizeof(double));\n",
    "    h_hat=(b-a)/n;\n",
    "    Rcf<<<1,n>>>(d_data, a,h_hat,n,d_suma); //1 bloque de n threads\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaMemcpy(&suma, d_suma, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "    suma=h_hat*suma;\n",
    "    cudaFree(d_data) ;\n",
    "    cudaFree(d_suma) ;\n",
    "    printf(\"Integral de %f a %f = %1.15e\\n\", a,b,suma);\n",
    "    printf(\"Error relativo de la solución: %1.15e\\n\", fabs(suma-objetivo)/fabs(objetivo));\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integral de 0.000000 a 1.000000 = 7.468241634690490e-01\n",
    "\n",
    "Error relativo de la solución: 4.104931878976858e-08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**\n",
    "\n",
    "1. N. Matloff, Parallel Computing for Data Science. With Examples in R, C++ and CUDA, 2014.\n",
    "\n",
    "2. [CUDA](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
