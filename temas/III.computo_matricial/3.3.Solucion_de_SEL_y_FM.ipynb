{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga](https://www.dropbox.com/s/jwu8lu4r14pb7ut/3.2.1.Sistemas_de_ecuaciones_lineales_eliminacion_Gaussiana_y_factorizacion_LU.pdf?dl=0), [liga2](https://www.dropbox.com/s/s4ch0ww1687pl76/3.2.2.Factorizaciones_matriciales_SVD_Cholesky_QR.pdf?dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3.Solución de Sistemas de Ecuaciones Lineales (SEL) y Factorizaciones Matriciales (FM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de ecuaciones lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general son de la forma: $$\\begin{array}{ccc} a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n  &= & b_1 \\\\ a_{21}x_1 + a_{22}x_2 +  \\cdots + a_{2n}x_n &= & b_2 \\\\ \\vdots & & \\\\ a_{m1}x_1 + a_{m2}x_2 + \\cdots + a_{mn}x_n &=& b_m \\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde: las $x_i$'s son las incógnitas y las $a_i$'s y $b_i$'s son constantes conocidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las entradas $a_{ij}$'s son llamadas coeficientes del sistema y el conjunto de $b_i$'s se le llama lado derecho del sistema. Si todas las $b_i$'s son iguales a $0$ el sistema se le nombra **homogéneo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 posibilidades para solución del sistema anterior:**\n",
    "\n",
    "* Una única solución: sólo existe uno y sólo un conjunto de valores de $x_i$'s que satisfacen todas las ecuaciones simultáneamente y el sistema se nombra **consistente** o **no singular**.\n",
    "\n",
    "* Ninguna solución: no existe ningún conjunto de valores de $x_i$'s que satisfacen todas las ecuaciones simultáneamente (el conjunto solución es vacío) y el sistema se nombra **inconsistente** o singular.\n",
    "\n",
    "* Infinitas soluciones: hay una infinidad de conjuntos (distintos) de valores de las $x_i$'s que satisfacen todas las ecuaciones simultáneamente. **obs:** si un sistema tiene más de una solución entonces tiene una infinidad de soluciones y el sistema se nombra **consistente** o **no singular**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretación geométrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resolver un sistema de ecuaciones lineales equivale a encontrar la intersección entre rectas, planos o hiperplanos (2,3 o n dimensiones respectivamente). Por ejemplo para un caso de dos dimensiones se tiene:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://drive.google.com/uc?export=view&id=0B66Kmqpqr3IQdHlOQk9LOWxZQ0VINVd6SlFELWdjR0c3d2lz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El inciso a) representa un sistema de ecuaciones lineales sin solución, el inciso b) infinitas soluciones (en el dibujo ligeramente se desplazó hacia abajo una de las rectas para mostrar ambas) y el inciso c) una única solución. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nombres dados a los sistemas dependiendo de sus dimensiones:**\n",
    "\n",
    "* Si $m > n$ el sistema $Ax=b$ se nombra *overdetermined*: hay más ecuaciones que incógnitas. En general no existe $x \\in \\mathbb{R}^n$ que satisfaga el sistema por lo que se busca resolver el problema de encontrar $x \\in \\mathbb{R}^n$ tal que $||Ax-b||$ sea mínima. Si $||\\cdot||$ es la norma Euclidiana, el problema anterior se le llama **mínimos cuadrados**.\n",
    "\n",
    "* Si $m < n$ el sistema $Ax=b$ se nombra *underdetermined*: hay menos ecuaciones que incógnitas. El sistema tiene una infinidad de soluciones ó ninguna solución. Lo anterior depende del $rank(A)$. Si $rank(A)=m$ entonces $Ax=b$ tiene infinitas soluciones\\*\n",
    "\n",
    "\\*Para ver esto considérese el resultado del álgebra lineal [Rank-nullity theorem](https://en.wikipedia.org/wiki/Rank%E2%80%93nullity_theorem) que en este contexto se escribe como $n = rank(A) + nullity(A) = m + nullity(A)$ $\\therefore nullity(A) = n-m$. Si $x_0 \\in \\mathbb{R}^n$ es una solución de $Ax=b$ entonces $x_0 + N(A)$ es el conjunto de soluciones de $Ax=b$, donde $x_0 + N(A) = \\{x_0 + z | z \\in N(A)\\}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen una gran cantidad de algoritmos para resolver los sistemas de ecuaciones lineales. Típicamente se elige el algoritmo de acuerdo a los coeficientes de la matriz del sistema que determinan propiedades de la misma y sus dimensiones.\n",
    "\n",
    "Los hay **iterativos** y **directos o basados en factorizaciones matriciales**. Entre los directos o basados en factorizaciones matriciales se encuentran:\n",
    "\n",
    "\n",
    "* Eliminación Gaussiana o factorización LU.\n",
    "* Factorización de Cholesky.\n",
    "* Factorización QR.\n",
    "* Descomposición en valores singulares (DVS o SVD por siglas en inglés).\n",
    "\n",
    "y como ejemplo de los iterativos están:\n",
    "\n",
    "* Jacobi.\n",
    "* Gauss-Seidel.\n",
    "* Gradiente conjugado.\n",
    "\n",
    "A estos algoritmos nombrémosles nuestros algoritmos básicos del álgebra lineal para resolver Sistemas de Ecuaciones Lineales o Factorizaciones Matriciales **(SEL o FM)**. Cada uno puede utilizarse para resolver SEL, FM o para otros propósitos. Por ejemplo la factorización QR también se utiliza en el cálculo de eigenvalores y eigenvectores en el algoritmo QR, ver [QR algorithm](https://en.wikipedia.org/wiki/QR_algorithm).\n",
    "\n",
    "\n",
    "Los algoritmos básicos del álgebra lineal para SEL y FM sirven de apoyo para resolver SEL por bloques. Como se revisó en la nota [3.1.Vectorizacion_BLAS_y_el_uso_del_cache_eficientemente](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/III.computo_matricial/3.1.Vectorizacion_BLAS_y_el_uso_del_cache_eficientemente.ipynb) los *blocking algorithms* son ricos en operaciones de nivel 3 de BLAS, simplifican notación matemática y su escritura ayuda a pensar en algoritmos paralelizables. Una desventaja es la cantidad de memoria RAM que utilizan vs algoritmos que no trabajan por bloques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisaremos algunos métodos basados en FM para resolver SEL por bloques. Ver [liga](https://www.dropbox.com/sh/uikk6wfh1aqoc6m/AACddaJWDlHa6hMxgdy5DCVza?dl=0) para revisión de los métodos iterativos: Jacobi y Gauss-Seidel para resolver SEL no por bloques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación por bloque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método consiste en eliminar un subconjunto de variables y resolver un sistema más pequeño. Si la submatriz asociada a este sistema más pequeño puede ser factorizada con alguno de los algoritmos para SEL o FM anteriores entonces este método puede tener más eficiencia que uno que no trabaja por bloques.\n",
    "\n",
    "Considérese un sistema de la forma: $Ax=b$ escrito como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{l}\n",
    "\\left[ \\begin{array}{cc}\n",
    "A_{11} & A_{12}\\\\\n",
    "A_{21} & A_{22}\n",
    "\\end{array}\n",
    "\\right] \\cdot \n",
    "\\left[\\begin{array}{cc}\n",
    "x_1\\\\\n",
    "x_2\n",
    "\\end{array}\n",
    "\\right] =\n",
    "\\left[\\begin{array}{cc}\n",
    "b_1\\\\\n",
    "b_2\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con $x_1 \\in \\mathbb{R}^{n_1}, x_2 \\in \\mathbb{R}^{n_2}, A_{11} \\in \\mathbb{R}^{n_1 \\times n_1}, A_{22} \\in \\mathbb{R}^{n_2 \\times n_2}, b_1 \\in \\mathbb{R}^{n_1}, b_2 \\in \\mathbb{R}^{n_2}$.\n",
    "\n",
    "El método de eliminación por bloques consiste en que si $A_{11}$ es invertible, entonces se puede eliminar $x_1$ de las ecuaciones como sigue:\n",
    "\n",
    "* De la primer ecuación por bloques: $A_{11}x_1 + A_{12}x_2 = b_1$ se obtiene: $x_1 = A_{11}^{-1}(b_1-A_{12}x_2)$.\n",
    "\n",
    "* Sustituyendo esta relación en la segunda ecuación por bloques obtenemos la ecuación reducida: $(A_{22}-A_{21}A_{11}^{-1}A_{12})x_2 = b_2 - A_{21}A_{11}^{-1}b1$.\n",
    "\n",
    "**Obs:** estas dos ecuaciones anteriores son equivalentes al sistema original $Ax=b$. La matriz $A_{22}-A_{21}A_{11}^{-1}A_{12}$ se le nombra **complemento de Schur** del bloque $A_{11}$ en $A$, esto es: $S = A_{22}-A_{21}A_{11}^{-1}A_{12}$. Se tiene la propiedad siguiente: $S$ es no singular si y sólo si $A$ es no singular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior el método de eliminación por bloque consiste: \n",
    "\n",
    "**Algoritmo**\n",
    "\n",
    "Sean $A$ y $A_{11}$ no singulares. \n",
    "\n",
    "1) Calcular $A_{11}^{-1}A_{12}$ y $A_{11}^{-1}b_1$ teniendo cuidado en **no** calcular la inversa sino un sistema de ecuaciones lineales.\n",
    "\n",
    "2) Calcular el complemento de Schur del bloque $A_{11}$ en $A$: $S = A_{22}-A_{21}A_{11}^{-1}A_{12}$. Calcular $ \\hat{b} = b_2-A_{21}A_{11}^{-1}b_1$.\n",
    "\n",
    "3) Resolver $Sx_2 = \\hat{b}$.\n",
    "\n",
    "4) Resolver $A_{11}x_1 = b_1-A_{12}x_2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de factor solve consiste en expresar a la matriz del sistema $Ax = b$ como un producto de la forma: $A = A_1A_2 \\cdots A_k$. Si $A$ es no singular entonces: $x = A^{-1}b = A_k^{-1}A_{k-1}^{-1} \\cdots A_1^{-1}b$.\n",
    "\n",
    "De esta forma, $x$ puede calcularse de \"derecha a izquierda\":\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "z_1&:=A_1^{-1}b \\\\\n",
    "z_2&:=A_2^{-1}z_1 &= A_2^{-1}A_1^{-1}b \\\\\n",
    "\\vdots \\\\\n",
    "z_{k-1}&:=A_{k-1}^{-1}z_{k-2} &= A_{k-1}^{-1} \\cdots A_1^{-1}b \\\\\n",
    "x &:=A_k^{-1}z_{k-1} &= A_k^{-1} \\cdot A_{k-1}^{-1} \\cdots A_1^{-1}b\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sustitución hacia delante por bloques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos directos o basados en factorizaciones matriciales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos directos encuentran **sistemas de ecuaciones equivalentes** a partir de operaciones básicas del álgebra lineal. **Obs:** dos sistemas de ecuaciones lineales son equivalentes si tienen el mismo conjunto solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "*  G. H. Golub, C. F. Van Loan, Matrix Computations, John Hopkins University Press, 2013.\n",
    "\n",
    "* [3.1.Vectorizacion_BLAS_y_el_uso_del_cache_eficientemente](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/III.computo_matricial/3.1.Vectorizacion_BLAS_y_el_uso_del_cache_eficientemente.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
