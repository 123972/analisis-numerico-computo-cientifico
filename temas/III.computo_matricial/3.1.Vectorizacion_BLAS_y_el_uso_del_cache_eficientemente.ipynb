{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notas para contenedor de docker:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comando de docker para ejecución de la nota de forma local:\n",
    "\n",
    "nota: cambiar `<ruta a mi directorio>` por la ruta de directorio que se desea mapear a `/datos` dentro del contenedor de docker.\n",
    "\n",
    "```\n",
    "docker run --rm -v <ruta a mi directorio>:/datos --cap-add SYS_ADMIN --privileged --name jupyterlab-numerical -p 8888:8888 -d palmoreck/jupyterlab_numerical:1.1.0\n",
    "```\n",
    "\n",
    "password para jupyterlab: `qwerty`\n",
    "\n",
    "Detener el contenedor de docker:\n",
    "\n",
    "```\n",
    "docker stop jupyterlab_numerical\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentación de la imagen de docker `palmoreck/jupyterlab_numerical:1.1.0` en [liga](https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/numerical)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para ejecutar el comando de linux [perf](https://github.com/torvalds/linux/tree/master/tools/perf), que se revisará en esta nota, obsérvese que es necesario correr el contenedor de docker descrito antes con las *flags* `--cap-add SYS_ADMIN` y `--privileged`. Además, sólo es posible obtener las métricas descritas en esta nota vía `perf` con un host que tenga un sistema operativo ubuntu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga](https://www.dropbox.com/s/fyqwiqasqaa3wlt/3.1.1.Multiplicacion_de_matrices_y_estructura_de_datos.pdf?dl=0), [liga2](https://www.dropbox.com/s/l4hq45rj860ql9f/3.1.2.Localidad_y_vectorizacion.Analisis_del_error_en_computos_matriciales_basicos.pdf?dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 El cómputo matricial y el álgebra lineal. Vectorización, BLAS y el uso del caché eficientemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cómputo matricial está construído sobre una jerarquía de operaciones del álgebra lineal:\n",
    "\n",
    "* Productos punto involucran operaciones escalares de suma y multiplicación (nivel BLAS 1).\n",
    "\n",
    "* La multiplicación matriz-vector está hecha de productos punto (nivel BLAS 2).\n",
    "\n",
    "* La multiplicación matriz-matriz utiliza colecciones de productos matriz-vector (nivel BLAS 3).\n",
    "\n",
    "Las operaciones anteriores se describen en el álgebra lineal con la teoría de espacios vectoriales pero también es posible describirlas en una forma algorítmica. Ambas descripciones se complementan una a la otra.\n",
    "\n",
    "Manejaremos nombres que en el [Linear Algebra Package: LAPACK](http://www.netlib.org/lapack/explore-html/dir_fa94b7b114d387a7a8beb2e3e22bf78d.html) son utilizados para denotar operaciones con escalares, vectores o matrices. Ver [ Reference-LAPACK / lapack](https://github.com/Reference-LAPACK/lapack) para su github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nivel 1 de BLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operación del producto interno estándar o producto punto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos $x,y \\in \\mathbb{R}^n$. El producto punto entre $x$ y $y$ es $c = x^Ty = \\displaystyle \\sum_{i=1}^n x_iy_i$. \n",
    "\n",
    "**Ejemplo y algoritmo del producto punto:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "n=5\n",
    "x=[-1]*n\n",
    "y=[1.5]*n\n",
    "\n",
    "for i in range(n):\n",
    "    c += x[i]*y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:**\n",
    "\n",
    "* El producto punto de dos $n$-vectores involucran $n$ multiplicaciones y $n$ sumas para un total de $2n$ operaciones o [floating point operations per second](https://en.wikipedia.org/wiki/FLOPS) (flops)\\*. Usamos la notación $\\mathcal{O}(\\cdot)$ para escribir que el producto punto es $\\mathcal{O}(n)$ y se lee \"de orden $n$ o proporcional a $n$\" para indicar que la **cantidad de trabajo** tiene un comportamiento **lineal** con la dimensión $n$. También tal cantidad de trabajo opera sobre una **cantidad lineal de datos**.\n",
    "\n",
    "\n",
    "\\*Los *flops* que realiza un algoritmo es una forma de cuantificar el volumen de trabajo asociado con un cálculo. Un *flop* es una operación de punto flotante: suma, multiplicación o división. Por ejemplo, en la línea:\n",
    "\n",
    "```\n",
    "C[i][j] = C[i][j] + A[i][k]*B[k][j]\n",
    "```\n",
    "\n",
    "se realizan $2$ *flops*. Los flops sólo representan una componente para categorizar a los algoritmos de acuerdo al trabajo que realizan, otras componentes son la transferencia o movimientos de datos, *data movement/motion*, ejecución secuencial o en paralelo y el *data locality* y *data reuse* que realizan.\n",
    "\n",
    "\n",
    "* En LAPACK encontramos [sdot](http://www.netlib.org/lapack/explore-html/d0/d16/sdot_8f.html), [ddot](http://www.netlib.org/lapack/explore-html/d5/df6/ddot_8f.html), [cdotu](http://www.netlib.org/lapack/explore-html/d7/d7b/cdotu_8f.html) y [zdotu](http://www.netlib.org/lapack/explore-html/db/d2d/zdotu_8f.html) para descripción de las funciones/subrutinas escritas en [Fortran](https://en.wikipedia.org/wiki/Fortran) del producto punto en los casos de precisión simple, doble o números complejos respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operación **saxpy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos $\\alpha \\in \\mathbb{R}, x,y \\in \\mathbb{R}^n$. El nombre lo recibe por *scalar alpha x plus y*. En LAPACK [saxpy](http://www.netlib.org/lapack/explore-html/d8/daf/saxpy_8f.html) se escribe en forma *update*:\n",
    "\n",
    "$$y=\\alpha x + y \\therefore y_i = \\alpha x_i + y_i \\forall i=1,...,n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** \n",
    "\n",
    "* El símbolo $=$ no se utiliza como igualdad de expresiones sino para denotar asignación (como en computación al escribir un algoritmo).\n",
    "\n",
    "* También encontramos en LAPACK [caxpy](http://www.netlib.org/lapack/explore-html/de/da2/caxpy_8f.html) o [daxpy](http://www.netlib.org/lapack/explore-html/d9/dcd/daxpy_8f.html) para el caso complejo y para números en doble precisión respectivamente.\n",
    "\n",
    "* Ésta operación realiza un trabajo de $\\mathcal{O}(n)$ sobre una cantidad de datos $\\mathcal{O}(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo y algoritmo de saxpy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=2\n",
    "n=5\n",
    "x=[-2]*n\n",
    "y=[0]*n\n",
    "\n",
    "for i in range(n):\n",
    "    y[i] += alpha*x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-4, -4, -4, -4, -4]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o en una forma *update*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=2\n",
    "n=5\n",
    "x=[-2]*n\n",
    "y=[3,4,-1,0,1]\n",
    "\n",
    "for i in range(n):\n",
    "    y[i] += alpha*x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, -5, -4, -3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentario:** La operación de producto punto y *saxpy* son algoritmos catalogados como de **nivel BLAS 1**, ver [BLAS: Basic Linear Algebra Subprograms](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms). Éstos algoritmos se caracterizan por involucrar una cantidad de trabajo lineal sobre una cantidad lineal de datos. Ver [level 1](http://www.netlib.org/blas/#_level_1) para más ejemplos de este tipo de algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nivel 2 de BLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplicación matriz-vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos $A \\in \\mathbb{R}^{m \\times n}, x \\in \\mathbb{R}^n, y \\in \\mathbb{R}^m$. La operación $y = y + Ax$ es una operación *generalizada* saxpy, por ello se denomina **gaxpy** pero en LAPACK podemos encontrarla con nombres como [sgemv](http://www.netlib.org/lapack/explore-html/db/d58/sgemv_8f.html), [dgemv](http://www.netlib.org/lapack/explore-html/dc/da8/dgemv_8f.html), [cgemv](http://www.netlib.org/lapack/explore-html/d4/d8a/cgemv_8f.html) o [zgemv](http://www.netlib.org/lapack/explore-html/db/d40/zgemv_8f.html) para los casos de precisión simple, doble o números complejos respectivamente. Hay diferentes formas de visualizar y escribir el algoritmo de multiplicación matriz-vector. Por ejemplo para una matriz $A$ con entradas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2\n",
    "n=5\n",
    "A=[[1.2]*n if i%2==0 else [1]*n for i in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.2, 1.2, 1.2, 1.2, 1.2], [1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1][n-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se tiene:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -) Algoritmo gaxpy *row oriented*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[2]*n\n",
    "y=[0]*m\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        y[i]+=A[i][j]*x[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.0, 10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $y$ tiene valores distintos de $0$, se realiza un *update*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[2]*n\n",
    "y=[-1]*m\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        y[i]+=A[i][j]*x[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.0, 9]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* En la versión *row oriented* del algoritmo *gaxpy*, el **inner loop** realiza **productos punto** entre el $i$-ésimo renglón de $A$ y el vector $x$. Se realizan $m$ productos punto $A[i,:]^Tx$:\n",
    "\n",
    "```\n",
    "for i in range(m)\n",
    "    y[i]+=A[i,:]*x #producto punto\n",
    "    \n",
    "```\n",
    "\n",
    "donde: $A[i,:]$ es el $i$-ésimo renglón de $A$. Así podemos reescribir de forma más compacta este algoritmo.\n",
    "\n",
    "* Obsérvese que el acceso a la matriz $A$ del algoritmo *gaxpy row oriented* es **por renglón**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puede escribirse al algoritmo *gaxpy* en una forma orientada por columnas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -) Algoritmo gaxpy *column oriented*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo ayuda a visualizar al producto matriz-vector como una combinación lineal de las columnas de $A$:\n",
    "\n",
    "$$Ax = \\displaystyle \\sum_{j=1}^n A_jx_j$$\n",
    "\n",
    "con $A_j$ la $j$-ésima columna de $A$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[2]*n\n",
    "y=[0]*m\n",
    "for j in range(n):\n",
    "    for i in range(m):\n",
    "        y[i]+=A[i][j]*x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.0, 10]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* El algoritmo de multiplicación matriz-vector (versión *row* o *column* oriented) involucra $\\mathcal{O}(mn)$ operaciones o una cantidad **cuadrática** de trabajo, que podemos entender como \"si duplicamos cada dimensión de $A$ entonces la cantidad de trabajo se incrementa por un factor de $4$\". Tal número de operaciones trabajan sobre una matriz o sobre una cantidad **cuadrática** de datos. A los algoritmos que realizan una cantidad cuadrática de trabajo sobre una cantidad cuadrática de datos se les cataloga de **nivel BLAS 2**. Ver [level 2](http://www.netlib.org/blas/#_level_2) para más ejemplos de algoritmos en el álgebra lineal en esta categoría.\n",
    "\n",
    "* En el algoritmo *gaxpy column oriented* el acceso a la matriz $A$ es por columna.\n",
    "\n",
    "* La versión *column oriented* se puede analizar desde el punto de vista puramente algorítmico como un intercambio entre las líneas con los índices $i$ y $j$ de cada *loop* y un acceso a los datos de la matriz por columna. O bien, se puede analizar desde el álgebra lineal indicando que el vector $y$ está en el **espacio generado** por las columnas de $A$ y cuyas coordenadas son dadas por las entradas del vector $x$:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/6a2b7rjs4a71sni/combinacion_lineal_columnas_A.png?dl=0\" heigth=\"700\" width=\"700\">\n",
    "\n",
    "Una ejemplo de visualización del espacio generado por las columnas de $A \\in \\mathbb{R}^{3 \\times 2}$, llamado **rango o imagen** de $A$, $Im(A)$, es el siguiente:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/zkbhzv9a2jiw11b/espacio_generado_columnas_de_A.png?dl=0\" heigth=\"400\" width=\"400\">\n",
    "\n",
    "En este dibujo los vectores $b, r(x) \\in \\mathbb{R}^3$ no están en $Im(A) \\subset \\mathbb{R}^3$ pero $Ax$ en azul sí. $Im(A)$ en el dibujo es un plano en el espacio $\\mathbb{R}^3$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obsérvese que el **inner loop** de la versión *column oriented* en *gaxpy* es un **saxpy** en la que el escalar está dado por una entrada de $x$. Esto lo podemos escribir de forma explícita definiendo $A[:,j]$ a la $j$-ésima columna de $A$ por lo que $A = [A[:,1] | A[:,2] | \\dots | A[:,n]]$, entonces:\n",
    "\n",
    "```\n",
    "for j in range(n)\n",
    "    y+=A[:,j] * x[j]\n",
    " \n",
    "```\n",
    "\n",
    "sin embargo como hemos visto en Python con su implementación más común CPython, no es posible realizar tal indexado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-93f449af9194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "x=[2]*n\n",
    "y=[0]*m\n",
    "for j in range(n):\n",
    "    y+=A[:,j]*x[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a menos que incorporemos alguna paquetería que permita la **vectorización** y el uso de índices para extracción de columnas (o renglones) de $A$. Entre las razones que encontramos en Python el no soporte para la vectorización está que el [bytecode](https://en.wikipedia.org/wiki/Bytecode) de Python no está optimizado para vectorización. Un ejemplo de un paquete que permite realizar operaciones de forma vectorizada es [numpy](https://numpy.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2*np.ones(n)\n",
    "y = np.zeros(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[1.2,1.2,1.2,1.2,1.2],[1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2, 1.2, 1.2, 1.2, 1.2],\n",
       "       [1. , 1. , 1. , 1. , 1. ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(n):\n",
    "    y+=A[:,j]*x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12., 10.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo, el algoritmo *gaxpy row oriented* puede escribirse de forma más compacta haciendo uso de la definición de producto punto estándar: $x^Ty$ para dos vectores columna $x$ y $y$. En el caso de una matriz $A$ se tiene:\n",
    "\n",
    "```\n",
    "for i=1:m\n",
    "    y[i]+=A[i,:]^T*x\n",
    "```\n",
    "\n",
    "donde: $A[i,:]$ es el $i$-ésimo renglón de $A$. En Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2*np.ones(n)\n",
    "y = np.zeros(m)\n",
    "A=np.array([[1.2,1.2,1.2,1.2,1.2],[1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(m):\n",
    "    y[i]+=A[i,:].dot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12., 10.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en donde se utilizó la función [numpy.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) de *numpy*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* La vectorización como se describe en [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb), es una herramienta que tenemos a nuestra disposición para escribir programas de alto rendimiento. La vectorización incrementa\\* el número de instrucciones por ciclo [IPC](https://en.wikipedia.org/wiki/Instructions_per_cycle) para procesadores que soportan el Single Instruction Multiple Data (SIMD) que encontramos en la taxonomía de Flynn (ver [liga](https://en.wikipedia.org/wiki/Flynn%27s_taxonomy)). Como ejemplo de tales procesadores están los procesadores vectoriales o en arreglo, ver [liga](https://en.wikipedia.org/wiki/Vector_processor). Obsérvese en [liga](https://github.com/numpy/numpy/blob/master/numpy/core/src/umath/simd.inc.src) que `numpy` soporta tales operaciones.\n",
    "\n",
    "\\*El incremento en IPC vía la vectorización se enfoca a que las instrucciones tiendan a completar trabajo **útil** por ciclo pues podría darse la situación en la que se tiene: *a high rate of instructions, but a low rate of actual work completed*. Recuérdese que un ciclo involucra los pasos de leer una instrucción, determinar acciones a realizar por tal instrucción y ejecutar las acciones, ver [liga](https://en.wikipedia.org/wiki/Instruction_cycle).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Perf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Linux existe la herramienta [perf](https://github.com/torvalds/linux/tree/master/tools/perf) que nos ayuda a calcular métricas de desempeño de la CPU o de los cores. Para la ejecución de los siguientes ejemplos es **indispensable** correr el contenedor de docker descrito al inicio de la nota en un sistema ubuntu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo de cálculo de la norma $2$ al cuadrado de un vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting norm_square.py\n"
     ]
    }
   ],
   "source": [
    "%%file norm_square.py\n",
    "n=10**5\n",
    "vector=list(range(n))\n",
    "norm=0\n",
    "for v in vector:\n",
    "    norm+=v*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 norm_square.py' (20 runs):\n",
      "\n",
      "         112969642      cycles                                                        ( +-  0.36% )\n",
      "         217301216      instructions              #    1.92  insn per cycle           ( +-  0.73% )\n",
      "           1137719      cache-references                                              ( +-  0.92% )\n",
      "             58733      cache-misses              #    5.162 % of all cache refs      ( +-  2.07% )\n",
      "\n",
      "       0.030025947 seconds time elapsed                                          ( +-  1.22% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 20 python3 norm_square.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* Con `perf` se repiten las mediciones utilizando la *flag* `-r`. Con la *flag* `-e` se enlistan las métricas a calcular. `-S` llama a [sync](http://man7.org/linux/man-pages/man2/sync.2.html) antes de iniciar la ejecución del programa.\n",
    "\n",
    "* En el ejemplo anterior además de los ciclos e instrucciones se calculan los *cache references* y los *cache misses*. Ver [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb) para definiciones de *cache references* y *misses*. Esencialmente el sistema de memoria buscó el número que aparece en *cache-references* por datos o instrucciones en el caché y de éstas búsquedas, en *cache-misses*, se repora el número (y porcentaje) de búsquedas fallidas que no estuvieron en memoria. \n",
    "\n",
    "* Un factor que incrementa el número de *cache-misses* es la fragmentación de datos, ver [Fragmentation](https://en.wikipedia.org/wiki/Fragmentation_(computing)). La fragmentación incrementa el número de transferencias de memoria hacia la CPU y además imposibilita la vectorización porque el caché no está lleno. El caché puede llenarse sólo al tener bloques contiguos de memoria alojados para los datos (recuérdese que la interconexión o *bus* sólo puede mover *chunks* de memoria contigua, ver [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb)). Python en su implementación común CPython, tiene **data fragmentation** por ejemplo al usar listas. Las listas de Python alojan locaciones donde se pueden encontrar los datos y no los datos en sí. Al utilizar tales estructuras para operaciones matriciales el *runtime* de Python debe realizar *lookups* por índices y al no encontrarse de forma contigua los datos, el *overhead* en la transferencia de datos es mayor lo que causa que se tengan mayor número de *cache-misses* y que los cores tengan que esperar hasta que los datos estén disponibles en el caché.\n",
    "\n",
    "* Obsérvese que se reporta el IPC al lado de *instructions* con nombre *insn per cycle*. Un alto IPC indica una alta transferencia de instrucciones de la unidad de memoria hacia la unidad de cómputo y un menor IPC indica más **stall cycles**, ver [pipeline stall](https://en.wikipedia.org/wiki/Pipeline_stall). Sin embargo como se mencionó antes, se debe evaluar si *a high rate of instructions* indica un *high rate of actual work completed* (p.ej. un *loop* tiene una alta tasa de IPC pero no siempre se realiza trabajo útil). Ver sección *CPU statistics* en la [liga](http://www.brendangregg.com/perf.html). `perf` también tiene una métrica para medir el número de ciclos que se utilizaron para esperar a ejecutar instrucciones (los cores están *stalled*). Las métricas son: `stalled-cycles-frontend` y `stalled-cycles-backend`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos obtener las estadísticas por core. Obsérvese que la salida anterior de `perf` calculó el IPC a partir del número de instrucciones y ciclos ahí reportados. El mismo cálculo se realiza a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (20 runs):\n",
      "\n",
      "S0-C0           2          111124270      cycles                                                      \n",
      "S0-C0           2          214054021      instructions              #    1.93  insn per cycle         \n",
      "S0-C0           2            1196096      cache-references                                            \n",
      "S0-C0           2              60653      cache-misses              #    5.071 % of all cache refs    \n",
      "S0-C1           2          111521501      cycles                                                      \n",
      "S0-C1           2           26249177      instructions              #    0.24  insn per cycle         \n",
      "S0-C1           2               2337      cache-references                                            \n",
      "S0-C1           2               1379      cache-misses              #   59.007 % of all cache refs    \n",
      "S0-C2           2            1184308      cycles                                                      \n",
      "S0-C2           2             313203      instructions              #    0.26  insn per cycle         \n",
      "S0-C2           2               9650      cache-references                                            \n",
      "S0-C2           2               4572      cache-misses              #   47.378 % of all cache refs    \n",
      "S0-C3           2            1500849      cycles                                                      \n",
      "S0-C3           2             482866      instructions              #    0.32  insn per cycle         \n",
      "S0-C3           2              29157      cache-references                                            \n",
      "S0-C3           2               6797      cache-misses              #   23.312 % of all cache refs    \n",
      "\n",
      "       0.030082184 seconds time elapsed                                          ( +-  0.58% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 20 python3 norm_square.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otras métricas pueden ser obtenidas si ejecutamos `perf` sólo con la *flag* `-r`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 norm_square.py' (20 runs):\n",
      "\n",
      "         30.059631      task-clock (msec)         #    0.994 CPUs utilized            ( +-  1.01% )\n",
      "                 0      context-switches          #    0.008 K/sec                    ( +- 39.74% )\n",
      "                 0      cpu-migrations            #    0.000 K/sec                  \n",
      "              2076      page-faults               #    0.069 M/sec                    ( +-  0.02% )\n",
      "         111057933      cycles                    #    3.695 GHz                      ( +-  0.23% )\n",
      "         214464593      instructions              #    1.93  insn per cycle           ( +-  0.45% )\n",
      "          45107448      branches                  # 1500.599 M/sec                    ( +-  0.52% )\n",
      "            669749      branch-misses             #    1.48% of all branches          ( +-  0.11% )\n",
      "\n",
      "       0.030241277 seconds time elapsed                                          ( +-  1.02% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -r 20 python3 norm_square.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* La métrica de *task-clock* indica cuántos *clock cycles* tomó nuestra tarea y se reporta en milisegundos. Obsérvese que también se indica cuántos CPU's fueron utilizados. En el *output* anterior no es exactamente 1 pues el programa no sólo involucra trabajo de CPU sino también de alojamiento de memoria. \n",
    "\n",
    "* *context-switches* y *cpu-migrations* indican cuánto se detuvo el programa para realizar:\n",
    "\n",
    "    * operaciones relacionadas con el kernel del sistema (por ejemplo I/O).\n",
    "    * ejecución de otras aplicaciones.\n",
    "    * alojamiento de la ejecución en un core distinto (lo que ocasiona que haya movimiento de datos o instrucciones hacia el caché de otro core).\n",
    "    \n",
    "la idea es que nuestro programa tenga un número pequeño de éstas métricas.\n",
    "\n",
    "* *page-faults* se relaciona con el alojamiento de memoria a partir del kernel del sistema operativo. Ocasiona que se detenga la ejecución del programa y por tanto deseamos que ésta métrica no sea muy grande. Ver [Page fault](https://en.wikipedia.org/wiki/Page_fault).\n",
    "\n",
    "* Ver [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb) para el *branching*. Esencialmente interesa que el número de *branch misses* sea pequeño.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos generar la salida anterior por *core*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (20 runs):\n",
      "\n",
      "S0-C0           2          59.699698      cpu-clock (msec)          #    1.911 CPUs utilized          \n",
      "S0-C0           2                  5      context-switches          #    0.084 K/sec                  \n",
      "S0-C0           2                  0      cpu-migrations            #    0.000 K/sec                  \n",
      "S0-C0           2               2074      page-faults               #    0.035 M/sec                  \n",
      "S0-C0           2          114151283      cycles                    #    1.912 GHz                    \n",
      "S0-C0           2          226146639      instructions              #    1.98  insn per cycle         \n",
      "S0-C0           2           47873603      branches                  #  801.907 M/sec                  \n",
      "S0-C0           2             667536      branch-misses             #    1.39% of all branches        \n",
      "S0-C1           2          59.700993      cpu-clock (msec)          #    1.911 CPUs utilized          \n",
      "S0-C1           2                  4      context-switches          #    0.067 K/sec                  \n",
      "S0-C1           2                  0      cpu-migrations            #    0.000 K/sec                  \n",
      "S0-C1           2                  0      page-faults               #    0.000 K/sec                  \n",
      "S0-C1           2             276727      cycles                    #    0.005 GHz                    \n",
      "S0-C1           2              75162      instructions              #    0.27  insn per cycle         \n",
      "S0-C1           2              15164      branches                  #    0.254 M/sec                  \n",
      "S0-C1           2                628      branch-misses             #    4.14% of all branches        \n",
      "S0-C2           2          59.700878      cpu-clock (msec)          #    1.911 CPUs utilized          \n",
      "S0-C2           2                  6      context-switches          #    0.101 K/sec                  \n",
      "S0-C2           2                  0      cpu-migrations            #    0.000 K/sec                  \n",
      "S0-C2           2                  0      page-faults               #    0.000 K/sec                  \n",
      "S0-C2           2            1610430      cycles                    #    0.027 GHz                    \n",
      "S0-C2           2             406556      instructions              #    0.25  insn per cycle         \n",
      "S0-C2           2              87378      branches                  #    1.464 M/sec                  \n",
      "S0-C2           2               2075      branch-misses             #    2.37% of all branches        \n",
      "S0-C3           2          59.722514      cpu-clock (msec)          #    1.912 CPUs utilized          \n",
      "S0-C3           2                 14      context-switches          #    0.234 K/sec                  \n",
      "S0-C3           2                  1      cpu-migrations            #    0.017 K/sec                  \n",
      "S0-C3           2                  0      page-faults               #    0.000 K/sec                  \n",
      "S0-C3           2            1381439      cycles                    #    0.023 GHz                    \n",
      "S0-C3           2             370386      instructions              #    0.27  insn per cycle         \n",
      "S0-C3           2              66333      branches                  #    1.111 M/sec                  \n",
      "S0-C3           2               3825      branch-misses             #    5.77% of all branches        \n",
      "\n",
      "       0.031236297 seconds time elapsed                                          ( +-  2.81% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -r 20 python3 norm_square.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para contrastar las salidas anteriores con un mejor uso del caché y de los *cores* se utiliza a continuación el paquete de `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing norm_square_numpy.py\n"
     ]
    }
   ],
   "source": [
    "%%file norm_square_numpy.py\n",
    "import numpy as np\n",
    "n=10**5\n",
    "vector=np.arange(n)\n",
    "vector.dot(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 norm_square_numpy.py' (20 runs):\n",
      "\n",
      "        2517939029      cycles                                                        ( +-  0.07% )\n",
      "        1287233993      instructions              #    0.51  insn per cycle           ( +-  0.07% )\n",
      "           7472851      cache-references                                              ( +-  0.22% )\n",
      "            403479      cache-misses              #    5.399 % of all cache refs      ( +-  1.80% )\n",
      "\n",
      "       0.139254850 seconds time elapsed                                          ( +-  0.36% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 20 python3 norm_square_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:** \n",
    "\n",
    "* Obsérvese que es **más tardado** este programa para el número $n$ que se está utilizando en comparación con el programa anterior sin vectorizar.\n",
    "\n",
    "* El número de instrucciones es **menor** al reportado anteriormente y parece tener un mayor número $%$ de *cache-misses*. Obsérvese que para este ejemplo es más ilustrativo observar las estadísticas por *core* y realizar conclusiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (20 runs):\n",
      "\n",
      "S0-C0           2          569110059      cycles                                                      \n",
      "S0-C0           2          222173905      instructions              #    0.39  insn per cycle         \n",
      "S0-C0           2              47498      cache-references                                            \n",
      "S0-C0           2              12696      cache-misses              #   26.730 % of all cache refs    \n",
      "S0-C1           2          569620862      cycles                                                      \n",
      "S0-C1           2          223486329      instructions              #    0.39  insn per cycle         \n",
      "S0-C1           2              51512      cache-references                                            \n",
      "S0-C1           2              12984      cache-misses              #   25.206 % of all cache refs    \n",
      "S0-C2           2          569812750      cycles                                                      \n",
      "S0-C2           2          223109158      instructions              #    0.39  insn per cycle         \n",
      "S0-C2           2              44136      cache-references                                            \n",
      "S0-C2           2               9939      cache-misses              #   22.519 % of all cache refs    \n",
      "S0-C3           2          818225184      cycles                                                      \n",
      "S0-C3           2          622681657      instructions              #    0.76  insn per cycle         \n",
      "S0-C3           2            7436355      cache-references                                            \n",
      "S0-C3           2             377443      cache-misses              #    5.076 % of all cache refs    \n",
      "\n",
      "       0.139100270 seconds time elapsed                                          ( +-  0.16% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 20 python3 norm_square_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:** \n",
    "\n",
    "* Se observa que la métrica IPC está más uniforme a través de los cores lo que indica un mejor *load balancing*.\n",
    "\n",
    "* Además, el $\\%$ de *cache-misses* es menor que en el caso no vectorizado a diferencia del *output* anterior que indicaba un mayor $\\%$ de *cache-misses*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos obtener las salidas anteriores de `perf` al usar `numpy`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 norm_square_numpy.py' (20 runs):\n",
      "\n",
      "        658.846611      task-clock (msec)         #    4.733 CPUs utilized            ( +-  0.28% )\n",
      "              1309      context-switches          #    0.002 M/sec                    ( +- 97.65% )\n",
      "                 1      cpu-migrations            #    0.002 K/sec                    ( +- 14.60% )\n",
      "              4755      page-faults               #    0.007 M/sec                    ( +-  0.04% )\n",
      "        2509194053      cycles                    #    3.808 GHz                      ( +-  0.28% )\n",
      "        1288129520      instructions              #    0.51  insn per cycle           ( +-  0.14% )\n",
      "         256581259      branches                  #  389.440 M/sec                    ( +-  0.15% )\n",
      "           6512464      branch-misses             #    2.54% of all branches          ( +-  0.09% )\n",
      "\n",
      "       0.139189866 seconds time elapsed                                          ( +-  0.27% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -r 20 python3 norm_square_numpy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (20 runs):\n",
      "\n",
      "S0-C0           2         280.327176      cpu-clock (msec)          #    1.997 CPUs utilized          \n",
      "S0-C0           2                 48      context-switches          #    0.171 K/sec                  \n",
      "S0-C0           2                  5      cpu-migrations            #    0.018 K/sec                  \n",
      "S0-C0           2                  4      page-faults               #    0.014 K/sec                  \n",
      "S0-C0           2          569732162      cycles                    #    2.032 GHz                    \n",
      "S0-C0           2          222998243      instructions              #    0.39  insn per cycle         \n",
      "S0-C0           2           41820920      branches                  #  149.186 M/sec                  \n",
      "S0-C0           2             761701      branch-misses             #    1.82% of all branches        \n",
      "S0-C1           2         280.362219      cpu-clock (msec)          #    1.997 CPUs utilized          \n",
      "S0-C1           2                 46      context-switches          #    0.164 K/sec                  \n",
      "S0-C1           2                  5      cpu-migrations            #    0.018 K/sec                  \n",
      "S0-C1           2                  0      page-faults               #    0.000 K/sec                  \n",
      "S0-C1           2          595485979      cycles                    #    2.124 GHz                    \n",
      "S0-C1           2          252609982      instructions              #    0.42  insn per cycle         \n",
      "S0-C1           2           47805375      branches                  #  170.513 M/sec                  \n",
      "S0-C1           2             850921      branch-misses             #    1.78% of all branches        \n",
      "S0-C2           2         280.362523      cpu-clock (msec)          #    1.997 CPUs utilized          \n",
      "S0-C2           2                 82      context-switches          #    0.292 K/sec                  \n",
      "S0-C2           2                  2      cpu-migrations            #    0.007 K/sec                  \n",
      "S0-C2           2                  1      page-faults               #    0.004 K/sec                  \n",
      "S0-C2           2          570048514      cycles                    #    2.033 GHz                    \n",
      "S0-C2           2          221858305      instructions              #    0.39  insn per cycle         \n",
      "S0-C2           2           41692943      branches                  #  148.711 M/sec                  \n",
      "S0-C2           2             763207      branch-misses             #    1.83% of all branches        \n",
      "S0-C3           2         280.375634      cpu-clock (msec)          #    1.997 CPUs utilized          \n",
      "S0-C3           2                 59      context-switches          #    0.210 K/sec                  \n",
      "S0-C3           2                  5      cpu-migrations            #    0.018 K/sec                  \n",
      "S0-C3           2               4744      page-faults               #    0.017 M/sec                  \n",
      "S0-C3           2          832271740      cycles                    #    2.968 GHz                    \n",
      "S0-C3           2          625657253      instructions              #    0.75  insn per cycle         \n",
      "S0-C3           2          132103906      branches                  #  471.168 M/sec                  \n",
      "S0-C3           2            4270632      branch-misses             #    3.23% of all branches        \n",
      "\n",
      "       0.140398443 seconds time elapsed                                          ( +-  0.23% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -r 20 python3 norm_square_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresando al algoritmo *gaxpy column oriented*...\n",
    "\n",
    "Utilizaremos `perf` en lo que sigue para evaluar las métricas de IPC, *cache-references*, *cache-misses* y medir el tiempo de ejecución. Además, esto permitirá comparar los tiempos de ejecución del algoritmo *gaxpy* (nivel BLAS 2), con vectorización y sin vectorización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos una matriz $A \\in \\mathbb{R}^{10^4 \\times 10^4}$ con entradas pseudoaleatorias. **No se sugiere ejecutar los siguientes ejemplos para máquinas que tengan menos de 8gb de memoria**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "m=10**4\n",
    "n=10**4\n",
    "A=np.random.rand(m,n)\n",
    "file='A.txt'\n",
    "np.savetxt(file,A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arhivo sin vectorizar y utilizando listas para construir a la matriz y a los vectores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_vector.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_vector.py\n",
    "m=10**4\n",
    "n=10**4\n",
    "x=[2.5]*n\n",
    "y=[0]*m\n",
    "A = []\n",
    "file='A.txt'\n",
    "with open(file,'r') as f:\n",
    "    for l in f:\n",
    "        A.append([float(k) for k in l.replace('\\n','').replace(' ',',').split(',')])      \n",
    "for j in range(n):\n",
    "    for i in range(m):\n",
    "        y[i]+=A[i][j]*x[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo vectorizando con numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_vector_numpy.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_vector_numpy.py\n",
    "import numpy as np\n",
    "m=10**4\n",
    "n=10**4\n",
    "x = 2.5*np.ones(n)\n",
    "y = np.zeros(m)\n",
    "file='A.txt'\n",
    "A = np.loadtxt(file)\n",
    "for j in np.arange(n):\n",
    "    y+=A[:,j]*x[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso no vectorizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 mult_matrix_vector.py' (2 runs):\n",
      "\n",
      "      253636293168      cycles                                                        ( +-  2.57% )\n",
      "      612211438956      instructions              #    2.41  insn per cycle           ( +-  0.80% )\n",
      "        1021919811      cache-references                                              ( +-  0.04% )\n",
      "         127117602      cache-misses              #   12.439 % of all cache refs      ( +-  0.56% )\n",
      "\n",
      "      63.613271875 seconds time elapsed                                          ( +-  2.51% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas por core:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "S0-C0           2          343119167      cycles                                                      \n",
      "S0-C0           2           98370360      instructions              #    0.29  insn per cycle         \n",
      "S0-C0           2            5840329      cache-references                                            \n",
      "S0-C0           2            1414327      cache-misses              #   24.217 % of all cache refs    \n",
      "S0-C1           2          528971112      cycles                                                      \n",
      "S0-C1           2          258058789      instructions              #    0.49  insn per cycle         \n",
      "S0-C1           2            8051433      cache-references                                            \n",
      "S0-C1           2            2969543      cache-misses              #   36.882 % of all cache refs    \n",
      "S0-C2           2        69421643702      cycles                                                      \n",
      "S0-C2           2       146665430983      instructions              #    2.11  insn per cycle         \n",
      "S0-C2           2          510280653      cache-references                                            \n",
      "S0-C2           2           75086567      cache-misses              #   14.715 % of all cache refs    \n",
      "S0-C3           2       182606290800      cycles                                                      \n",
      "S0-C3           2       459364489796      instructions              #    2.52  insn per cycle         \n",
      "S0-C3           2          530605786      cache-references                                            \n",
      "S0-C3           2           60288944      cache-misses              #   11.362 % of all cache refs    \n",
      "\n",
      "      61.854651367 seconds time elapsed                                          ( +-  0.61% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso vectorizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 mult_matrix_vector_numpy.py' (2 runs):\n",
      "\n",
      "      243217588216      cycles                                                        ( +-  1.27% )\n",
      "      598729874148      instructions              #    2.46  insn per cycle           ( +-  0.42% )\n",
      "         662503038      cache-references                                              ( +-  1.39% )\n",
      "          95202746      cache-misses              #   14.370 % of all cache refs      ( +-  0.97% )\n",
      "\n",
      "      60.488697485 seconds time elapsed                                          ( +-  1.26% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector_numpy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "S0-C0           2         2664298731      cycles                                                      \n",
      "S0-C0           2         1964872569      instructions              #    0.74  insn per cycle         \n",
      "S0-C0           2           10837071      cache-references                                            \n",
      "S0-C0           2            4435770      cache-misses              #   40.931 % of all cache refs    \n",
      "S0-C1           2          964636936      cycles                                                      \n",
      "S0-C1           2          320553130      instructions              #    0.33  insn per cycle         \n",
      "S0-C1           2            6043601      cache-references                                            \n",
      "S0-C1           2            2799592      cache-misses              #   46.323 % of all cache refs    \n",
      "S0-C2           2         1339127149      cycles                                                      \n",
      "S0-C2           2          935833922      instructions              #    0.70  insn per cycle         \n",
      "S0-C2           2            8451552      cache-references                                            \n",
      "S0-C2           2            2653359      cache-misses              #   31.395 % of all cache refs    \n",
      "S0-C3           2       305074104555      cycles                                                      \n",
      "S0-C3           2       606515058789      instructions              #    1.99  insn per cycle         \n",
      "S0-C3           2          661941985      cache-references                                            \n",
      "S0-C3           2           94553002      cache-misses              #   14.284 % of all cache refs    \n",
      "\n",
      "      61.588377630 seconds time elapsed                                          ( +-  2.84% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* No se observa una gran diferencia entre el caso vectorizado y no vectorizado salvo que en el caso vectorizando se tiene un $\\%$ mayor de *cache-misses*. Sería conveniente realizar más repeticiones de esta misma operación o con diferentes operaciones de nivel 2 BLAS para realizar conclusiones más sólidas. Ver [level 2](http://www.netlib.org/blas/#_level_2) para más ejemplos de algoritmos en el álgebra lineal en esta categoría.\n",
    "\n",
    "* Otra opción que se tiene es utilizar la siguiente implementación ya que `numpy` soporta operaciones del tipo matriz-vector sin necesidad de utilizar un *for loop*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_vector_numpy_2.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_vector_numpy_2.py\n",
    "import numpy as np\n",
    "m=10**4\n",
    "n=10**4\n",
    "x = 2.5*np.ones(n)\n",
    "y = np.zeros(m)\n",
    "file='A.txt'\n",
    "A = np.loadtxt(file)\n",
    "y=A@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 mult_matrix_vector_numpy_2.py' (2 runs):\n",
      "\n",
      "      243195411750      cycles                                                        ( +-  1.00% )\n",
      "      602205576232      instructions              #    2.48  insn per cycle           ( +-  0.23% )\n",
      "         553013970      cache-references                                              ( +-  0.65% )\n",
      "          87666482      cache-misses              #   15.852 % of all cache refs      ( +-  0.47% )\n",
      "\n",
      "      60.022411249 seconds time elapsed                                          ( +-  1.06% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector_numpy_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "S0-C0           2         5768543148      cycles                                                      \n",
      "S0-C0           2         2652993320      instructions              #    0.46  insn per cycle         \n",
      "S0-C0           2           13669781      cache-references                                            \n",
      "S0-C0           2            5700218      cache-misses              #   41.699 % of all cache refs    \n",
      "S0-C1           2         1341384457      cycles                                                      \n",
      "S0-C1           2          397736414      instructions              #    0.30  insn per cycle         \n",
      "S0-C1           2            7366652      cache-references                                            \n",
      "S0-C1           2            3922098      cache-misses              #   53.241 % of all cache refs    \n",
      "S0-C2           2         1434196155      cycles                                                      \n",
      "S0-C2           2          399070532      instructions              #    0.28  insn per cycle         \n",
      "S0-C2           2            8991081      cache-references                                            \n",
      "S0-C2           2            4214025      cache-misses              #   46.869 % of all cache refs    \n",
      "S0-C3           2       250722975414      cycles                                                      \n",
      "S0-C3           2       598321598562      instructions              #    2.39  insn per cycle         \n",
      "S0-C3           2          553229600      cache-references                                            \n",
      "S0-C3           2           83582036      cache-misses              #   15.108 % of all cache refs    \n",
      "\n",
      "      59.291536937 seconds time elapsed                                          ( +-  0.88% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector_numpy_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O con una versión *gaxpy row oriented***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mult_matrix_vector_numpy_row_oriented.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_vector_numpy_row_oriented.py\n",
    "import numpy as np\n",
    "m=10**4\n",
    "n=10**4\n",
    "x = 2.5*np.ones(n)\n",
    "y = np.zeros(m)\n",
    "file='A.txt'\n",
    "A = np.loadtxt(file)\n",
    "for i in np.arange(m):\n",
    "    y[i]+=A[i,:].dot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 mult_matrix_vector_numpy_row_oriented.py' (2 runs):\n",
      "\n",
      "      240065888790      cycles                                                        ( +-  0.31% )\n",
      "      596676621081      instructions              #    2.49  insn per cycle           ( +-  0.28% )\n",
      "         549617732      cache-references                                              ( +-  0.84% )\n",
      "          87432788      cache-misses              #   15.908 % of all cache refs      ( +-  0.29% )\n",
      "\n",
      "      59.657694617 seconds time elapsed                                          ( +-  0.32% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector_numpy_row_oriented.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "S0-C0           2         2022241353      cycles                                                      \n",
      "S0-C0           2          749567422      instructions              #    0.37  insn per cycle         \n",
      "S0-C0           2            5565741      cache-references                                            \n",
      "S0-C0           2            1418960      cache-misses              #   25.495 % of all cache refs    \n",
      "S0-C1           2          978643966      cycles                                                      \n",
      "S0-C1           2          468796681      instructions              #    0.48  insn per cycle         \n",
      "S0-C1           2            5124516      cache-references                                            \n",
      "S0-C1           2            2519200      cache-misses              #   49.160 % of all cache refs    \n",
      "S0-C2           2         1827829093      cycles                                                      \n",
      "S0-C2           2         1157668329      instructions              #    0.63  insn per cycle         \n",
      "S0-C2           2            7050536      cache-references                                            \n",
      "S0-C2           2            4433714      cache-misses              #   62.885 % of all cache refs    \n",
      "S0-C3           2       253080374948      cycles                                                      \n",
      "S0-C3           2       606973949249      instructions              #    2.40  insn per cycle         \n",
      "S0-C3           2          559644223      cache-references                                            \n",
      "S0-C3           2           87449250      cache-misses              #   15.626 % of all cache refs    \n",
      "\n",
      "      60.039748269 seconds time elapsed                                          ( +-  1.13% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector_numpy_row_oriented.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nivel 3 de BLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otras comparaciones que podemos realizar entre los tiempos de ejecución, *cache-references* y *cache-misses* utilizando la versión vectorizada y no vectorizada, es con el algoritmo de multiplicación de matrices $C = C + AB$ con $A \\in \\mathbb{R}^{m \\times r}, B \\in \\mathbb{R}^{r \\times n}, C \\in \\mathbb{R}^{m \\times n}$. Este algoritmo se cataloga como de nivel 3 de BLAS pues realiza una **cantidad de trabajo cúbica** sobre una **cantidad cuadrática de datos**. Ver [level 3](http://www.netlib.org/blas/#_level_3) para más ejemplos de algoritmos en el álgebra lineal en esta categoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplicación de matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En LAPACK encontramos al algoritmo de multiplicación matricial con nombres como [sgemm](http://www.netlib.org/lapack/explore-html/d4/de2/sgemm_8f.html), [dgemm](http://www.netlib.org/lapack/explore-html/d7/d2b/dgemm_8f.html), [cgemm](http://www.netlib.org/lapack/explore-html/d6/d5b/cgemm_8f.html) y [zgemm](http://www.netlib.org/lapack/explore-html/d7/d76/zgemm_8f.html) para los casos de precisión simple, doble o números complejos respectivamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de multiplicación de matrices puede escribirse en diferentes versiones. Por ejemplo la versión  **i,j,k** es:\n",
    "\n",
    "```\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        for k in range(r):\n",
    "            C[i][j]+=A[i][k]*B[k][j]\n",
    "    \n",
    "```\n",
    "\n",
    "y la versión **j,k,i** es:\n",
    "\n",
    "```\n",
    "for j in range(n):\n",
    "    for k in range(r):\n",
    "        for i in range(m):\n",
    "            C[i][j]+=A[i][k]*B[k][j]\n",
    "```\n",
    "\n",
    "**Comentarios:**\n",
    "\n",
    "* Cualquiera de las versiones (hay $3!$ de ellas) involucra una cantidad de trabajo del orden $\\mathcal{O}(mnr)$, la cual es cúbica. Es posible interpretar ésta cantidad de trabajo con una frase del tipo \"si duplicamos cada dimensión de $A$ entonces la cantidad de trabajo se incrementa por un factor de $8$\".\n",
    "\n",
    "* Distintas versiones tienen distinto patrón de acceso a los datos de $A, B$ y $C$. Por ejemplo, para la variante **i,j,k** el **inner loop** realiza un producto punto que requiere acceso a renglones de $A$ y columnas de $B$ en una forma izquierda-derecha y abajo-arriba respectivamente. La variante **j,k,i** involucra una operación *saxpy* en el **inner loop** y acceso por columnas a la matriz $C$ y a $A$. Un resúmen de lo anterior se presenta en el siguiente cuadro:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/rw81crmo1b7fjvb/tabla_con_versiones_mult_matrices.png?dl=0\" heigth=\"450\" width=\"450\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre versiones vectorizadas y no vectorizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos matrices $A, B \\in \\mathbb{R}^{10^4 \\times 10^4}$ con entradas pseudoaleatorias. **No se sugiere ejecutar los siguientes ejemplos para máquinas que tengan menos de 8gb de memoria. Si se ejecutó el ejemplo de *gaxpy* de nivel 2 de BLAS, no es necesario volver a ejecutar la siguiente celda para crear a la matriz A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "m=10**4\n",
    "r=10**4\n",
    "\n",
    "A=np.random.rand(m,r)\n",
    "fileA='A.txt'\n",
    "np.savetxt(fileA,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "r=10**4\n",
    "n=10**4\n",
    "\n",
    "B=np.random.rand(r,n)\n",
    "fileB='B.txt'\n",
    "np.savetxt(fileB,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_matrix.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_matrix.py\n",
    "m=10**4\n",
    "r=10**4\n",
    "n=10**4\n",
    "\n",
    "A = []\n",
    "B = []\n",
    "fileA='A.txt'\n",
    "fileB='B.txt'\n",
    "\n",
    "with open(fileA,'r') as f:\n",
    "    for l in f:\n",
    "        A.append([float(k) for k in l.replace('\\n','').replace(' ',',').split(',')]) \n",
    "        \n",
    "with open(fileB,'r') as f:\n",
    "    for l in f:\n",
    "        B.append([float(k) for k in l.replace('\\n','').replace(' ',',').split(',')])  \n",
    "\n",
    "C=[[0]*n for i in range(m)]\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        for k in range(r):\n",
    "            C[i][j]+=A[i][k]*B[k][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_matrix_numpy.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_matrix_numpy.py\n",
    "import numpy as np\n",
    "m=10**4\n",
    "r=10**4\n",
    "n=10**4\n",
    "\n",
    "fileA='A.txt'\n",
    "fileB='B.txt'\n",
    "A = np.loadtxt(fileA)\n",
    "B = np.loadtxt(fileB)\n",
    "C = A@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 1 python3 mult_matrix_matrix.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... 36 min y todavía no terminaba... cambiar a r 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a -e cycles,instructions,cache-references,cache-misses -r 1 python3 mult_matrix_matrix.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "      836044127523      cycles                                                        ( +-  0.57% )\n",
      "     1686463020251      instructions              #    2.02  insn per cycle           ( +-  0.43% )\n",
      "        4086628234      cache-references                                              ( +-  1.72% )\n",
      "         882062956      cache-misses              #   21.584 % of all cache refs      ( +-  4.13% )\n",
      "\n",
      "     130.609360500 seconds time elapsed                                          ( +-  0.66% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_matrix_numpy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "S0-C0           2        89616044167      cycles                                                      \n",
      "S0-C0           2       121446222500      instructions              #    1.36  insn per cycle         \n",
      "S0-C0           2          811435068      cache-references                                            \n",
      "S0-C0           2          194368638      cache-misses              #   23.954 % of all cache refs    \n",
      "S0-C1           2        88898510819      cycles                                                      \n",
      "S0-C1           2       121389910135      instructions              #    1.37  insn per cycle         \n",
      "S0-C1           2          722839867      cache-references                                            \n",
      "S0-C1           2          162558289      cache-misses              #   22.489 % of all cache refs    \n",
      "S0-C2           2       563600069053      cycles                                                      \n",
      "S0-C2           2      1280855473637      instructions              #    2.27  insn per cycle         \n",
      "S0-C2           2         1782304769      cache-references                                            \n",
      "S0-C2           2          317385129      cache-misses              #   17.808 % of all cache refs    \n",
      "S0-C3           2       103452663605      cycles                                                      \n",
      "S0-C3           2       155023368415      instructions              #    1.50  insn per cycle         \n",
      "S0-C3           2          805500520      cache-references                                            \n",
      "S0-C3           2          192465138      cache-misses              #   23.894 % of all cache refs    \n",
      "\n",
      "     131.489034132 seconds time elapsed                                          ( +-  0.71% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_matrix_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras versiones de la multiplicación de matrices apoyándose de las formas (i,j,k), (j,k,i),..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizamos la versión **i,j,k** podemos reescribir la multiplicación de matrices en una forma:\n",
    "\n",
    "```\n",
    "for i in range(m):\n",
    "    for j in range(n)\n",
    "        C[i][j]+= A[i,:].dot(B[:,j])\n",
    "```\n",
    "\n",
    "y hemos vectorizado el *inner loop* para usar productos punto que es una operación nivel 1 de BLAS.\n",
    "\n",
    "Además `numpy` nos provee de funcionalidad para reescribir ésta forma de productos punto en una como sigue:\n",
    "\n",
    "\n",
    "```\n",
    "for i in range(m):\n",
    "    C[i,:]+= A[i,:]@B\n",
    "```\n",
    "\n",
    "**Obs**: obsérvese que en esta reescritura en el loop se realizan $m$ operaciones *gaxpy* de nivel 2. Esta versión como se verá a continuación es más rápida que la que utiliza operaciones de nivel 1 de BLAS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparación de versiones de multiplicación de matrices utilizando nivel 1 vs nivel 2 de BLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos matrices $A, B \\in \\mathbb{R}^{10^3 \\times 10^3}$ pseudoaleatorias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "m=10**3\n",
    "r=10**3\n",
    "\n",
    "A=np.random.rand(m,r)\n",
    "fileA_10_3='A_10_3.txt'\n",
    "np.savetxt(fileA_10_3,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "m=10**3\n",
    "r=10**3\n",
    "\n",
    "B=np.random.rand(m,r)\n",
    "fileB_10_3='B_10_3.txt'\n",
    "np.savetxt(fileB_10_3,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_matrix_numpy_dot_product.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_matrix_numpy_dot_product.py\n",
    "import numpy as np\n",
    "m=10**3\n",
    "n=10**3\n",
    "\n",
    "fileA_10_3='A_10_3.txt'\n",
    "fileB_10_3='B_10_3.txt'\n",
    "A = np.loadtxt(fileA_10_3)\n",
    "B = np.loadtxt(fileB_10_3)\n",
    "C = np.zeros((m,n))\n",
    "for i in np.arange(m):\n",
    "        for j in np.arange(n):\n",
    "                C[i][j]+= A[i,:].dot(B[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (5 runs):\n",
      "\n",
      "       17727880724      cycles                                                        ( +-  2.67% )\n",
      "       31196800089      instructions              #    1.76  insn per cycle           ( +-  0.18% )\n",
      "         174120561      cache-references                                              ( +-  1.57% )\n",
      "          14645042      cache-misses              #    8.411 % of all cache refs      ( +-  8.98% )\n",
      "\n",
      "       3.817488998 seconds time elapsed                                          ( +-  0.55% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a -e cycles,instructions,cache-references,cache-misses -r 5 python3 mult_matrix_matrix_numpy_dot_product.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (5 runs):\n",
      "\n",
      "S0-C0           2          582438322      cycles                                                      \n",
      "S0-C0           2          225885082      instructions              #    0.39  insn per cycle         \n",
      "S0-C0           2             274724      cache-references                                            \n",
      "S0-C0           2             130031      cache-misses              #   47.332 % of all cache refs    \n",
      "S0-C1           2          642407408      cycles                                                      \n",
      "S0-C1           2          272043994      instructions              #    0.42  insn per cycle         \n",
      "S0-C1           2             546749      cache-references                                            \n",
      "S0-C1           2             324188      cache-misses              #   59.294 % of all cache refs    \n",
      "S0-C2           2          596216226      cycles                                                      \n",
      "S0-C2           2          226892804      instructions              #    0.38  insn per cycle         \n",
      "S0-C2           2             446956      cache-references                                            \n",
      "S0-C2           2             184440      cache-misses              #   41.266 % of all cache refs    \n",
      "S0-C3           2        17956845889      cycles                                                      \n",
      "S0-C3           2        30574523485      instructions              #    1.70  insn per cycle         \n",
      "S0-C3           2          185655560      cache-references                                            \n",
      "S0-C3           2           15107439      cache-misses              #    8.137 % of all cache refs    \n",
      "\n",
      "       3.861269417 seconds time elapsed                                          ( +-  0.93% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 5 python3 mult_matrix_matrix_numpy_dot_product.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mult_matrix_matrix_numpy_dot_product_gaxpy.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_matrix_numpy_dot_product_gaxpy.py\n",
    "import numpy as np\n",
    "m=10**3\n",
    "n=10**3\n",
    "fileA_10_3='A_10_3.txt'\n",
    "fileB_10_3='B_10_3.txt'\n",
    "A = np.loadtxt(fileA_10_3)\n",
    "B = np.loadtxt(fileB_10_3)\n",
    "C = np.zeros((m,n))\n",
    "for i in np.arange(m):\n",
    "    C[i,:] = A[i,:]@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (5 runs):\n",
      "\n",
      "       11010075589      cycles                                                        ( +-  0.66% )\n",
      "       14922627515      instructions              #    1.36  insn per cycle           ( +-  0.26% )\n",
      "         142059490      cache-references                                              ( +-  1.24% )\n",
      "           8572872      cache-misses              #    6.035 % of all cache refs      ( +- 11.05% )\n",
      "\n",
      "       1.455285799 seconds time elapsed                                          ( +-  0.44% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a -e cycles,instructions,cache-references,cache-misses -r 5 python3 mult_matrix_matrix_numpy_dot_product_gaxpy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (5 runs):\n",
      "\n",
      "S0-C0           2         1448177294      cycles                                                      \n",
      "S0-C0           2          623468047      instructions              #    0.43  insn per cycle         \n",
      "S0-C0           2           29581790      cache-references                                            \n",
      "S0-C0           2             575180      cache-misses              #    1.944 % of all cache refs    \n",
      "S0-C1           2         1477272782      cycles                                                      \n",
      "S0-C1           2          656096587      instructions              #    0.44  insn per cycle         \n",
      "S0-C1           2           29881953      cache-references                                            \n",
      "S0-C1           2             608210      cache-misses              #    2.035 % of all cache refs    \n",
      "S0-C2           2         1457641798      cycles                                                      \n",
      "S0-C2           2          633875919      instructions              #    0.43  insn per cycle         \n",
      "S0-C2           2           24959423      cache-references                                            \n",
      "S0-C2           2            1281191      cache-misses              #    5.133 % of all cache refs    \n",
      "S0-C3           2         6518413194      cycles                                                      \n",
      "S0-C3           2        12982975813      instructions              #    1.99  insn per cycle         \n",
      "S0-C3           2           53648618      cache-references                                            \n",
      "S0-C3           2            2954550      cache-misses              #    5.507 % of all cache refs    \n",
      "\n",
      "       1.449412595 seconds time elapsed                                          ( +-  0.43% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 5 python3 mult_matrix_matrix_numpy_dot_product_gaxpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* Obsérvese que en las implementaciones anteriores ambas versiones utilizan la vectorización mediante `numpy`.\n",
    "\n",
    "* A continuación se muestra una tabla que presenta el número de *flops* realizados por distintas operaciones del álgebra lineal:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/rvqkokicaqkwrif/tabla_con_flops_para_operaciones_alg_lineal.png?dl=0\" heigth=\"550\" width=\"550\">\n",
    "\n",
    "* Como se observa en la tabla anterior, *gaxpy* (nivel 2 de BLAS) realiza más *flops* que un producto punto. Aún así, los tiempos medidos con `perf` indican que la versión de *gaxpy* es más rápida que la versión con productos punto (nivel 1 de BLAS) para la multiplicación de matrices ya que  aprovecha mejor el *data reuse* y *data locality*. Esto se logra pues *gaxpy* disminuye el número de *cache misses* y por tanto el tráfico hacia y desde el caché, el llamado *data movement/motion*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking algorithms para multiplicación de matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *data reuse* y el *data locality* como se vio en el ejemplo pasado se incrementa al utilizar operaciones de nivel BLAS mayores. También disminuye el *data motion* hacia y desde el caché lo que disminuye el tráfico de datos o *data movement/motion* pues se atiende uno de los cuellos de botella que se revisó en [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb) conocido con el nombre de *bottleneck* de Von Neumann. \n",
    "\n",
    "Por lo anterior hay algoritmos que se diseñan con el objetivo de aprovechar lo más posible el *data reuse* y el *data locality* y se nombran *blocking algorithms*. Entre los *blocking algorithms* encontramos a los que trabajan con matrices por bloques pues son más eficientes al utilizar un nivel $3$ de BLAS. Una matriz $A \\in \\mathbb{R}^{m \\times n}$ por bloques se puede escribir como:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/s77weq74yoi2rfc/matrix_A_by_blocks.png?dl=0\" heigth=\"300\" width=\"300\">\n",
    "\n",
    "donde: $m_1 + \\dots + m_q = m$, $n_1 + \\dots + n_r = n$. Con esta definición se llama a la matriz $A$, una matriz por bloques de tamaño $q \\times r$.\n",
    "\n",
    "**Comentarios:** \n",
    "\n",
    "* Hay que tener en cuenta que trabajar con matrices por bloques utiliza mayor cantidad de memoria que un algoritmo que opera a un nivel escalar esto puede ser benéfico o no dependiendo del problema, máquina o arquitectura en la que se esté trabajando.\n",
    "\n",
    "* Trabajar con *blocking algorithms* permite simplificar notación matemática. También ayudan a implementarlos con cómputo en paralelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunas operaciones en matrices por bloques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las operaciones que son posibles realizar a un nivel por bloques se encuentran:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicación por escalares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{l}\n",
    "\\mu \\left[ \\begin{array}{cc}\n",
    "A_{11} & A_{12}\\\\\n",
    "A_{21} & A_{22}\\\\\n",
    "A_{31} & A_{32}\n",
    "\\end{array}\n",
    "\\right] = \n",
    "\\left[\\begin{array}{cc}\n",
    "\\mu A_{11} & \\mu A_{12}\\\\\n",
    "\\mu A_{21} & \\mu A_{22}\\\\\n",
    "\\mu A_{31} & \\mu A_{32}\n",
    "\\end{array}\n",
    "\\right] \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "con $\\mu \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{l}\n",
    "\\left[ \\begin{array}{cc}\n",
    "A_{11} & A_{12}\\\\\n",
    "A_{21} & A_{22}\\\\\n",
    "A_{31} & A_{32}\n",
    "\\end{array}\n",
    "\\right]^T = \n",
    "\\left[\\begin{array}{ccc}\n",
    "A_{11}^T & A_{21}^T & A_{31}^T\\\\\n",
    "A_{12}^T & A_{22}^T & A_{32}^T\\\\\n",
    "\\end{array}\n",
    "\\right] \n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{l}\n",
    "\\left[ \\begin{array}{cc}\n",
    "A_{11} & A_{12}\\\\\n",
    "A_{21} & A_{22}\\\\\n",
    "A_{31} & A_{32}\n",
    "\\end{array}\n",
    "\\right] + \n",
    "\\left[\\begin{array}{cc}\n",
    "B_{11} & B_{12}\\\\\n",
    "B_{21} & B_{22}\\\\\n",
    "B_{31} & B_{32}\n",
    "\\end{array}\n",
    "\\right] =\n",
    "\\left[\\begin{array}{cc}\n",
    "A_{11} + B_{11} & A_{12} + B_{12}\\\\\n",
    "A_{21} + B_{21} & A_{22} + B_{22}\\\\\n",
    "A_{31} + B_{31} & A_{32} + B_{32}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{l}\n",
    "\\left[ \\begin{array}{cc}\n",
    "A_{11} & A_{12}\\\\\n",
    "A_{21} & A_{22}\\\\\n",
    "A_{31} & A_{32}\n",
    "\\end{array}\n",
    "\\right] \\cdot\n",
    "\\left[\\begin{array}{cc}\n",
    "B_{11} & B_{12}\\\\\n",
    "B_{21} & B_{22}\\\\\n",
    "\\end{array}\n",
    "\\right] =\n",
    "\\left[\\begin{array}{cc}\n",
    "A_{11}B_{11} + A_{12}B_{21} & A_{11}B_{12} + A_{12}B_{22}\\\\\n",
    "A_{21}B_{11} + A_{22}B_{21} & A_{21}B_{12} + A_{22}B_{22}\\\\\n",
    "A_{31}B_{11} + A_{32}B_{21} & A_{31}B_{12} + A_{32}B_{22}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** el número de columnas de los bloques $A_{11}, A_{21}, A_{31}$ deben coincidir con el número de renglones de $B_{11}, B_{12}$. Así como con los bloques $A_{12}, A_{22}, A_{32}$ y $B_{21}, B_{22}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérese que se particionan a las matrices $A, B, C$ como sigue:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/j0p89i19vf5r88k/A_B_C_matrices_by_blocks.png?dl=0\" heigth=\"400\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es, $A,B,C$ son $N \\times N$ matrices por bloques con $\\ell \\times \\ell$ bloques. Entonces, para índices $\\alpha = 1,2,\\dots, N$ y $\\beta = 1,2,\\dots,N$ se tiene que el bloque $\\alpha \\beta$ de $C$ se obtiene: $C_{\\alpha \\beta} = \\displaystyle \\sum_{\\gamma=1}^N A_{\\alpha \\gamma} B_{\\gamma \\beta}$. \n",
    "\n",
    "El algoritmo es:\n",
    "\n",
    "```\n",
    "for alpha in np.arange(N)\n",
    "    i = np.arange((alpha - 1)*l + 1,alpha*l + 1) #hay que revisar si están bien definidos los índices\n",
    "    for beta in np.arange(N)\n",
    "        j = np.arange((beta - 1)*l + 1, beta*l + 1) #hay que revisar si están bien definidos los índices\n",
    "        for gamma in np.arange(N)\n",
    "            k = np.arange((gamma - 1)*l + 1, gamma*l + 1) #hay que revisar si están bien los índices\n",
    "            C[i][:,j]+= A[i][:,k]*B[k][:,j]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:**\n",
    "\n",
    "Implementar multiplicación por bloques en Python y R. Perfilar tal implementación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(fileA)\n",
    "os.remove(fileB)\n",
    "os.remove(fileA_10_3)\n",
    "os.remove(fileB_10_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "* E. Anderson, Z. Bai, C. Bischof, L. S. Blackford, J. Demmel, J. Dongarra, J. Du Croz,\n",
    "A. Greenbaum, S. Hammarling, A. Mckenney and D. Sorensen, LAPACK Users Guide, Society for Industrial and Applied Mathematics, Philadelphia, PA, third ed., 1999.\n",
    "\n",
    "* G. H. Golub, C. F. Van Loan, Matrix Computations, John Hopkins University\n",
    "Press, 2013.\n",
    "\n",
    "* [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb)\n",
    "\n",
    "Para más sobre BLAS, LAPACK con C ver:\n",
    "\n",
    "* [C/BLAS](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/BLAS)\n",
    "\n",
    "* [C/LAPACK](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/LAPACK)\n",
    "\n",
    "Hay implementaciones en paralelo de BLAS para sistemas de memoria distribuida. Ver por ejemplo:\n",
    "\n",
    "* [PBLAS](http://www.netlib.org/scalapack/pblas_qref.html) y [ScaLAPACK](http://www.netlib.org/scalapack/)\n",
    "\n",
    "También NVIDIA tiene su propia implementación de BLAS para uso con GPU's: [CUBLAS](https://docs.nvidia.com/cuda/cublas/index.html) y su implementación de LAPACK: [CUSOLVER](https://docs.nvidia.com/cuda/cusolver/index.html). Para más sobre CUBLAS y CUSOLVER ver: [C/extensiones_a_C/CUDA/CUBLAS](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA/CUBLAS) y [C/extensiones_a_C/CUDA/CUSOLVER/](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA/CUSOLVER)\n",
    "\n",
    "Otras referencias para uso de GPU's con implementaciones de BLAS y LAPACK se encuentran:\n",
    "\n",
    "* [MAGMA](https://icl.cs.utk.edu/magma/), [MAGMA en NVIDIA](https://developer.nvidia.com/magma), ver por ejemplo: [Matrix computations on the GPU](https://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf)\n",
    "\n",
    "* [NVBLAS](https://docs.nvidia.com/cuda/nvblas/)\n",
    "\n",
    "Otras referencias útiles para [perf](https://github.com/torvalds/linux/tree/master/tools/perf) son:\n",
    "\n",
    "* [perf-wiki](https://perf.wiki.kernel.org/index.php/Tutorial)\n",
    "\n",
    "* [perf-tools](https://github.com/brendangregg/perf-tools) para *tools* que se apoyan de `perf`.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
