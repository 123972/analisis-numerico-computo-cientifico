{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notas para contenedor de docker:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comando de docker para ejecución de la nota de forma local:\n",
    "\n",
    "nota: cambiar `<ruta a mi directorio>` por la ruta de directorio que se desea mapear a `/datos` dentro del contenedor de docker.\n",
    "\n",
    "```\n",
    "sudo docker run --rm -v <ruta a mi directorio>:/datos --cap-add SYS_ADMIN --privileged --name jupyterlab-numerical -p 8888:8888 -d palmoreck/jupyterlab_numerical:1.1.0\n",
    "```\n",
    "\n",
    "password para jupyterlab: `qwerty`\n",
    "\n",
    "Detener el contenedor de docker:\n",
    "\n",
    "```\n",
    "docker stop jupyterlab_numerical\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentación de la imagen de docker `palmoreck/jupyterlab_numerical:1.1.0` en [liga](https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/numerical)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para ejecutar el comando de linux [perf](https://github.com/torvalds/linux/tree/master/tools/perf), que se revisará en esta nota, obsérvese que es necesario correr el contenedor de docker descrito antes con las *flags* `--cap-add SYS_ADMIN` y `--privileged`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga](https://www.dropbox.com/s/fyqwiqasqaa3wlt/3.1.1.Multiplicacion_de_matrices_y_estructura_de_datos.pdf?dl=0), [liga2](https://www.dropbox.com/s/l4hq45rj860ql9f/3.1.2.Localidad_y_vectorizacion.Analisis_del_error_en_computos_matriciales_basicos.pdf?dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 El cómputo matricial y el álgebra lineal. Vectorización, BLAS y el uso del caché eficientemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cómputo matricial está construído sobre una jerarquía de operaciones del álgebra lineal:\n",
    "\n",
    "* Productos punto involucran operaciones escalares de suma y multiplicación (nivel BLAS 1).\n",
    "\n",
    "* La multiplicación matriz-vector está hecha de productos punto (nivel BLAS 2).\n",
    "\n",
    "* La multiplicación matriz-matriz utiliza colecciones de productos matriz-vector (nivel BLAS 3).\n",
    "\n",
    "Las operaciones anteriores se describen en el álgebra lineal con la teoría de espacios vectoriales pero también es posible describirlas en una forma algorítmica. Ambas descripciones se complementan una a la otra.\n",
    "\n",
    "Manejaremos nombres que en el [Linear Algebra Package: LAPACK](http://www.netlib.org/lapack/explore-html/dir_fa94b7b114d387a7a8beb2e3e22bf78d.html) son utilizados para denotar operaciones con escalares, vectores o matrices. Ver [ Reference-LAPACK / lapack](https://github.com/Reference-LAPACK/lapack) para su github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nivel 1 de BLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operación del producto interno estándar o producto punto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos $x,y \\in \\mathbb{R}^n$. El producto punto entre $x$ y $y$ es $c = x^Ty = \\displaystyle \\sum_{i=1}^n x_iy_i$. \n",
    "\n",
    "**Ejemplo y algoritmo del producto punto:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "n=5\n",
    "x=[-1]*n\n",
    "y=[1.5]*n\n",
    "\n",
    "for i in range(n):\n",
    "    c += x[i]*y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:**\n",
    "\n",
    "* El producto punto de dos $n$-vectores involucran $n$ multiplicaciones y $n$ sumas para un total de $2n$ operaciones. Usamos la notación $\\mathcal{O}(\\cdot)$ para escribir que el producto punto es $\\mathcal{O}(n)$ y se lee \"de orden $n$ o proporcional a $n$\" para indicar que la **cantidad de trabajo** tiene un comportamiento **lineal** con la dimensión $n$. También tal cantidad de trabajo opera sobre una **cantidad lineal de datos**.\n",
    "\n",
    "* En LAPACK encontramos [sdot](http://www.netlib.org/lapack/explore-html/d0/d16/sdot_8f.html), [ddot](http://www.netlib.org/lapack/explore-html/d5/df6/ddot_8f.html), [cdotu](http://www.netlib.org/lapack/explore-html/d7/d7b/cdotu_8f.html) y [zdotu](http://www.netlib.org/lapack/explore-html/db/d2d/zdotu_8f.html) para descripción de las funciones/subrutinas escritas en [Fortran](https://en.wikipedia.org/wiki/Fortran) del producto punto en los casos de precisión simple, doble o números complejos respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operación **saxpy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos $\\alpha \\in \\mathbb{R}, x,y \\in \\mathbb{R}^n$. El nombre lo recibe por *scalar alpha x plus y*. En LAPACK [saxpy](http://www.netlib.org/lapack/explore-html/d8/daf/saxpy_8f.html) se escribe en forma *update*:\n",
    "\n",
    "$$y=\\alpha x + y \\therefore y_i = \\alpha x_i + y_i \\forall i=1,...,n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** \n",
    "\n",
    "* El símbolo $=$ no se utiliza como igualdad de expresiones sino para denotar asignación (como en computación al escribir un algoritmo).\n",
    "\n",
    "* También encontramos en LAPACK [caxpy](http://www.netlib.org/lapack/explore-html/de/da2/caxpy_8f.html) o [daxpy](http://www.netlib.org/lapack/explore-html/d9/dcd/daxpy_8f.html) para el caso complejo y para números en doble precisión respectivamente.\n",
    "\n",
    "* Ésta operación realiza un trabajo de $\\mathcal{O}(n)$ sobre una cantidad de datos $\\mathcal{O}(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo y algoritmo de saxpy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=2\n",
    "n=5\n",
    "x=[-2]*n\n",
    "y=[0]*n\n",
    "\n",
    "for i in range(n):\n",
    "    y[i] += alpha*x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-4, -4, -4, -4, -4]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o en una forma *update*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=2\n",
    "n=5\n",
    "x=[-2]*n\n",
    "y=[3,4,-1,0,1]\n",
    "\n",
    "for i in range(n):\n",
    "    y[i] += alpha*x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, -5, -4, -3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentario:** La operación de producto punto y *saxpy* son algoritmos catalogados como de **nivel BLAS 1**, ver [BLAS: Basic Linear Algebra Subprograms](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms). Éstos algoritmos se caracterizan por involucrar una cantidad de trabajo lineal sobre una cantidad lineal de datos. Ver [level 1](http://www.netlib.org/blas/#_level_1) para más ejemplos de este tipo de algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nivel 2 de BLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplicación matriz-vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos $A \\in \\mathbb{R}^{m \\times n}, x \\in \\mathbb{R}^n, y \\in \\mathbb{R}^m$. La operación $y = y + Ax$ es una operación *generalizada* saxpy, por ello se denomina **gaxpy** pero en LAPACK podemos encontrarla con nombres como [sgemv](http://www.netlib.org/lapack/explore-html/db/d58/sgemv_8f.html), [dgemv](http://www.netlib.org/lapack/explore-html/dc/da8/dgemv_8f.html), [cgemv](http://www.netlib.org/lapack/explore-html/d4/d8a/cgemv_8f.html) o [zgemv](http://www.netlib.org/lapack/explore-html/db/d40/zgemv_8f.html) para los casos de precisión simple, doble o números complejos respectivamente. Hay diferentes formas de visualizar y escribir el algoritmo de multiplicación matriz-vector. Por ejemplo para una matriz $A$ con entradas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2\n",
    "n=5\n",
    "A=[[1.2]*n if i%2==0 else [1]*n for i in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.2, 1.2, 1.2, 1.2, 1.2], [1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1][n-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se tiene:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -) Algoritmo gaxpy *row oriented*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[2]*n\n",
    "y=[0]*m\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        y[i]+=A[i][j]*x[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.0, 10]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $y$ tiene valores distintos de $0$, se realiza un *update*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[2]*n\n",
    "y=[-1]*m\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        y[i]+=A[i][j]*x[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.0, 9]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* En la versión *row oriented* del algoritmo *gaxpy*, el **inner loop** realiza **productos punto** entre el $i$-ésimo renglón de $A$ y el vector $x$. Se realizan $m$ productos punto $A[i,:]^Tx$:\n",
    "\n",
    "```\n",
    "for i in range(m)\n",
    "    y[i]+=A[i,:]*x #producto punto\n",
    "    \n",
    "```\n",
    "\n",
    "donde: $A[i,:]$ es el $i$-ésimo renglón de $A$. Así podemos reescribir de forma más compacta este algoritmo.\n",
    "\n",
    "* Obsérvese que el acceso a la matriz $A$ del algoritmo *gaxpy row oriented* es **por renglón**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puede escribirse al algoritmo *gaxpy* en una forma orientada por columnas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -) Algoritmo gaxpy *column oriented*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo ayuda a visualizar al producto matriz-vector como una combinación lineal de las columnas de $A$:\n",
    "\n",
    "$$Ax = \\displaystyle \\sum_{j=1}^n A_jx_j$$\n",
    "\n",
    "con $A_j$ la $j$-ésima columna de $A$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[2]*n\n",
    "y=[0]*m\n",
    "for j in range(n):\n",
    "    for i in range(m):\n",
    "        y[i]+=A[i][j]*x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.0, 10]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* El algoritmo de multiplicación matriz-vector (versión *row* o *column* oriented) involucra $\\mathcal{O}(mn)$ operaciones o una cantidad **cuadrática** de trabajo, que podemos entender como \"si duplicamos cada dimensión de $A$ entonces la cantidad de trabajo se incrementa por un factor de $4$\". Tal número de operaciones trabajan sobre una matriz o sobre una cantidad **cuadrática** de datos. A los algoritmos que realizan una cantidad cuadrática de trabajo sobre una cantidad cuadrática de datos se les cataloga de **nivel BLAS 2**. Ver [level 2](http://www.netlib.org/blas/#_level_2) para más ejemplos de algoritmos en el álgebra lineal en esta categoría.\n",
    "\n",
    "* En el algoritmo *gaxpy column oriented* el acceso a la matriz $A$ es por columna.\n",
    "\n",
    "* La versión *column oriented* se puede analizar desde el punto de vista puramente algorítmico como un intercambio entre las líneas con los índices $i$ y $j$ de cada *loop* y un acceso a los datos de la matriz por columna. O bien, se puede analizar desde el álgebra lineal indicando que el vector $y$ está en el **espacio generado** por las columnas de $A$ y cuyas coordenadas son dadas por las entradas del vector $x$:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/6a2b7rjs4a71sni/combinacion_lineal_columnas_A.png?dl=0\" heigth=\"700\" width=\"700\">\n",
    "\n",
    "Una ejemplo de visualización del espacio generado por las columnas de $A \\in \\mathbb{R}^{3 \\times 2}$, llamado **rango o imagen** de $A$, $Im(A)$, es el siguiente:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/zkbhzv9a2jiw11b/espacio_generado_columnas_de_A.png?dl=0\" heigth=\"400\" width=\"400\">\n",
    "\n",
    "En este dibujo los vectores $b, r(x) \\in \\mathbb{R}^3$ no están en $Im(A) \\subset \\mathbb{R}^3$ pero $Ax$ en azul sí. $Im(A)$ en el dibujo es un plano en el espacio $\\mathbb{R}^3$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obsérvese que el **inner loop** de la versión *column oriented* en *gaxpy* es un **saxpy** en la que el escalar está dado por una entrada de $x$. Esto lo podemos escribir de forma explícita definiendo $A[:,j]$ a la $j$-ésima columna de $A$ por lo que $A = [A[:,1] | A[:,2] | \\dots | A[:,n]]$, entonces:\n",
    "\n",
    "```\n",
    "for j in range(n)\n",
    "    y+=A[:,j] * x[j]\n",
    " \n",
    "```\n",
    "\n",
    "sin embargo como hemos visto en Python con su implementación más común CPython, no es posible realizar tal indexado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-93f449af9194>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "x=[2]*n\n",
    "y=[0]*m\n",
    "for j in range(n):\n",
    "    y+=A[:,j]*x[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a menos que incorporemos alguna paquetería que permita la **vectorización** y el uso de índices para extracción de columnas (o renglones) de $A$. Entre las razones que encontramos en Python el no soporte para la vectorización está que el [bytecode](https://en.wikipedia.org/wiki/Bytecode) de Python no está optimizado para vectorización. Un ejemplo de un paquete que permite realizar operaciones de forma vectorizada es [numpy](https://numpy.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2*np.ones(n)\n",
    "y = np.zeros(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[1.2,1.2,1.2,1.2,1.2],[1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2, 1.2, 1.2, 1.2, 1.2],\n",
       "       [1. , 1. , 1. , 1. , 1. ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(n):\n",
    "    y+=A[:,j]*x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12., 10.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo, el algoritmo *gaxpy row oriented* puede escribirse de forma más compacta haciendo uso de la definición de producto punto estándar: $x^Ty$ para dos vectores columna $x$ y $y$. En el caso de una matriz $A$ se tiene:\n",
    "\n",
    "```\n",
    "for i=1:m\n",
    "    y[i]+=A[i,:]^T*x\n",
    "```\n",
    "\n",
    "donde: $A[i,:]$ es el $i$-ésimo renglón de $A$. En Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2*np.ones(n)\n",
    "y = np.zeros(m)\n",
    "A=np.array([[1.2,1.2,1.2,1.2,1.2],[1,1,1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(m):\n",
    "    y[i]+=A[i,:].dot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12., 10.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en donde se utilizó la función [numpy.dot](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) de *numpy*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* La vectorización como se describe en [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb), es una herramienta que tenemos a nuestra disposición para escribir programas de alto rendimiento. La vectorización incrementa\\* el número de instrucciones por ciclo [IPC](https://en.wikipedia.org/wiki/Instructions_per_cycle) para procesadores que soportan el Single Instruction Multiple Data (SIMD) que encontramos en la taxonomía de Flynn (ver [liga](https://en.wikipedia.org/wiki/Flynn%27s_taxonomy)). Como ejemplo de tales procesadores están los procesadores vectoriales o en arreglo, ver [liga](https://en.wikipedia.org/wiki/Vector_processor). Obsérvese en [liga](https://github.com/numpy/numpy/blob/master/numpy/core/src/umath/simd.inc.src) que `numpy` soporta tales operaciones.\n",
    "\n",
    "\\*El incremento en IPC vía la vectorización se enfoca a que las instrucciones tiendan a completar trabajo **útil** por ciclo pues podría darse la situación en la que se tiene: *a high rate of instructions, but a low rate of actual work completed*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Perf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Linux existe la herramienta [perf](https://github.com/torvalds/linux/tree/master/tools/perf) que nos ayuda a calcular métricas de desempeño de la CPU o de los cores. Para la ejecución de los siguientes ejemplos es **indispensable** correr el contenedor de docker descrito al inicio de la nota en un sistema ubuntu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo de cálculo de la norma $2$ al cuadrado de un vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting norm_square.py\n"
     ]
    }
   ],
   "source": [
    "%%file norm_square.py\n",
    "n=10**5\n",
    "vector=list(range(n))\n",
    "norm=0\n",
    "for v in vector:\n",
    "    norm+=v*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 norm_square.py' (20 runs):\n",
      "\n",
      "         112969642      cycles                                                        ( +-  0.36% )\n",
      "         217301216      instructions              #    1.92  insn per cycle           ( +-  0.73% )\n",
      "           1137719      cache-references                                              ( +-  0.92% )\n",
      "             58733      cache-misses              #    5.162 % of all cache refs      ( +-  2.07% )\n",
      "\n",
      "       0.030025947 seconds time elapsed                                          ( +-  1.22% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 20 python3 norm_square.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* Con `perf` se repiten las mediciones utilizando la *flag* `-r`. Con la *flag* `-e` se enlistan las métricas a calcular. `-S` llama a sync() antes de iniciar una ejecución.\n",
    "\n",
    "* En el ejemplo anterior además de los ciclos e instrucciones se calculan los *cache references* y los *cache misses*. Ver [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb) para definiciones de *cache references* y *misses*. Esencialmente el sistema de memoria buscó el número que aparece en *cache-references* por datos o instrucciones en el caché y de éstas búsquedas, en *cache-misses* se repora el número (y porcentaje) de búsquedas fallidas que no estuvieron en memoria. \n",
    "\n",
    "* La fragmentación, ver [Fragmentation](https://en.wikipedia.org/wiki/Fragmentation_(computing)), incrementa el número de transferencias de memoria hacia la CPU y además imposibilita la vectorización porque el caché no está lleno. El caché puede llenarse sólo al tener bloques contiguos de memoria alojados para los datos (recuérdese que la interconexión o *bus* sólo puede mover *chunks* de memoria contigua, ver [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb)). Python en su implementación común CPython, tiene **data fragmentation** por ejemplo al usar listas. Las listas de Python alojan locaciones donde se pueden encontrar los datos y no los datos en sí. Al utilizar tales estructuras para operaciones matriciales el *runtime* de Python debe realizar *lookups* por índices y al no encontrarse de forma contigua los datos, el *overhead* en la transferencia de datos es mayor lo que causa que se tengan mayor número de *cache-misses* y que los cores tengan que esperar hasta que los datos estén disponibles en el caché.\n",
    "\n",
    "* Obsérvese que se reporta el IPC al lado de *instructions* con nombre *insn per cycle*. Un alto IPC indica una alta transferencia de instrucciones de la unidad de memoria hacia la unidad de cómputo y un menor IPC indica más **stall cycles**, ver [pipeline stall](https://en.wikipedia.org/wiki/Pipeline_stall). Sin embargo como se mencionó antes, se debe evaluar si *a high rate of instructions* indica un *high rate of actual work completed* (p.ej. un *loop* tiene una alta tasa de IPC pero no siempre se realiza trabajo útil). Ver sección *CPU statistics* en la [liga](http://www.brendangregg.com/perf.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos obtener las estadísticas por core. Obsérvese que la salida anterior de `perf` calculó el IPC a partir del número de instrucciones y ciclos ahí reportados. El mismo cálculo se realiza a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (20 runs):\n",
      "\n",
      "S0-C0           2          111124270      cycles                                                      \n",
      "S0-C0           2          214054021      instructions              #    1.93  insn per cycle         \n",
      "S0-C0           2            1196096      cache-references                                            \n",
      "S0-C0           2              60653      cache-misses              #    5.071 % of all cache refs    \n",
      "S0-C1           2          111521501      cycles                                                      \n",
      "S0-C1           2           26249177      instructions              #    0.24  insn per cycle         \n",
      "S0-C1           2               2337      cache-references                                            \n",
      "S0-C1           2               1379      cache-misses              #   59.007 % of all cache refs    \n",
      "S0-C2           2            1184308      cycles                                                      \n",
      "S0-C2           2             313203      instructions              #    0.26  insn per cycle         \n",
      "S0-C2           2               9650      cache-references                                            \n",
      "S0-C2           2               4572      cache-misses              #   47.378 % of all cache refs    \n",
      "S0-C3           2            1500849      cycles                                                      \n",
      "S0-C3           2             482866      instructions              #    0.32  insn per cycle         \n",
      "S0-C3           2              29157      cache-references                                            \n",
      "S0-C3           2               6797      cache-misses              #   23.312 % of all cache refs    \n",
      "\n",
      "       0.030082184 seconds time elapsed                                          ( +-  0.58% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 20 python3 norm_square.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ejecutamos `perf` sólo con la *flag* `-r` resulta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 norm_square.py' (20 runs):\n",
      "\n",
      "         30.059631      task-clock (msec)         #    0.994 CPUs utilized            ( +-  1.01% )\n",
      "                 0      context-switches          #    0.008 K/sec                    ( +- 39.74% )\n",
      "                 0      cpu-migrations            #    0.000 K/sec                  \n",
      "              2076      page-faults               #    0.069 M/sec                    ( +-  0.02% )\n",
      "         111057933      cycles                    #    3.695 GHz                      ( +-  0.23% )\n",
      "         214464593      instructions              #    1.93  insn per cycle           ( +-  0.45% )\n",
      "          45107448      branches                  # 1500.599 M/sec                    ( +-  0.52% )\n",
      "            669749      branch-misses             #    1.48% of all branches          ( +-  0.11% )\n",
      "\n",
      "       0.030241277 seconds time elapsed                                          ( +-  1.02% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -r 20 python3 norm_square.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* La métrica de *task-clock* indica cuántos *clock cycles* tomó nuestra tarea y se reporta en milisegundos. Obsérvese que también se indica cuántos CPU's fueron utilizados, no es exactamente 1 pues el programa no sólo involucra trabajo de CPU sino también de alojamiento de memoria. \n",
    "\n",
    "* *context-switches* y *cpu-migrations* indican cuánto se detuvo el programa para realizar:\n",
    "\n",
    "    * operaciones relacionadas con el kernel del sistema (por ejemplo I/O).\n",
    "    * ejecución de otras aplicaciones.\n",
    "    * alojamiento de la ejecución en un core distinto (lo que ocasiona que haya movimiento de datos o instrucciones hacia el caché de otro core).\n",
    "    \n",
    "la idea es tener un número pequeño de éstas métricas.\n",
    "\n",
    "* *page-faults* se relaciona con el alojamiento de memoria a partir del kernel del sistema operativo. Ocasiona que se detenga la ejecución del programa y por tanto deseamos que ésta métrica no sea muy grande. Ver [Page fault](https://en.wikipedia.org/wiki/Page_fault).\n",
    "\n",
    "* Ver [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb) para el *branching*. Esencialmente interesa que el número de *branch misses* sea pequeño.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos generar la salida anterior por *core*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (20 runs):\n",
      "\n",
      "S0-C0           2          59.699698      cpu-clock (msec)          #    1.911 CPUs utilized          \n",
      "S0-C0           2                  5      context-switches          #    0.084 K/sec                  \n",
      "S0-C0           2                  0      cpu-migrations            #    0.000 K/sec                  \n",
      "S0-C0           2               2074      page-faults               #    0.035 M/sec                  \n",
      "S0-C0           2          114151283      cycles                    #    1.912 GHz                    \n",
      "S0-C0           2          226146639      instructions              #    1.98  insn per cycle         \n",
      "S0-C0           2           47873603      branches                  #  801.907 M/sec                  \n",
      "S0-C0           2             667536      branch-misses             #    1.39% of all branches        \n",
      "S0-C1           2          59.700993      cpu-clock (msec)          #    1.911 CPUs utilized          \n",
      "S0-C1           2                  4      context-switches          #    0.067 K/sec                  \n",
      "S0-C1           2                  0      cpu-migrations            #    0.000 K/sec                  \n",
      "S0-C1           2                  0      page-faults               #    0.000 K/sec                  \n",
      "S0-C1           2             276727      cycles                    #    0.005 GHz                    \n",
      "S0-C1           2              75162      instructions              #    0.27  insn per cycle         \n",
      "S0-C1           2              15164      branches                  #    0.254 M/sec                  \n",
      "S0-C1           2                628      branch-misses             #    4.14% of all branches        \n",
      "S0-C2           2          59.700878      cpu-clock (msec)          #    1.911 CPUs utilized          \n",
      "S0-C2           2                  6      context-switches          #    0.101 K/sec                  \n",
      "S0-C2           2                  0      cpu-migrations            #    0.000 K/sec                  \n",
      "S0-C2           2                  0      page-faults               #    0.000 K/sec                  \n",
      "S0-C2           2            1610430      cycles                    #    0.027 GHz                    \n",
      "S0-C2           2             406556      instructions              #    0.25  insn per cycle         \n",
      "S0-C2           2              87378      branches                  #    1.464 M/sec                  \n",
      "S0-C2           2               2075      branch-misses             #    2.37% of all branches        \n",
      "S0-C3           2          59.722514      cpu-clock (msec)          #    1.912 CPUs utilized          \n",
      "S0-C3           2                 14      context-switches          #    0.234 K/sec                  \n",
      "S0-C3           2                  1      cpu-migrations            #    0.017 K/sec                  \n",
      "S0-C3           2                  0      page-faults               #    0.000 K/sec                  \n",
      "S0-C3           2            1381439      cycles                    #    0.023 GHz                    \n",
      "S0-C3           2             370386      instructions              #    0.27  insn per cycle         \n",
      "S0-C3           2              66333      branches                  #    1.111 M/sec                  \n",
      "S0-C3           2               3825      branch-misses             #    5.77% of all branches        \n",
      "\n",
      "       0.031236297 seconds time elapsed                                          ( +-  2.81% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -r 20 python3 norm_square.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para contrastar las salidas anteriores con un mejor uso del caché se utiliza a continuación el paquete de `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing norm_square_numpy.py\n"
     ]
    }
   ],
   "source": [
    "%%file norm_square_numpy.py\n",
    "import numpy as np\n",
    "n=10**5\n",
    "vector=np.arange(n)\n",
    "vector.dot(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 norm_square_numpy.py' (20 runs):\n",
      "\n",
      "        2517939029      cycles                                                        ( +-  0.07% )\n",
      "        1287233993      instructions              #    0.51  insn per cycle           ( +-  0.07% )\n",
      "           7472851      cache-references                                              ( +-  0.22% )\n",
      "            403479      cache-misses              #    5.399 % of all cache refs      ( +-  1.80% )\n",
      "\n",
      "       0.139254850 seconds time elapsed                                          ( +-  0.36% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 20 python3 norm_square_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentario:** \n",
    "\n",
    "* Obsérvese que es **más tardado** este programa para el número $n$ que se está utilizando en comparación con el programa anterior sin vectorizar.\n",
    "\n",
    "* El número de instrucciones es **menor** al reportado anteriormente y parece tener un mayor número $%$ de *cache-misses*. Obsérvese que para este ejemplo es más ilustrativo observar las estadísticas por *core* y realizar conclusiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (20 runs):\n",
      "\n",
      "S0-C0           2          569110059      cycles                                                      \n",
      "S0-C0           2          222173905      instructions              #    0.39  insn per cycle         \n",
      "S0-C0           2              47498      cache-references                                            \n",
      "S0-C0           2              12696      cache-misses              #   26.730 % of all cache refs    \n",
      "S0-C1           2          569620862      cycles                                                      \n",
      "S0-C1           2          223486329      instructions              #    0.39  insn per cycle         \n",
      "S0-C1           2              51512      cache-references                                            \n",
      "S0-C1           2              12984      cache-misses              #   25.206 % of all cache refs    \n",
      "S0-C2           2          569812750      cycles                                                      \n",
      "S0-C2           2          223109158      instructions              #    0.39  insn per cycle         \n",
      "S0-C2           2              44136      cache-references                                            \n",
      "S0-C2           2               9939      cache-misses              #   22.519 % of all cache refs    \n",
      "S0-C3           2          818225184      cycles                                                      \n",
      "S0-C3           2          622681657      instructions              #    0.76  insn per cycle         \n",
      "S0-C3           2            7436355      cache-references                                            \n",
      "S0-C3           2             377443      cache-misses              #    5.076 % of all cache refs    \n",
      "\n",
      "       0.139100270 seconds time elapsed                                          ( +-  0.16% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 20 python3 norm_square_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:** \n",
    "\n",
    "* Se observa que la métrica IPC está más uniforme a través de los cores lo que indica un mejor *load balancing*.\n",
    "\n",
    "* Además, el $\\%$ de caché misses es menor que en el caso no vectorizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos obtener las salidas anteriores de `perf` al usar `numpy`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 norm_square_numpy.py' (20 runs):\n",
      "\n",
      "        658.846611      task-clock (msec)         #    4.733 CPUs utilized            ( +-  0.28% )\n",
      "              1309      context-switches          #    0.002 M/sec                    ( +- 97.65% )\n",
      "                 1      cpu-migrations            #    0.002 K/sec                    ( +- 14.60% )\n",
      "              4755      page-faults               #    0.007 M/sec                    ( +-  0.04% )\n",
      "        2509194053      cycles                    #    3.808 GHz                      ( +-  0.28% )\n",
      "        1288129520      instructions              #    0.51  insn per cycle           ( +-  0.14% )\n",
      "         256581259      branches                  #  389.440 M/sec                    ( +-  0.15% )\n",
      "           6512464      branch-misses             #    2.54% of all branches          ( +-  0.09% )\n",
      "\n",
      "       0.139189866 seconds time elapsed                                          ( +-  0.27% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -r 20 python3 norm_square_numpy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (20 runs):\n",
      "\n",
      "S0-C0           2         280.327176      cpu-clock (msec)          #    1.997 CPUs utilized          \n",
      "S0-C0           2                 48      context-switches          #    0.171 K/sec                  \n",
      "S0-C0           2                  5      cpu-migrations            #    0.018 K/sec                  \n",
      "S0-C0           2                  4      page-faults               #    0.014 K/sec                  \n",
      "S0-C0           2          569732162      cycles                    #    2.032 GHz                    \n",
      "S0-C0           2          222998243      instructions              #    0.39  insn per cycle         \n",
      "S0-C0           2           41820920      branches                  #  149.186 M/sec                  \n",
      "S0-C0           2             761701      branch-misses             #    1.82% of all branches        \n",
      "S0-C1           2         280.362219      cpu-clock (msec)          #    1.997 CPUs utilized          \n",
      "S0-C1           2                 46      context-switches          #    0.164 K/sec                  \n",
      "S0-C1           2                  5      cpu-migrations            #    0.018 K/sec                  \n",
      "S0-C1           2                  0      page-faults               #    0.000 K/sec                  \n",
      "S0-C1           2          595485979      cycles                    #    2.124 GHz                    \n",
      "S0-C1           2          252609982      instructions              #    0.42  insn per cycle         \n",
      "S0-C1           2           47805375      branches                  #  170.513 M/sec                  \n",
      "S0-C1           2             850921      branch-misses             #    1.78% of all branches        \n",
      "S0-C2           2         280.362523      cpu-clock (msec)          #    1.997 CPUs utilized          \n",
      "S0-C2           2                 82      context-switches          #    0.292 K/sec                  \n",
      "S0-C2           2                  2      cpu-migrations            #    0.007 K/sec                  \n",
      "S0-C2           2                  1      page-faults               #    0.004 K/sec                  \n",
      "S0-C2           2          570048514      cycles                    #    2.033 GHz                    \n",
      "S0-C2           2          221858305      instructions              #    0.39  insn per cycle         \n",
      "S0-C2           2           41692943      branches                  #  148.711 M/sec                  \n",
      "S0-C2           2             763207      branch-misses             #    1.83% of all branches        \n",
      "S0-C3           2         280.375634      cpu-clock (msec)          #    1.997 CPUs utilized          \n",
      "S0-C3           2                 59      context-switches          #    0.210 K/sec                  \n",
      "S0-C3           2                  5      cpu-migrations            #    0.018 K/sec                  \n",
      "S0-C3           2               4744      page-faults               #    0.017 M/sec                  \n",
      "S0-C3           2          832271740      cycles                    #    2.968 GHz                    \n",
      "S0-C3           2          625657253      instructions              #    0.75  insn per cycle         \n",
      "S0-C3           2          132103906      branches                  #  471.168 M/sec                  \n",
      "S0-C3           2            4270632      branch-misses             #    3.23% of all branches        \n",
      "\n",
      "       0.140398443 seconds time elapsed                                          ( +-  0.23% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -r 20 python3 norm_square_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresando al algoritmo *gaxpy column oriented*...\n",
    "\n",
    "Utilizaremos `perf` en lo que sigue para evaluar las métricas de IPC, *cache-references*, *cache-misses* y medir el tiempo de ejecución. Además, esto permitirá comparar los tiempos de ejecución del algoritmo *gaxpy* (nivel BLAS 2), con vectorización y sin vectorización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "m=10**4\n",
    "n=10**4\n",
    "A=np.random.rand(m,n)\n",
    "file='A.txt'\n",
    "np.savetxt(file,A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arhivo sin vectorizar y utilizando listas para la matriz y los vectores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_vector.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_vector.py\n",
    "m=10**4\n",
    "n=10**4\n",
    "x=[2]*n\n",
    "y=[0]*m\n",
    "A = []\n",
    "file='A.txt'\n",
    "with open(file,'r') as f:\n",
    "    for l in f:\n",
    "        A.append([float(k) for k in l.replace('\\n','').replace(' ',',').split(',')])      \n",
    "for j in range(n):\n",
    "    for i in range(m):\n",
    "        y[i]+=A[i][j]*x[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivo vectorizando con numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_vector_numpy.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_vector_numpy.py\n",
    "import numpy as np\n",
    "m=10**4\n",
    "n=10**4\n",
    "x = 2*np.ones(n)\n",
    "y = np.zeros(m)\n",
    "file='A.txt'\n",
    "A = np.loadtxt(file)\n",
    "for j in np.arange(n):\n",
    "    y+=A[:,j]*x[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso no vectorizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 mult_matrix_vector.py' (2 runs):\n",
      "\n",
      "      259544977496      cycles                                                        ( +-  0.60% )\n",
      "      625505659134      instructions              #    2.41  insn per cycle           ( +-  0.13% )\n",
      "        1014372934      cache-references                                              ( +-  0.28% )\n",
      "         126123343      cache-misses              #   12.434 % of all cache refs      ( +-  0.87% )\n",
      "\n",
      "      65.051571959 seconds time elapsed                                          ( +-  0.63% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas por core:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "S0-C0           2          722013519      cycles                                                      \n",
      "S0-C0           2          420881666      instructions              #    0.58  insn per cycle         \n",
      "S0-C0           2           10917452      cache-references                                            \n",
      "S0-C0           2            3975059      cache-misses              #   36.410 % of all cache refs    \n",
      "S0-C1           2          695895760      cycles                                                      \n",
      "S0-C1           2          145568672      instructions              #    0.21  insn per cycle         \n",
      "S0-C1           2            8308276      cache-references                                            \n",
      "S0-C1           2            3231580      cache-misses              #   38.896 % of all cache refs    \n",
      "S0-C2           2         1599077422      cycles                                                      \n",
      "S0-C2           2         1062171055      instructions              #    0.66  insn per cycle         \n",
      "S0-C2           2           11916889      cache-references                                            \n",
      "S0-C2           2            5883472      cache-misses              #   49.371 % of all cache refs    \n",
      "S0-C3           2       255264304886      cycles                                                      \n",
      "S0-C3           2       627749661657      instructions              #    2.46  insn per cycle         \n",
      "S0-C3           2         1018206645      cache-references                                            \n",
      "S0-C3           2          126764694      cache-misses              #   12.450 % of all cache refs    \n",
      "\n",
      "      63.187169901 seconds time elapsed                                          ( +-  1.17% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso vectorizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'python3 mult_matrix_vector_numpy.py' (2 runs):\n",
      "\n",
      "      239426251422      cycles                                                        ( +-  0.20% )\n",
      "      599033991518      instructions              #    2.50  insn per cycle           ( +-  0.09% )\n",
      "         656790900      cache-references                                              ( +-  0.15% )\n",
      "          93785326      cache-misses              #   14.279 % of all cache refs      ( +-  1.85% )\n",
      "\n",
      "      59.527032712 seconds time elapsed                                          ( +-  0.25% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector_numpy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "S0-C0           2         1504209672      cycles                                                      \n",
      "S0-C0           2         1066901784      instructions              #    0.71  insn per cycle         \n",
      "S0-C0           2           12347468      cache-references                                            \n",
      "S0-C0           2            3960360      cache-misses              #   32.074 % of all cache refs    \n",
      "S0-C1           2         1935535192      cycles                                                      \n",
      "S0-C1           2          538940580      instructions              #    0.28  insn per cycle         \n",
      "S0-C1           2            6076215      cache-references                                            \n",
      "S0-C1           2            2951868      cache-misses              #   48.581 % of all cache refs    \n",
      "S0-C2           2         2116484334      cycles                                                      \n",
      "S0-C2           2         1242805501      instructions              #    0.59  insn per cycle         \n",
      "S0-C2           2           11515235      cache-references                                            \n",
      "S0-C2           2            5876144      cache-misses              #   51.029 % of all cache refs    \n",
      "S0-C3           2       236810085139      cycles                                                      \n",
      "S0-C3           2       595744526008      instructions              #    2.52  insn per cycle         \n",
      "S0-C3           2          655955309      cache-references                                            \n",
      "S0-C3           2           92513328      cache-misses              #   14.104 % of all cache refs    \n",
      "\n",
      "      59.291923574 seconds time elapsed                                          ( +-  0.39% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_vector_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nivel 3 de BLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplicación de matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el \"desempate\" entre los tiempos de ejecución, *cache-references* y *cache-misses* entre la versión vectorizada y no vectorizada, consideremos al algoritmo de multiplicación de matrices $C = C + AB$ con $A \\in \\mathbb{R}^{m \\times r}, B \\in \\mathbb{R}^{r \\times n}, C \\in \\mathbb{R}^{m \\times n}$. En LAPACK encontramos tal algoritmo con nombres como [sgemm](http://www.netlib.org/lapack/explore-html/d4/de2/sgemm_8f.html), [dgemm](http://www.netlib.org/lapack/explore-html/d7/d2b/dgemm_8f.html), [cgemm](http://www.netlib.org/lapack/explore-html/d6/d5b/cgemm_8f.html) y [zgemm](http://www.netlib.org/lapack/explore-html/d7/d76/zgemm_8f.html) para los casos de precisión simple, doble o números complejos respectivamente. Este algoritmo se cataloga como de nivel 3 de BLAS pues realiza una **cantidad de trabajo cuadrática** sobre una **cantidad cúbica de datos**. Ver [level 3](http://www.netlib.org/blas/#_level_3) para más ejemplos de algoritmos en el álgebra lineal en esta categoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de multiplicación de matrices puede escribirse en diferentes versiones. Por ejemplo la versión  **i,j,k** es:\n",
    "\n",
    "```\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        for k in range(r):\n",
    "            C[i][j]+=A[i][k]*B[k][j]\n",
    "    \n",
    "```\n",
    "\n",
    "y la versión **j,k,i** es:\n",
    "\n",
    "```\n",
    "for j in range(n):\n",
    "    for k in range(r):\n",
    "        for i in range(m):\n",
    "            C[i][j]+=A[i][k]*B[k][j]\n",
    "```\n",
    "\n",
    "**Comentarios:**\n",
    "\n",
    "* Cualquiera de las versiones involucra una cantidad de trabajo del orden $\\mathcal{O}(mnr)$, la cual es cúbica. Es posible interpretar ésta cantidad de trabajo con una frase del tipo \"si duplicamos cada dimensión de $A$ entonces la cantidad de trabajo se incrementa por un factor de $8$\".\n",
    "\n",
    "* Distintas versiones tienen distinto patrón de acceso a los datos de $A, B$ y $C$. Por ejemplo, para la variante **i,j,k** el **inner loop** realiza un producto punto que requiere acceso a renglones de $A$ y columnas de $B$. La variante **j,k,i** involucra una operación *saxpy* en el **inner loop** y acceso por columnas a la matriz $C$ y a una columna de $A$. Un resúmen de lo anterior se presenta en el siguiente cuadro:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/rw81crmo1b7fjvb/tabla_con_versiones_mult_matrices.png?dl=0\" heigth=\"400\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación entre versiones vectorizadas y no vectorizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)\n",
    "m=10**4\n",
    "r=10**4\n",
    "\n",
    "A=np.random.rand(m,r)\n",
    "fileA='A.txt'\n",
    "np.savetxt(fileA,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "r=10**4\n",
    "n=10**4\n",
    "\n",
    "B=np.random.rand(r,n)\n",
    "fileB='B.txt'\n",
    "np.savetxt(fileB,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_matrix.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_matrix.py\n",
    "m=10**4\n",
    "r=10**4\n",
    "n=10**4\n",
    "\n",
    "A = []\n",
    "B = []\n",
    "fileA='A.txt'\n",
    "fileB='B.txt'\n",
    "\n",
    "with open(fileA,'r') as f:\n",
    "    for l in f:\n",
    "        A.append([float(k) for k in l.replace('\\n','').replace(' ',',').split(',')]) \n",
    "        \n",
    "with open(fileB,'r') as f:\n",
    "    for l in f:\n",
    "        B.append([float(k) for k in l.replace('\\n','').replace(' ',',').split(',')])  \n",
    "\n",
    "C=[[0]*n for i in range(m)]\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        for k in range(r):\n",
    "            C[i][j]+=A[i][k]*B[k][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mult_matrix_matrix_numpy.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_matrix_numpy.py\n",
    "import numpy as np\n",
    "m=10**4\n",
    "r=10**4\n",
    "n=10**4\n",
    "\n",
    "fileA='A.txt'\n",
    "fileB='B.txt'\n",
    "A = np.loadtxt(fileA)\n",
    "B = np.loadtxt(fileB)\n",
    "C = A@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 1 python3 mult_matrix_matrix.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... 36 min y todavía no terminaba... cambiar a r 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a -e cycles,instructions,cache-references,cache-misses -r 1 python3 mult_matrix_matrix.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "      836044127523      cycles                                                        ( +-  0.57% )\n",
      "     1686463020251      instructions              #    2.02  insn per cycle           ( +-  0.43% )\n",
      "        4086628234      cache-references                                              ( +-  1.72% )\n",
      "         882062956      cache-misses              #   21.584 % of all cache refs      ( +-  4.13% )\n",
      "\n",
      "     130.609360500 seconds time elapsed                                          ( +-  0.66% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_matrix_numpy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (2 runs):\n",
      "\n",
      "S0-C0           2        89616044167      cycles                                                      \n",
      "S0-C0           2       121446222500      instructions              #    1.36  insn per cycle         \n",
      "S0-C0           2          811435068      cache-references                                            \n",
      "S0-C0           2          194368638      cache-misses              #   23.954 % of all cache refs    \n",
      "S0-C1           2        88898510819      cycles                                                      \n",
      "S0-C1           2       121389910135      instructions              #    1.37  insn per cycle         \n",
      "S0-C1           2          722839867      cache-references                                            \n",
      "S0-C1           2          162558289      cache-misses              #   22.489 % of all cache refs    \n",
      "S0-C2           2       563600069053      cycles                                                      \n",
      "S0-C2           2      1280855473637      instructions              #    2.27  insn per cycle         \n",
      "S0-C2           2         1782304769      cache-references                                            \n",
      "S0-C2           2          317385129      cache-misses              #   17.808 % of all cache refs    \n",
      "S0-C3           2       103452663605      cycles                                                      \n",
      "S0-C3           2       155023368415      instructions              #    1.50  insn per cycle         \n",
      "S0-C3           2          805500520      cache-references                                            \n",
      "S0-C3           2          192465138      cache-misses              #   23.894 % of all cache refs    \n",
      "\n",
      "     131.489034132 seconds time elapsed                                          ( +-  0.71% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 2 python3 mult_matrix_matrix_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Otra versión vectorizando el inner loop en el que se involucran productos punto:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pendiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mult_matrix_matrix_numpy_dot_product.py\n"
     ]
    }
   ],
   "source": [
    "%%file mult_matrix_matrix_numpy_dot_product.py\n",
    "import numpy as np\n",
    "m=10**2\n",
    "r=10**3\n",
    "n=10**2\n",
    "\n",
    "fileA='A.txt'\n",
    "fileB='B.txt'\n",
    "A = np.loadtxt(fileA)\n",
    "B = np.loadtxt(fileB)\n",
    "C = np.zeros((m,n))\n",
    "for i in np.arange(m):\n",
    "        for j in np.arange(n):\n",
    "                C[i][j]+= A[i,:].dot(B[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (5 runs):\n",
      "\n",
      "        3052736247      cycles                                                        ( +-  2.05% )\n",
      "        2680158414      instructions              #    0.88  insn per cycle           ( +-  0.72% )\n",
      "          11041581      cache-references                                              ( +-  0.80% )\n",
      "            644429      cache-misses              #    5.836 % of all cache refs      ( +-  7.31% )\n",
      "\n",
      "       0.282211430 seconds time elapsed                                          ( +-  1.92% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a -e cycles,instructions,cache-references,cache-misses -r 1 python3 mult_matrix_matrix_numpy_dot_product.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Performance counter stats for 'system wide' (5 runs):\n",
      "\n",
      "S0-C0           2          569610445      cycles                                                      \n",
      "S0-C0           2          221505417      instructions              #    0.39  insn per cycle         \n",
      "S0-C0           2              56811      cache-references                                            \n",
      "S0-C0           2              17900      cache-misses              #   31.508 % of all cache refs    \n",
      "S0-C1           2         1319889207      cycles                                                      \n",
      "S0-C1           2         2002371463      instructions              #    1.52  insn per cycle         \n",
      "S0-C1           2           10456781      cache-references                                            \n",
      "S0-C1           2             489184      cache-misses              #    4.678 % of all cache refs    \n",
      "S0-C2           2          570228997      cycles                                                      \n",
      "S0-C2           2          227205140      instructions              #    0.40  insn per cycle         \n",
      "S0-C2           2              74761      cache-references                                            \n",
      "S0-C2           2              15297      cache-misses              #   20.461 % of all cache refs    \n",
      "S0-C3           2          571192241      cycles                                                      \n",
      "S0-C3           2          235730344      instructions              #    0.41  insn per cycle         \n",
      "S0-C3           2              49865      cache-references                                            \n",
      "S0-C3           2              17270      cache-misses              #   34.634 % of all cache refs    \n",
      "\n",
      "       0.288762948 seconds time elapsed                                          ( +-  0.89% )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo perf stat -S -a --per-core -e cycles,instructions,cache-references,cache-misses -r 1 python3 mult_matrix_matrix_numpy_dot_product.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('A.txt')\n",
    "os.remove('B.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "* E. Anderson, Z. Bai, C. Bischof, L. S. Blackford, J. Demmel, J. Dongarra, J. Du Croz,\n",
    "A. Greenbaum, S. Hammarling, A. Mckenney and D. Sorensen, LAPACK Users Guide, Society for Industrial and Applied Mathematics, Philadelphia, PA, third ed., 1999.\n",
    "\n",
    "* G. H. Golub, C. F. Van Loan, Matrix Computations, John Hopkins University\n",
    "Press, 2013.\n",
    "\n",
    "* [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb)\n",
    "\n",
    "Para más sobre BLAS, LAPACK con C ver:\n",
    "\n",
    "* [C/BLAS](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/BLAS)\n",
    "\n",
    "* [C/LAPACK](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/LAPACK)\n",
    "\n",
    "Hay implementaciones en paralelo de BLAS para sistemas de memoria distribuida. Ver por ejemplo:\n",
    "\n",
    "* [PBLAS](http://www.netlib.org/scalapack/pblas_qref.html) y [ScaLAPACK](http://www.netlib.org/scalapack/)\n",
    "\n",
    "También NVIDIA tiene su propia implementación de BLAS para uso con GPU's: [CUBLAS](https://docs.nvidia.com/cuda/cublas/index.html) y su implementación de LAPACK: [CUSOLVER](https://docs.nvidia.com/cuda/cusolver/index.html). Para más sobre CUBLAS y CUSOLVER ver: [C/extensiones_a_C/CUDA/CUBLAS](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA/CUBLAS) y [C/extensiones_a_C/CUDA/CUSOLVER/](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/C/extensiones_a_C/CUDA/CUSOLVER)\n",
    "\n",
    "Otras referencias para uso de GPU's con implementaciones de BLAS y LAPACK se encuentran:\n",
    "\n",
    "* [MAGMA](https://icl.cs.utk.edu/magma/), [MAGMA en NVIDIA](https://developer.nvidia.com/magma), ver por ejemplo: [Matrix computations on the GPU](https://developer.nvidia.com/sites/default/files/akamai/cuda/files/Misc/mygpu.pdf)\n",
    "\n",
    "* [NVBLAS](https://docs.nvidia.com/cuda/nvblas/)\n",
    "\n",
    "Otras referencias útiles para [perf](https://github.com/torvalds/linux/tree/master/tools/perf) son:\n",
    "\n",
    "* [perf-wiki](https://perf.wiki.kernel.org/index.php/Tutorial)\n",
    "\n",
    "* [perf-tools](https://github.com/brendangregg/perf-tools) para *tools* que se apoyan de `perf`.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
