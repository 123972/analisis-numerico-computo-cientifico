{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definiciones generales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que sigue se supone una matriz cuadrada $A \\in \\mathbb{R}^{nxn}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalor (valor propio o característico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número $\\lambda$ (real o complejo) se denomina *eigenvalor* de A si existe $v \\in \\mathbb{C}^n - \\{0\\}$ tal que $Av = \\lambda v$. El vector $v$ se nombra eigenvector (vector propio o característico) de $A$ correspondiente al eigenvalor $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** \n",
    "\n",
    "* Una matriz con componentes reales puede tener eigenvalores y eigenvectores con valores en $\\mathbb{C}$ o $\\mathbb{C}^n$ respectivamente.\n",
    "* El conjunto de eigenvalores se le llama **espectro de una matriz**.\n",
    "* $A$ siempre tiene al menos un eigenvalor con eigenvector asociado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Si A es simétrica entonces tiene eigenvalores reales y aún más: $A$ tiene eigenvectores reales linealmente independientes y forman un conjunto ortonormal. Entonces $A$ se escribe como un producto de tres matrices nombrado descomposición espectral: $$A = Q \\Lambda Q^T$$ donde: $Q$ es una matriz ortogonal cuyas columnas son eigenvectores de $A$ y $\\Lambda$ es una matriz diagonal con eigenvalores de $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valores y vectores singulares de una matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que sigue se supone $A \\in \\mathbb{R}^{mxn}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valor singular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número $\\sigma$ se denomina valor *singular* de $A$ si $\\sigma = \\sqrt{\\lambda_{A^TA}} = \\sqrt{\\lambda_{AA^T}}$ donde: $\\lambda_{A^TA}$ y $\\lambda_{AA^T}$ es eigenvalor de $A^TA$ y $AA^T$ respectivamente ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** la definición se realiza sobre $A^TA$ o $AA^T$ pues éstas matrices tienen el mismo espectro y además sus eigenvalores son reales y positivos por lo que $\\sigma \\in \\mathbb{R}$ y de hecho $\\sigma \\geq 0$ (la raíz cuadrada se calcula para un eigenvalor no negativo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector singular izquierdo, vector singular derecho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asociado con cada valor singular $\\sigma$ existen vectores singulares $u,v$ que cumplen con la igualdad: $$Av = \\sigma u .$$ Al vector $u$ se le nombra vector singular *izquierdo* y al vector $v$ se le nombra vector singular *derecho*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descomposición en valores singulares (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $A \\in \\mathbb{R}^{mxn}$ entonces existen $U \\in \\mathbb{R}^{mxm}, V \\in \\mathbb{R}^{nxn}$ ortogonales tales que: $A = U\\Sigma V^T$ con $\\Sigma = diag(\\sigma_1, \\sigma_2, \\dots, \\sigma_p) \\in \\mathbb{R}^{mxn}$, $p = \\min\\{m,n\\}$ y $\\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq \\sigma_p \\geq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** La notación $\\sigma_1$ hace referencia al valor singular más grande de A, $\\sigma_2$ al segundo valor singular más grande de A y así sucesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs2:** La SVD que se definió arriba es nombrada *SVD full*, hay una forma **truncada** en la que $U \\in \\mathbb{R}^{mxk}$, $V \\in \\mathbb{R}^{nxk}$ y $\\Sigma \\in \\mathbb{R}^{kxk}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen diferentes propiedades de los valores y vectores singulares, aquí se enlistan algunas:\n",
    "\n",
    "* Si $rank(A) = r$ entonces $r \\leq p$ y $\\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq \\sigma_r > \\sigma_{r+1} = \\sigma_{r+2} = \\dots = \\sigma_p =  0$.\n",
    "\n",
    "* Si $rank(A) = r$ entonces $A = \\displaystyle \\sum_{i=0}^r \\sigma_i u_i v_i^T$ con $u_i$ $i$-ésima columna de U y $v_i$ $i$-ésima columna de V.\n",
    "\n",
    "* Geométricamente los valores singulares de una matriz $A \\in \\mathbb{R}^{mxn}$ son las longitudes de los semiejes del hiperelipsoide $E$ definido por $E = \\{Ax : ||x|| \\leq 1, \\text{ con } ||\\cdot || \\text{ norma Euclidiana}\\}$ y los vectores $u_i$ son direcciones de estos semiejes; los vectores $vi$'s tienen norma igual a $1$ por lo que se encuentran en una circunferencia de radio igual a $1$ y como $Av_i = \\sigma u_i$ entonces $A$ mapea los vectores $v_i$'s a los semiejes $u_i$'s respectivamente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=0B66Kmqpqr3IQbnJYUW9XR3BhM1h1eFctMUdIbTNfa2RScFVv\" alt=\"a\" heigth=700\" width=\"700\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La SVD da bases ortogonales para los $4$ espacios fundamentales de una matriz: espacio columna, espacio nulo izquierdo, espacio nulo y espacio renglón:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=0B66Kmqpqr3IQVXVndGtLY3dVQy1XdEFSbi1POEoyVnFjRUY4\" alt=\"b\" heigth=\"700\" width=\"700\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Si $t < r$ y $r=rank(A)$ entonces $A_t =  \\displaystyle \\sum_{i=0}^t \\sigma_i u_i v_i^T$ es una matriz de entre todas las matrices con $rank$ igual a t, que es más *cercana* a A (la cercanía se mide con una norma **matricial**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las aplicaciones de la SVD se encuentran:\n",
    "\n",
    "* Procesamiento de imágenes y señales.\n",
    "* Sistemas de recomendación (Netflix).\n",
    "* Mínimos cuadrados.\n",
    "* Componentes principales.\n",
    "* Reconstrucción de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método de Jacobi para calcular la SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "* Ver [4_SVD_y_reconstruccion_de_imagenes](https://github.com/ITAM-DS/Propedeutico/blob/master/Python/clases/3_algebra_lineal/4_SVD_y_reconstruccion_de_imagenes.ipynb) para definiciones de eigenvalores, eigenvectores y la descomposición en valores singulares o DVS (o SVD por sus siglas en inglés)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
