{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga](https://www.dropbox.com/s/qb3swgkpaps7yba/4.1.Introduccion_optimizacion_convexa.pdf?dl=0), [liga2](https://www.dropbox.com/s/6isby5h1e5f2yzs/4.2.Problemas_de_optimizacion_convexa.pdf?dl=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización Numérica y machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización de código ¿es optimización numérica?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta este módulo hemos invertido buena parte del tiempo del curso en la eficiente implementación en el hardware que poseemos. Revisamos lo que estudia el análisis numérico o cómputo científico, definiciones de funciones, derivadas, integrales y métodos o algoritmos numéricos para su aproximación. Consideramos *bottlenecks* que pueden surgir en la implementación de los métodos o algoritmos y revisamos posibles opciones para encontrarlos y minimizarlos (**optimización de código**). Lo anterior lo resumimos con el uso de herramientas como: perfilamiento, integración de R y Python con C++ o C, cómputo en paralelo y uso del caché de forma eficiente al usar niveles altos en operaciones de BLAS ([módulo I: cómputo científico y análisis numérico](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/I.computo_cientifico), [módulo II: cómputo en paralelo](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/temas/II.computo_paralelo), [módulo III: cómputo matricial](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/tree/master/temas/III.computo_matricial)). \n",
    "\n",
    "Si bien la optimización de código no le compete a la **optimización numérica**, sí se apoya enormemente de ella para la implementación de sus métodos o algoritmos en la(s) máquina(s) para resolver problemas que surgen en tal rama de las **matemáticas aplicadas**. A la implementación y simulación en el desarrollo de los métodos o algoritmos del análisis numérico o cómputo científico típicamente se le acompaña de estudios que realizan [benchmarks](https://en.wikipedia.org/wiki/Benchmark_(computing)), mediciones de recursos (tiempo y memoria por ejemplo) y perfilamiento con el objetivo de tener **software confiable y eficiente** en la práctica. Esto lo encontramos también en la rama de optimización numérica con los métodos o algoritmos que son desarrollados e implementados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métodos o algoritmos numéricos en *big data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de los métodos o algoritmos en el contexto de **grandes cantidades de datos** o *big data* es **crítica** al ir a la práctica pues de esto depende que nuestra(s) máquina(s) tarde meses, semanas, días u horas para resolver problemas que se presentan en este contexto. La ciencia de datos apunta al desarrollo de técnicas y se apoya de aplicaciones de *machine learning* para la extracción de conocimiento útil y toma como fuente de información las grandes cantidades de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Problemas de optimización numérica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una gran cantidad de aplicaciones plantean problemas de optimización matemática o numérica. Tenemos problemas básicos que se presentan en cursos iniciales de cálculo:\n",
    "\n",
    "*Una caja con base y tapa cuadradas debe tener un volumen de $100 cm^3$. Encuentre las dimensiones de la caja que minimicen la cantidad de material.*\n",
    "\n",
    "Y tenemos más especializados que encontramos en áreas como estadística, ingeniería, finanzas o *machine learning*:\n",
    "\n",
    "* Ajustar un modelo de regresión lineal a un conjunto de datos.\n",
    "\n",
    "* Buscar la mejor forma de invertir un capital en un conjunto de activos.\n",
    "\n",
    "* Elección del ancho y largo de un dispositivo en un circuito electrónico.\n",
    "\n",
    "* Ajustar un modelo que clasifique un conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general un problema de optimización matemática o numérica tiene la forma:\n",
    "\n",
    "$$\\displaystyle \\min_{x \\in \\mathbb{R}^n} f_o(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{sujeto a:} f_i(x) \\leq b_i, i=1,\\dots, m$$\n",
    "\n",
    "donde: $x=(x_1,x_2,\\dots, x_n)^T$ es la **variable de optimización del problema**, la función $f_o: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ es la **función objetivo**, las funciones $f_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}, i=1,\\dots,m$ son las **funciones de restricción** (aquí se colocan únicamente desigualdades pero pueden ser sólo igualdades o bien una combinación de ellas) y las constantes $b_1,b_2,\\dots, b_m$ son los **límites o cotas de las restricciones**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un vector $x^* \\in \\mathbb{R}^n$ es nombrado **óptimo** o solución del problema anterior si tiene el valor más pequeño de entre todos los vectores $x \\in \\mathbb{R}^n$ que satisfacen las restricciones. Por ejemplo, si $z \\in \\mathbb{R}^n$ satisface $f_1(z) \\leq b_1, f_2(z) \\leq b_2, \\dots, f_m(z) \\leq b_m$ y $x^*$ es óptimo entonces $f_o(z) \\geq f_o(x^*)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentario:** en el curso revisamos métodos o algoritmos de optimización numérica que consideran funciones objetivo $f_o: \\mathbb{R} \\rightarrow \\mathbb{R}^n$. Sin embargo, hay formulaciones que utilizan $f_o: \\mathbb{R}^n \\rightarrow \\mathbb{R}^q$. Tales formulaciones pueden hallarlas en la optimización multicriterio, multiobjetivo, vectorial o Pareto. Ver [Multi objective optimization](https://en.wikipedia.org/wiki/Multi-objective_optimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:**\n",
    "\n",
    "$$\\displaystyle \\min_{x \\in \\mathbb{R}^n} ||x||_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{sujeto a:} Ax \\leq b$$\n",
    "\n",
    "\n",
    "con $A \\in \\mathbb{R}^{m \\times n}, b \\in \\mathbb{R}^m$. En este problema buscamos el vector $x$ que es solución del problema $Ax \\leq b$ con mínima norma Euclidiana. La función objetivo es $f_o(x)=||x||_2$, las funciones de restricción son las desigualdades lineales $f_i(x) = a_i^Tx \\leq b_i$ con $a_i$ $i$-ésimo renglón de $A$ y $b_i$ $i$-ésima componente de $b$, $\\forall i=1,\\dots,m$.\n",
    "\n",
    "Un problema similar al anterior lo podemos encontrar en resolver el sistema de ecuaciones lineales $Ax=b$ *underdetermined* en el que $m < n$ y se busca el vector $x$ con mínima norma Euclidiana que satisfaga tal sistema. Tal sistema puede tener infinitas soluciones o ninguna solución, ver [3.3.Solucion_de_SEL_y_FM](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/III.computo_matricial/3.3.Solucion_de_SEL_y_FM.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Machine learning, statistical machine learning y optimización numérica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección relacionamos a *machine learning* con la optimización matemática o numérica y se describen diferentes enfoques que se han propuesto para aplicaciones de *machine learning* con métodos de optimización numérica. Lo siguiente **no** pretende ser una exposición extensa **ni** completa sobre *machine learning*, ustedes llevan materias que se enfocan esencialmente a definir esta área, sus objetivos y conceptos más importantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la ciencia de datos se utilizan las aplicaciones desarrolladas en *machine learning* por ejemplo:\n",
    "\n",
    "* Clasificación de documentos o textos: detección de *spam*.\n",
    "\n",
    "* Procesamiento de lenguaje natural:  [named-entity recognition](https://en.wikipedia.org/wiki/Named-entity_recognition).\n",
    "\n",
    "* Reconocimiento de voz.\n",
    "\n",
    "* [Visión por computadora](https://en.wikipedia.org/wiki/Computer_vision): reconocimiento de rostros o imágenes.\n",
    "\n",
    "* Detección de fraude.\n",
    "\n",
    "* Diagnóstico médico.\n",
    "\n",
    "* Sistemas de recomendación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las aplicaciones anteriores involucran problemas como son:\n",
    "\n",
    "* Clasificación.\n",
    "\n",
    "* Regresión.\n",
    "\n",
    "* *Ranking*.\n",
    "\n",
    "* *Clustering*.\n",
    "\n",
    "* Reducción de la dimensionalidad.\n",
    "\n",
    "En cada una de las aplicaciones o problemas anteriores se utilizan **funciones de pérdida** que guían el proceso de aprendizaje. Tal proceso involucra **optimización numérica de parámetros** de la función de pérdida. Por ejemplo, si la función de pérdida en un problema de regresión es una pérdida cuadrática $\\mathcal{L}(y,\\hat{y}) = (\\hat{y}-y)^2$ con $\\hat{y} = \\hat{\\beta}_0 + \\beta_1x$, entonces el vector de parámetros a optimizar (aprender) es $\n",
    "\\beta=\n",
    "\\left[ \\begin{array}{c}\n",
    "\\beta_0\\\\\n",
    "\\beta_1\n",
    "\\end{array}\n",
    "\\right]\n",
    "$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Machine learning* no sólo se apoya de la optimización matemática o numérica pues es un área de Inteligencia Artificial\\* que utiliza técnicas estadísticas para el diseño de sistemas capaces de aplicaciones como las escritas anteriormente, de modo que hoy en día tenemos *statistical machine learning*. No obstante, uno de los **pilares** de *machine learning* o *statistical machine learning* es la optimización matemática o numérica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*La IA o inteligencia artificial es una rama de las ciencias de la computación que atrajo un gran interés en $1950$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Machine learning* o *statistical machine learning* se apoya de las formulaciones y algoritmos en optimización matemática o numérica. Sin embargo, también ha contribuido a ésta área desarrollando nuevos enfoques en los métodos o algoritmos numéricos de optimización para el tratamiento de las grandes cantidades de datos o *big data* y estableciendo retos significativos no presentes en problemas clásicos de optimización matemática o numérica. De hecho, al revisar literatura que intersecta estas dos disciplinas encontramos comunidades científicas que desarrollan o utilizan métodos o algoritmos exactos (ver [Exact algorithm](https://en.wikipedia.org/wiki/Exact_algorithm)) y otras que utilizan métodos de optimización estocástica (ver [Stochastic optimization](https://en.wikipedia.org/wiki/Stochastic_optimization)) basados en métodos o algoritmos aproximados (ver [Approximation algorithm](https://en.wikipedia.org/wiki/Approximation_algorithm))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Large scale machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En *machine learning* uno de los objetivos bien definido es encontrar soluciones que generalicen y provean una explicación no compleja del fenómeno en estudio\\*. Esto sigue el principio de la navaja de Occam, ver [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor): para cualquier conjunto de observaciones en general se prefieren explicaciones simples a explicaciones más complicadas. Un ejemplo de técnica utilizada en *machine leargning* es **regularización** la cual sigue el principio de Occam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El inicio del siglo XXI estuvo marcado, entre otros temas, por un incremento significativo en la generación de información. Esto puede contrastarse con el desarrollo de los procesadores de las máquinas como se revisó en el  módulo II del curso en el tema [2.1.Un_poco_de_historia_y_generalidades](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.1.Un_poco_de_historia_y_generalidades.ipynb). Asimismo, las mejoras en el performance y precio de dispositivos de almacenamiento o *storage* y sistemas de networking abarató costos de almacenamiento y permitió tal incremento de información.  En este contexto, los modelos y métodos de *statistical machine learning* se vieron limitados por el tiempo de cómputo y no por el tamaño de muestra. La conclusión de esto fue el diseño de métodos o modelos para procesar grandes cantidades de datos usando recursos computacionales comparativamente menores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Información de primer y segundo orden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tradicionalmente en la optimización matemática o numérica la búsqueda del (o los) **óptimo(s)** involucran el cálculo de información de primer o segundo orden (ver [1.4.Polinomios_de_Taylor_y_diferenciacion_numerica](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/I.computo_cientifico/1.4.Polinomios_de_Taylor_y_diferenciacion_numerica.ipynb)) de la función $f_o$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:**\n",
    "\n",
    "1) Calcular $\\nabla f(x), \\nabla^2f(x)$ con $f: \\mathbb{R}^4 \\rightarrow \\mathbb{R}$, dada por $f(x) = (x_1-2)^2+(2-x_2)^2+x_3^2+x_4^4$ en el punto $x_0=(1.5,1.5,1.5,1.5)^T$. \n",
    "\n",
    "**Solución:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla f(x) = \n",
    "\\left[ \\begin{array}{c}\n",
    "2(x_1-2)\\\\\n",
    "-2(2-x_2)\\\\\n",
    "2x_3\\\\\n",
    "4x_4^3\n",
    "\\end{array}\n",
    "\\right] ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla^2f(x)=\n",
    " \\left[\\begin{array}{cccc}\n",
    "2 & 0 & 0 & 0\\\\\n",
    "0 & 2 & 0 & 0\\\\\n",
    "0 & 0 &2 & 0\\\\\n",
    "0 & 0 &0 &12x_3^2\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla f(x_0) = \n",
    "\\left[ \\begin{array}{c}\n",
    "-1\\\\\n",
    "-1\\\\\n",
    "3\\\\\n",
    "\\frac{27}{2}\n",
    "\\end{array}\n",
    "\\right],\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla^2f(x_0)=\n",
    " \\left[\\begin{array}{cccc}\n",
    "2 &0&0&0\\\\\n",
    "0&2&0&0\\\\\n",
    "0 &0&2&0\\\\\n",
    "0&0&0&27\\\\\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información de primer y segundo orden la constituyen el gradiente de $f$, $\\nabla f$, y la matriz Hessiana de $f$, $\\nabla^2f(x)$. Obsérvese que el almacenamiento de la Hessiana involucra $\\mathcal{O}(n^2)$ entradas y en los métodos de optimización matemática o numérica se utiliza para encontrar el mínimo de una función resolviendo un sistema de ecuaciones lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Encontrar el mínimo de $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0=np.array([1.5,1.5,1.5,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf= lambda x: np.array([2*(x[0]-2),\n",
    "                        -2*(2-x[1]),\n",
    "                        2*x[2],\n",
    "                        4*x[3]**3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hf = lambda x: np.array([[2, 0, 0 ,0],\n",
    "                         [0, 2, 0, 0],\n",
    "                         [0, 0, 2, 0],\n",
    "                         [0, 0, 0, 27]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1. , -1. ,  3. , 13.5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  0,  0,  0],\n",
       "       [ 0,  2,  0,  0],\n",
       "       [ 0,  0,  2,  0],\n",
       "       [ 0,  0,  0, 27]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hf(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como $f$ es una función convexa (definida abajo) se tiene que su óptimo se obtiene igualando $\\nabla f(x) = 0$ :\n",
    "\n",
    "$$\\nabla f(x) = \n",
    "\\left[ \\begin{array}{c}\n",
    "2(x_1-2) \\\\\n",
    "-2(2-x_2)\\\\\n",
    "2x_3\\\\\n",
    "4x_4^3\n",
    "\\end{array}\n",
    "\\right]\n",
    "= 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dado por $x^* \\in \\mathbb{R}^4:$\n",
    "\n",
    "$$x^*=\n",
    "\\left[ \\begin{array}{c}\n",
    "2\\\\\n",
    "2\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numéricamente se puede utilizar un método iterativo en el que iniciamos con un punto inicial $x^{(0)}$ y las actualizaciones se realizan con el gradiente:\n",
    "\n",
    "$$x^{(k)} = x^{(k-1)} - \\nabla f(x^{(k-1)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para $k=1,2,\\dots,$. En el ejemplo anterior tomando $x^{(0)} = (0,0,0,0)^T$ se tiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = np.array([5,5,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = x_0 - gf(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = x_1 - gf(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_3 = x_2 - gf(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_4 = x_3 - gf(x_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y aquí nos quedaremos ciclando hasta el infinito..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra opción es utilizar la información de segundo orden con la Hessiana y considerar una actualización:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^{(k)} = x^{(k-1)} - \\nabla^2 f \\left (x^{(k-1)} \\right )^{-1} \\nabla f\\left(x^{(k-1)} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(recordamos que no calculmos inversas de matrices por mayor costo computacional que resolver un sistema de ecuaciones lineales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = x_0 - np.linalg.solve(Hf(x_0),gf(x_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:** de acuerdo al ejemplo anterior:\n",
    "\n",
    "* Utilizar información de primer o segundo orden nos ayuda a encontrar óptimo(s) de funciones.\n",
    "\n",
    "* Encontrar al óptimo involucró un método iterativo.\n",
    "\n",
    "* Con la información de primer orden no alcanzamos al óptimo pero con la de segundo orden sí lo alcanzamos en una iteración y tuvimos que resolver un sistema de ecuaciones lineales.\n",
    "\n",
    "* Si consideramos una actualización de la forma:\n",
    "\n",
    "$$x^{(k)} = x^{(k-1)} - t_k\\nabla f(x^{(k-1)})$$\n",
    "\n",
    "con $t_1=0.5$ llegamos al óptimo en una iteración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 2, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = x_0 - t_1*gf(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calcular el gradiente involucra menos almacenamiento en memoria que el cálculo de la Hessiana: $\\mathcal{O}(n)$ vs $\\mathcal{O}(n^2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch algoritmhs and online algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo: regresión lineal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supóngase que se han realizado mediciones de un fenómeno de interés en diferentes puntos $x_i$'s resultando en cantidades $y_i$'s $\\forall i=0,1,\\dots, m$ (se tienen $m+1$ puntos) y además las $y_i$'s contienen un ruido aleatorio causado por errores de medición:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/iydpi0m8ndqzb0s/mcuadrados_1.jpg?dl=0\" heigth=\"350\" width=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de los mínimos cuadrados lineales es construir una curva, $f(x|\\beta)$ que \"mejor\" se ajuste a los datos $(x_i,y_i)$, $\\forall i=0,1,\\dots,m$. El término de \"mejor\" se refiere a que la suma: $$\\displaystyle \\sum_{i=0}^m (y_i -f(x_i|\\beta))^2$$ sea lo más pequeña posible, esto es, a que la suma de las distancias verticales entre $y_i$ y $f(x_i|\\beta)$ $\\forall i=0,1,\\dots,m$ al cuadrado sea mínima:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/0dhzv336jj6ep4z/mcuadrados_2.jpg?dl=0\" heigth=\"350\" width=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:**\n",
    "\n",
    "* La notación $f(x|\\beta)$ se utiliza para denotar que $\\beta$ es un vector de parámetros a estimar, en específico $\\beta_0, \\beta_1, \\dots \\beta_n$, esto es: $n+1$ parámetros a estimar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $m=3$ y $A \\in \\mathbb{R}^{3 \\times 2}$ geométricamente el problema de mínimos cuadrados se puede visualizar con el siguiente dibujo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/zkbhzv9a2jiw11b/espacio_generado_columnas_de_A.png?dl=0\" heigth=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y por el dibujo se tiene que cumplir que $A^Tr(x)=0$. La ecuación anterior conduce a las **ecuaciones normales**: \n",
    "\n",
    "$$0=A^Tr(x)=A^T(b-Ax)=A^Tb-A^TAx.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo en mínimos cuadrados lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los mínimos cuadrados lineales se supone:  $f(x|\\beta) = \\displaystyle \\sum_{j=0}^n\\beta_j\\phi_j(x)$ con $\\phi_j: \\mathbb{R} \\rightarrow \\mathbb{R}$ funciones conocidas por lo que se tiene una gran flexibilidad para el proceso de ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** \n",
    "\n",
    "* Si $n=m$ entonces se tiene un problema de interpolación.\n",
    "* x se nombra variable **regresora**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo ajustar el modelo anterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo siguiente se **asume** $n+1 \\leq m+1$ (tenemos más puntos $(x_i,y_i)$'s que parámetros a estimar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar el ajuste de mínimos cuadrados se utilizan las ecuaciones normales: $$A^TA\\beta=A^Ty$$ donde: $A$ se construye con las $\\phi_j$'s evaluadas en los puntos $x_i$'s, el vector $\\beta$ contiene a los parámetros $\\beta_j$'s a estimar y el vector $y$, la variable **respuesta**, se construye con los puntos $y_i$'s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = \\left[\\begin{array}{cccc}\n",
    "\\phi_0(x_0) &\\phi_1(x_0)&\\dots&\\phi_n(x_0)\\\\\n",
    "\\phi_0(x_1) &\\phi_1(x_1)&\\dots&\\phi_n(x_1)\\\\\n",
    "\\vdots &\\vdots& \\vdots&\\vdots\\\\\n",
    "\\phi_0(x_n) &\\phi_1(x_n)&\\dots&\\phi_n(x_n)\\\\\n",
    "\\vdots &\\vdots& \\vdots&\\vdots\\\\\n",
    "\\phi_0(x_{m-1}) &\\phi_1(x_{m-1})&\\dots&\\phi_n(x_{m-1})\\\\\n",
    "\\phi_0(x_m) &\\phi_1(x_m)&\\dots&\\phi_n(x_m)\n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^{(m+1)x(n+1)},\n",
    "\\beta=\n",
    "\\left[\\begin{array}{c}\n",
    "\\beta_0\\\\\n",
    "\\beta_1\\\\\n",
    "\\vdots \\\\\n",
    "\\beta_n\n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^n,\n",
    "y=\n",
    "\\left[\\begin{array}{c}\n",
    "y_0\\\\\n",
    "y_1\\\\\n",
    "\\vdots \\\\\n",
    "y_m\n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y si $A$ es de $rank$ completo (tiene $n+1$ columnas linealmente independientes) se calcula la factorización $QR$ de $A$ : $A = QR$ y entonces: $$A^TA\\beta = A^Ty$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y como $A=QR$ se tiene: $A^TA = (R^TQ^T)(QR)$ y $A^T = R^TQ^T$ por lo que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(R^TQ^T)(QR) \\beta =  R^TQ^T y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y usando que $Q$ tiene columnas ortonormales:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R^TR\\beta = R^TQ^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como $A$ tiene $n$ columnas linealmente independientes, la matriz $R$ es invertible por lo que $R^T$ también lo es y finalmente se tiene el sistema de ecuaciones por resolver:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R\\beta = Q^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de la **regresión lineal** se ajusta un modelo de la forma: $f(x|\\beta) = \\beta_0 + \\beta_1 x$ a los datos $(x_i,y_i)$'s $\\forall i=0,1,\\dots,m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** En este caso se eligen $\\phi_0(x) = 1$, $\\phi_1(x) =x$. Y tenemos que estimar dos parámetros: $\\beta_0, \\beta_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pprint\n",
    "np.set_printoptions(precision = 2) #sólo dos decimales que se muestren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1989) #para reproducibilidad\n",
    "mpoints = 20\n",
    "x = np.random.randn(mpoints) \n",
    "y = -3*x + np.random.normal(2,1,mpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los datos ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y, 'r*')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Puntos ejemplo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### El ajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con numpy podemos usar la función `polyfit` en el paquete de `numpy` para realizar el ajuste: (ver [numpy.polyfit](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el tercer argumento de polyfit especifica el grado del polinomio a ajustar. \n",
    "#Usaremos ngrado = 1 pues queremos ajustar una recta\n",
    "ngrado = 1\n",
    "coeficientes = np.polyfit(x,y,ngrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([-2.65,  2.03])\n"
     ]
    }
   ],
   "source": [
    "#Una vez realizado el llamado a la función polyfit se regresan los coeficientes de x\n",
    "#ordenados del mayor grado al menor.\n",
    "pprint.pprint(coeficientes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces nuestro polinomio es: $$p_{1}(x) = -2.65x + 2.03$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y así tenemos nuestras beta's ajustadas $\\hat{\\beta_0} = 2.03$, $\\hat{\\beta_1} = -2.65$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### La gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nos gustaría graficar el modelo en el intervalo $[min(x),max(x)]$ con $min(x)$ la entrada con valor mínimo del numpy array $x$ y $max(x)$ su entrada con valor máximo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lo anterior debemos obtener los valores ajustados al evaluar $p_1(x)$ los valores de $x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ajustadas_numpy = coeficientes[1] + coeficientes[0] * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y_ajustadas_numpy, 'k-',x, y, 'r*')\n",
    "plt.legend(['modelo lineal','datos'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### También podemos obtener lo anterior con la factorización QR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construimos a la matriz A:\n",
    "A=np.ones((mpoints,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[:,1] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  , -0.26],\n",
       "       [ 1.  ,  0.09],\n",
       "       [ 1.  ,  0.43],\n",
       "       [ 1.  ,  0.9 ],\n",
       "       [ 1.  ,  0.56],\n",
       "       [ 1.  ,  0.44],\n",
       "       [ 1.  ,  0.38],\n",
       "       [ 1.  , -0.15],\n",
       "       [ 1.  ,  0.78],\n",
       "       [ 1.  , -0.02],\n",
       "       [ 1.  ,  1.61],\n",
       "       [ 1.  , -0.37],\n",
       "       [ 1.  ,  0.36],\n",
       "       [ 1.  ,  0.17],\n",
       "       [ 1.  ,  2.52],\n",
       "       [ 1.  ,  0.14],\n",
       "       [ 1.  ,  1.16],\n",
       "       [ 1.  ,  0.59],\n",
       "       [ 1.  , -1.2 ],\n",
       "       [ 1.  , -0.37]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q,R = np.linalg.qr(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 2.03, -2.65])\n"
     ]
    }
   ],
   "source": [
    "#Resolvemos el sistema R*beta = Q^T*y\n",
    "beta = np.linalg.solve(R,Q.T@y)\n",
    "pprint.pprint(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ajustadas_QR = A@beta\n",
    "#obsérvese que la línea anterior es equivalente a realizar:\n",
    "#y_ajustadas_QR = beta[0] + beta[1]*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y_ajustadas_QR , 'k-',x, y, 'r*')\n",
    "plt.legend(['modelo lineal','datos'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**También podemos obtener el ajuste anterior con optimización numérica**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f_o=\\displaystyle \\sum_{i=0}^{20} (y_i -f(x_i|\\beta))^2 = \\displaystyle \\sum_{i=0}^{20} (y_i - (\\beta_0 + \\beta_1 x_i))^2 = ||y - A \\beta||_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con $y \\in \\mathbb{R}^{20}, A \\in \\mathbb{R}^{20 \\times 2}, \\beta \\in \\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema de optimización numérica:\n",
    "\n",
    "$$\\displaystyle \\min_{\\beta \\in \\mathbb{R}^n} ||y - A\\beta||_2^2$$\n",
    "\n",
    "**¿Solución?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reescribimos $f_o$ como $f_o(\\beta) = (y-A\\beta)^T(y-A\\beta) = y^Ty-2\\beta^TA^Ty + \\beta^TA^TA\\beta$, observa que esta última expresión es un número $\\mathbb{R}$. \n",
    "\n",
    "Por lo anterior: $\\nabla f_o(\\beta) = -2A^Ty + 2A^TA\\beta$. Esto conduce a una forma **cerrada** de la solución a la ecuación (no lineal): $\\nabla f_o(\\beta)= 0$ dada por $A^TA \\beta=A^Ty$ (que son las ecuaciones normales!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución como la encontramos en el ejemplo anterior es considerar un método iterativo en el que iniciamos con un punto inicial $x^{(0)}$ y las actualizaciones se realizan con el gradiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^{(k)} = x^{(k-1)} - \\nabla f\\left(x^{(k-1)}\\right), k=1,2,\\dots$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y como el óptimo de $-2A^Ty + 2A^TA\\beta$ es el mismo que $A^Ty + A^TA\\beta$, utilizamos esta última expresión (que corresponde a $f_o = \\frac{1}{2}y^Ty-\\beta^TA^Ty + \\frac{1}{2}\\beta^TA^TA\\beta$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cte=-np.transpose(A)@y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20.1,  23.7])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = lambda beta_fun: cte + np.transpose(A)@(A@beta_fun)\n",
    "    #observa que no hacemos la multiplicación (A^T*A)*beta, mejor hacemos\n",
    "    #primero A*beta y luego multiplicacmos por A^T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = np.array([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_0=.130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = beta_0 - t_0*gf(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.61, -3.08])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1=.0625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_2 = beta_1 - t_1*gf(beta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.09, -2.97])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_2 = .0625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_3 = beta_2 - t_2*gf(beta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.17, -2.71])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_3 = .0625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_4 = beta_3 - t_3*gf(beta_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.02, -2.72])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_4 = .0625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_5 = beta_4 - t_4*gf(beta_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.07, -2.66])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la Hessiana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = beta_0 - np.linalg.solve(np.transpose(A)@A,gf(beta_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.03, -2.65])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios:**\n",
    "\n",
    "* El cálculo anterior lo realizamos por lotes o *batch*. \n",
    "* El nombre de *batch* o lotes se utiliza pues la información de primer o segundo orden es calculada utilizando todos los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Optimización numérica convexa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
