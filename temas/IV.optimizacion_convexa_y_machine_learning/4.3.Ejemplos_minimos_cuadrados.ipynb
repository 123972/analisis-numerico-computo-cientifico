{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mínimos cuadrados lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supóngase que se han realizado mediciones de un fenómeno de interés en diferentes puntos $x_i$'s resultando en cantidades $y_i$'s $\\forall i=0,1,\\dots, m$ (se tienen $m+1$ puntos) y además las $y_i$'s contienen un ruido aleatorio causado por errores de medición:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/iydpi0m8ndqzb0s/mcuadrados_1.jpg?dl=0\" heigth=\"350\" width=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de los mínimos cuadrados lineales es construir una curva, $f(x|\\beta)$ que \"mejor\" se ajuste a los datos $(x_i,y_i)$, $\\forall i=0,1,\\dots,m$. El término de \"mejor\" se refiere a que la suma: $$\\displaystyle \\sum_{i=0}^m (y_i -f(x_i|\\beta))^2$$ sea lo más pequeña posible, esto es, a que la suma de las distancias verticales entre $y_i$ y $f(x_i|\\beta)$ $\\forall i=0,1,\\dots,m$ al cuadrado sea mínima:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/0dhzv336jj6ep4z/mcuadrados_2.jpg?dl=0\" heigth=\"350\" width=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:**\n",
    "\n",
    "* La notación $f(x|\\beta)$ se utiliza para denotar que $\\beta$ es un vector de parámetros a estimar, en específico $\\beta_0, \\beta_1, \\dots \\beta_n$, esto es: $n+1$ parámetros a estimar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $m=3$ y $A \\in \\mathbb{R}^{3 \\times 2}$ geométricamente el problema de mínimos cuadrados se puede visualizar con el siguiente dibujo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/zkbhzv9a2jiw11b/espacio_generado_columnas_de_A.png?dl=0\" heigth=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo en mínimos cuadrados lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los mínimos cuadrados lineales se supone:  $f(x|\\beta) = \\displaystyle \\sum_{j=0}^n\\beta_j\\phi_j(x)$ con $\\phi_j: \\mathbb{R} \\rightarrow \\mathbb{R}$ funciones conocidas por lo que se tiene una gran flexibilidad para el proceso de ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** \n",
    "\n",
    "* Si $n=m$ entonces se tiene un problema de interpolación.\n",
    "* x se nombra variable **regresora**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo ajustar el modelo anterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo siguiente se **asume** $n+1 \\leq m+1$ (tenemos más puntos $(x_i,y_i)$'s que parámetros a estimar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar el ajuste de mínimos cuadrados se utilizan las ecuaciones normales: $$A^TA\\beta=A^Ty$$ donde: $A$ se construye con las $\\phi_j$'s evaluadas en los puntos $x_i$'s, el vector $\\beta$ contiene a los parámetros $\\beta_j$'s a estimar y el vector $y$, la variable **respuesta**, se construye con los puntos $y_i$'s:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = \\left[\\begin{array}{cccc}\n",
    "\\phi_0(x_0) &\\phi_1(x_0)&\\dots&\\phi_n(x_0)\\\\\n",
    "\\phi_0(x_1) &\\phi_1(x_1)&\\dots&\\phi_n(x_1)\\\\\n",
    "\\vdots &\\vdots& \\vdots&\\vdots\\\\\n",
    "\\phi_0(x_n) &\\phi_1(x_n)&\\dots&\\phi_n(x_n)\\\\\n",
    "\\vdots &\\vdots& \\vdots&\\vdots\\\\\n",
    "\\phi_0(x_{m-1}) &\\phi_1(x_{m-1})&\\dots&\\phi_n(x_{m-1})\\\\\n",
    "\\phi_0(x_m) &\\phi_1(x_m)&\\dots&\\phi_n(x_m)\n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^{(m+1)x(n+1)},\n",
    "\\beta=\n",
    "\\left[\\begin{array}{c}\n",
    "\\beta_0\\\\\n",
    "\\beta_1\\\\\n",
    "\\vdots \\\\\n",
    "\\beta_n\n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^n,\n",
    "y=\n",
    "\\left[\\begin{array}{c}\n",
    "y_0\\\\\n",
    "y_1\\\\\n",
    "\\vdots \\\\\n",
    "y_m\n",
    "\\end{array}\n",
    "\\right] \\in \\mathbb{R}^m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y si $A$ es de $rank$ completo (tiene $n+1$ columnas linealmente independientes) se calcula la factorización $QR$ de $A$ : $A = QR$ y entonces: $$A^TA\\beta = A^Ty$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y como $A=QR$ se tiene: $A^TA = (R^TQ^T)(QR)$ y $A^T = R^TQ^T$ por lo que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(R^TQ^T)(QR) \\beta =  R^TQ^T y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y usando que $Q$ tiene columnas ortonormales:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R^TR\\beta = R^TQ^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como $A$ tiene $n$ columnas linealmente independientes, la matriz $R$ es invertible por lo que $R^T$ también lo es y finalmente se tiene el sistema de ecuaciones por resolver:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R\\beta = Q^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘iterators’, ‘foreach’, ‘shape’\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(c(\"latex2exp\",\"glmnet\"),lib=\"/usr/local/lib/R/site-library/\",\n",
    "                repos=\"https://cran.itam.mx/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_index<-function(vec,index,h){\n",
    "    '\n",
    "    Auxiliary function for gradient and Hessian computation.\n",
    "    Args:\n",
    "        vec (double): vector\n",
    "        index (int): index.\n",
    "        h (float):   quantity that vec[index] will be increased.\n",
    "    Returns:\n",
    "        vec (double): vector with vec[index] increased by h.\n",
    "    '\n",
    "    vec[index]<-vec[index]+h\n",
    "    vec\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_approximation<-function(f,x,h=1e-8){\n",
    "    '\n",
    "    Numerical approximation of gradient for function f using forward differences.\n",
    "    Args:\n",
    "        f (expression): definition of function f.\n",
    "        x (double): vector that holds values where gradient will be computed.\n",
    "        h (float): step size for forward differences, tipically h=1e-8\n",
    "    Returns:\n",
    "        gf (array): numerical approximation to gradient of f.\n",
    "\n",
    "    '\n",
    "    n<-length(x)\n",
    "    gf<-vector(\"double\",n)\n",
    "    for(i in 1:n){\n",
    "        gf[i]=(f(inc_index(x,i,h))-f(x))\n",
    "    }\n",
    "    gf/h\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hessian_approximation<-function(f,x,h=1e-6){\n",
    "    '\n",
    "    Numerical approximation of Hessian for function f using forward differences.\n",
    "    Args:\n",
    "        f (expression): definition of function f.\n",
    "        x (double): vector that holds values where Hessian will be computed.\n",
    "        h (float): step size for forward differences, tipically h=1e-6\n",
    "    Returns:\n",
    "        Hf (double): matrix of numerical approximation to Hessian of f.\n",
    "    '\n",
    "    n<-length(x)\n",
    "    Hf<-matrix(rep(0,n^2),nrow=n,ncol=n)\n",
    "    f_x<-f(x)\n",
    "    for(i in 1:n){\n",
    "        x_inc_in_i<-inc_index(x,i,h)\n",
    "        f_x_inc_in_i<-f(x_inc_in_i)\n",
    "        for(j in i:n){\n",
    "            dif<-f(inc_index(x_inc_in_i,j,h))-f_x_inc_in_i-f(inc_index(x,j,h))+f_x\n",
    "            Hf[i,j]<-dif\n",
    "            if(j!=i)\n",
    "                Hf[j,i]<-dif\n",
    "        }\n",
    "    }\n",
    "    Hf/h^2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_search_by_backtracking<-function(f,dir_desc,x,\n",
    "                                      der_direct, alpha=.15, beta=.5){\n",
    "    '\n",
    "    Line search that sufficiently decreases f restricted to a ray in the direction dir_desc.\n",
    "    Args:\n",
    "        alpha (float): parameter in line search with backtracking, tipically .15\n",
    "        beta (float): parameter in line search with backtracking, tipically .5\n",
    "        f (expression): definition of function f.\n",
    "        dir_desc (double): vector of descent direction.\n",
    "        x (double): vector that holds values where line search will be performed.\n",
    "        der_direct (float): directional derivative of f.\n",
    "    Returns:\n",
    "        t (float): positive number for stepsize along dir_desc that sufficiently decreases f.\n",
    "    '\n",
    "    t<-1\n",
    "    if (alpha > 1/2){\n",
    "        print('alpha must be less than or equal to 1/2')\n",
    "        t <- -1\n",
    "    }\n",
    "    if (beta>1){\n",
    "        print('beta must be less than 1')\n",
    "        t <- -1\n",
    "    }\n",
    "    if (t!=-1){\n",
    "        eval1 <- f(x+t*dir_desc)\n",
    "        eval2 <- f(x) + alpha*t*der_direct\n",
    "        while (eval1 > eval2){\n",
    "            t<-beta*t\n",
    "            eval1 <- f(x+t*dir_desc)\n",
    "            eval2 <- f(x)+alpha*t*der_direct\n",
    "        }\n",
    "    }else\n",
    "        t <- -1\n",
    "    t\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Euclidian_norm<-function(vec){\n",
    "    sqrt(sum(vec*vec))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error<-function(x_obj,x_approx){\n",
    "    '\n",
    "    Relative error between x_obj and x_approx.\n",
    "    '\n",
    "    if (Euclidian_norm(x_obj) > .Machine$double.eps){\n",
    "        Err<-Euclidian_norm(x_obj-x_approx)/Euclidian_norm(x_obj)\n",
    "    }else\n",
    "        Err<-Euclidian_norm(x_obj-x_approx)\n",
    "    Err\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent<-function(f, x_0, tol, \n",
    "                        tol_backtracking, x_ast, p_ast, maxiter){\n",
    "    '\n",
    "    Method of gradient descent to numerically approximate solution of min f.\n",
    "    Args:\n",
    "        f (expression): definition of function f.\n",
    "        x_0 (double): vector of initial point for gradient descent method.\n",
    "        tol (float): tolerance that will halt method. Controls norm of gradient of f.\n",
    "        tol_backtracking (float): tolerance that will halt method. Controls value of line search by backtracking.\n",
    "        x_ast (double): vector solution of min f, now its required that user knows the solution...\n",
    "        p_ast (double): vector value of f(x_ast), now its required that user knows the solution...\n",
    "        maxiter (int): maximum number of iterations\n",
    "    Returns:\n",
    "        x (double): vector approximation of x_ast.\n",
    "        iteration (int): number of iterations.\n",
    "        Err_plot (double): vector array of absolute error between p_ast and f(x) with x approximation.\n",
    "                          of x_ast. Useful for plotting.\n",
    "        x_plot (double): vector array that containts in columns vector of approximations. Last column\n",
    "                        contains x, approximation of solution. Useful for plotting.\n",
    "    '\n",
    "    iteration <- 1\n",
    "    x <- x_0\n",
    "    \n",
    "    feval <- f(x)\n",
    "    gfeval <- gradient_approximation(f,x)\n",
    "\n",
    "    normgf <- Euclidian_norm(gfeval)\n",
    "    \n",
    "    Err_plot_aux <- vector(\"double\",maxiter)\n",
    "    Err_plot_aux[iteration] <- abs(feval-p_ast)\n",
    "    \n",
    "    Err <- compute_error(x_ast,x)\n",
    "    n <- length(x)\n",
    "    x_plot <- matrix(0,nrow=n,ncol=maxiter)\n",
    "    x_plot[,iteration] <- x\n",
    "    \n",
    "    cat(sprintf(\"I    Normagf   Error x_ast   Error p_ast   line search\\n\"))\n",
    "    cat(sprintf(\"%d    %.2e   %0.2e      %0.2e      %s\\n\",iteration,normgf,Err,Err_plot_aux[iteration],\"---\"))\n",
    "    iteration<-iteration + 1\n",
    "    while(normgf>tol && iteration <= maxiter){\n",
    "        dir_desc <- -gfeval\n",
    "        der_direct <- sum(gfeval*dir_desc)\n",
    "        t <- line_search_by_backtracking(f,dir_desc,x,der_direct)\n",
    "        x <- x + t*dir_desc\n",
    "        feval <- f(x)\n",
    "        gfeval <- gradient_approximation(f,x)\n",
    "        normgf <- Euclidian_norm(gfeval)\n",
    "        Err_plot_aux[iteration] <- abs(feval-p_ast);\n",
    "        x_plot[,iteration] <- x\n",
    "        Err <- compute_error(x_ast,x)\n",
    "        cat(sprintf(\"%d    %.2e   %0.2e      %0.2e      %s\\n\",iteration,normgf,Err,Err_plot_aux[iteration],t))\n",
    "        if (t<tol_backtracking){ #if t is less than tol_backtracking then we need to check the reason\n",
    "            iter_salida <- iteration\n",
    "            iteration <- maxiter\n",
    "        }\n",
    "        iteration <- iteration + 1\n",
    "    } #while\n",
    "    cat(sprintf(\"Error of x with respect to x_ast: %.2e\\n\",Err))\n",
    "    cat(sprintf(\"Approximate solution:\"))\n",
    "    print(x)\n",
    "    cond <- Err_plot_aux > .Machine$double.eps*10**(-2)\n",
    "    Err_plot = Err_plot_aux[cond]\n",
    "    cond<- apply(x_plot,2,function(x) all(x==0))\n",
    "    x_plot <- x_plot[,!cond]\n",
    "    if (iteration == maxiter && t < tol_backtracking){\n",
    "        print(\"Backtracking value less than tol_backtracking, check approximation\")\n",
    "        iteration<-iter_salida\n",
    "    }\n",
    "   list(x,iteration-1,Err_plot,x_plot)\n",
    "    \n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "Loaded glmnet 3.0-2\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "library(latex2exp)\n",
    "library(glmnet)\n",
    "library(magrittr)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) $$\\min \\quad \\frac{1}{2}y^Ty-\\beta^TA^Ty + \\frac{1}{2}\\beta^TA^TA\\beta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1989) #para reproducibilidad\n",
    "mpoints <- 20\n",
    "df <-  data.frame(x=rnorm(mpoints))\n",
    "y <- -3*df$x + rnorm(mpoints,2,1)\n",
    "df$y <- y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg <- ggplot(data=df, aes(x=x, y=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC7lBMVEUAAAABAQECAgIDAwME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\nQCISBCQiQUAiEvT/dznEQWYyEOMAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg + \n",
    "geom_point(aes(x=x,y=y),size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model <- lm(df$y~df$x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>1.56566282784822</dd>\n",
       "\t<dt>df$x</dt>\n",
       "\t\t<dd>-2.81058194144795</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 1.56566282784822\n",
       "\\item[df\\textbackslash{}\\$x] -2.81058194144795\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   1.56566282784822df$x\n",
       ":   -2.81058194144795\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)        df$x \n",
       "   1.565663   -2.810582 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_model$coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAACXBIWXMAABJ0AAASdAHeZh94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\nDgAAQCcIdgAAADrx/wGBLisLhEo3+QAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg +\n",
    "geom_point(aes(x=x,y=y),size=2) +\n",
    "geom_smooth(method='lm',colour='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método de descenso gradiente con $\\beta_0=(0,0)^T$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) $$\\min \\quad \\frac{1}{2}y^Ty-\\beta^TA^Ty + \\frac{1}{2}\\beta^TA^TA\\beta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cte <- sum(y*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A <- matrix(c(rep(1,mpoints),df$x),nrow=mpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo <-function(beta)1/2*cte - sum(beta*(t(A)%*%y)) + 1/2*sum(beta*(t(A)%*%(A%*%beta)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 <- matrix(c(0,0),nrow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ast <- c(linear_model$coefficients[1],linear_model$coefficients[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>1.56566282784822</dd>\n",
       "\t<dt>df$x</dt>\n",
       "\t\t<dd>-2.81058194144795</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 1.56566282784822\n",
       "\\item[df\\textbackslash{}\\$x] -2.81058194144795\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   1.56566282784822df$x\n",
       ":   -2.81058194144795\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)        df$x \n",
       "   1.565663   -2.810582 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ast <- fo(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "11.1174998924303"
      ],
      "text/latex": [
       "11.1174998924303"
      ],
      "text/markdown": [
       "11.1174998924303"
      ],
      "text/plain": [
       "[1] 11.1175"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol <- 1e-8\n",
    "tol_backtracking <- 1e-14\n",
    "maxiter <- 30\n",
    "p_ast <- fo(beta_ast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search\n",
      "1    7.73e+01   1.00e+00      1.24e+02      ---\n",
      "2    4.17e+01   5.17e-01      3.46e+01      0.0625\n",
      "3    2.41e+01   2.95e-01      1.14e+01      0.0625\n",
      "4    1.41e+01   1.73e-01      3.91e+00      0.0625\n",
      "5    8.27e+00   1.01e-01      1.35e+00      0.0625\n",
      "6    4.86e+00   5.95e-02      4.65e-01      0.0625\n",
      "7    2.85e+00   3.49e-02      1.60e-01      0.0625\n",
      "8    1.68e+00   2.05e-02      5.53e-02      0.0625\n",
      "9    9.84e-01   1.20e-02      1.91e-02      0.0625\n",
      "10    5.78e-01   7.07e-03      6.58e-03      0.0625\n",
      "11    3.39e-01   4.15e-03      2.27e-03      0.0625\n",
      "12    1.99e-01   2.44e-03      7.83e-04      0.0625\n",
      "13    1.17e-01   1.43e-03      2.70e-04      0.0625\n",
      "14    6.88e-02   8.42e-04      9.31e-05      0.0625\n",
      "15    4.04e-02   4.94e-04      3.21e-05      0.0625\n",
      "16    2.37e-02   2.90e-04      1.11e-05      0.0625\n",
      "17    1.39e-02   1.70e-04      3.82e-06      0.0625\n",
      "18    8.19e-03   1.00e-04      1.32e-06      0.0625\n",
      "19    4.81e-03   5.89e-05      4.56e-07      0.0625\n",
      "20    2.82e-03   3.46e-05      1.57e-07      0.0625\n",
      "21    1.65e-03   2.03e-05      5.41e-08      0.0625\n",
      "22    9.67e-04   1.18e-05      1.84e-08      0.0625\n",
      "23    5.69e-04   6.95e-06      6.35e-09      0.0625\n",
      "24    3.34e-04   4.11e-06      2.22e-09      0.0625\n",
      "25    1.95e-04   2.39e-06      7.51e-10      0.0625\n",
      "26    1.15e-04   1.40e-06      2.56e-10      0.0625\n",
      "27    6.98e-05   8.42e-07      9.32e-11      0.0625\n",
      "28    3.99e-05   5.13e-07      3.46e-11      0.0625\n",
      "29    2.45e-05   2.62e-07      9.00e-12      0.0625\n",
      "30    2.01e-06   3.49e-08      1.56e-13      0.03125\n",
      "Error of x with respect to x_ast: 3.49e-08\n",
      "Approximate solution:          [,1]\n",
      "[1,]  1.565663\n",
      "[2,] -2.810582\n"
     ]
    }
   ],
   "source": [
    "l<-gradient_descent(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [,1]\n",
      "[1,]  1.565663\n",
      "[2,] -2.810582\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)        df$x \n",
      "   1.565663   -2.810582 \n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg <- ggplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC+lBMVEUAAAABAQECAgIDAwME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\nTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg +\n",
    "geom_line(aes(x=25:total_of_iterations,y=Err_plot[25:length(Err_plot)])) + \n",
    "xlab('Iterations') + ylab(TeX('f_o(x^k)-p^*'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penalización lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hessian_evaluation<-function()1/mpoints*t(A)%*%A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_evaluation<- function(beta) 1/mpoints * t(A)%*%(A%*%beta-y) + reg*sign(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coordinate descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_descent<-function(f, x_0, tol, \n",
    "                        tol_backtracking, x_ast, p_ast, maxiter){\n",
    "    '\n",
    "    Method of coordinate descent to numerically approximate solution of min f.\n",
    "    Args:\n",
    "        f (expression): definition of function f.\n",
    "        x_0 (double): vector of initial point for coordinate descent method.\n",
    "        tol (float): tolerance that will halt method. Controls norm of gradient of f.\n",
    "        tol_backtracking (float): tolerance that will halt method. Controls value of line search by backtracking.\n",
    "        x_ast (double): vector solution of min f, now its required that user knows the solution...\n",
    "        p_ast (double): vector value of f(x_ast), now its required that user knows the solution...\n",
    "        maxiter (int): maximum number of iterations\n",
    "    Returns:\n",
    "        x (double): vector approximation of x_ast.\n",
    "        iteration (int): number of iterations.\n",
    "        Err_plot (double): vector array of absolute error between p_ast and f(x) with x approximation.\n",
    "                          of x_ast. Useful for plotting.\n",
    "        x_plot (double): vector array that containts in columns vector of approximations. Last column\n",
    "                        contains x, approximation of solution. Useful for plotting.\n",
    "    '\n",
    "    iteration <- 1\n",
    "    x <- x_0\n",
    "    \n",
    "    feval <- f(x)\n",
    "    gfeval <- gradient_approximation(f,x)\n",
    "\n",
    "    normgf <- Euclidian_norm(gfeval)\n",
    "    \n",
    "    Err_plot_aux <- vector(\"double\",maxiter)\n",
    "    Err_plot_aux[iteration] <- abs(feval-p_ast)\n",
    "    \n",
    "    Err <- compute_error(x_ast,x)\n",
    "    n <- length(x)\n",
    "    x_plot <- matrix(0,nrow=n,ncol=maxiter)\n",
    "    x_plot[,iteration] <- x\n",
    "    \n",
    "    cat(sprintf(\"I    Normagf   Error x_ast   Error p_ast   line search\\n\"))\n",
    "    cat(sprintf(\"%d    %.2e   %0.2e      %0.2e      %s\\n\",iteration,normgf,Err,Err_plot_aux[iteration],\"---\"))\n",
    "    iteration<-iteration + 1\n",
    "    while(normgf>tol && iteration <= maxiter){\n",
    "        ind_maximo <- which.max(abs(gfeval))\n",
    "        e_canonico <- vector(\"integer\",n)\n",
    "        e_canonico[ind_maximo] <- 1\n",
    "        dir_desc <- -gfeval[ind_maximo]*e_canonico\n",
    "        der_direct <- sum(gfeval*dir_desc)\n",
    "        t <- line_search_by_backtracking(f,dir_desc,x,der_direct)\n",
    "        x <- x + t*dir_desc\n",
    "        feval <- f(x)\n",
    "        gfeval <- gradient_approximation(f,x)\n",
    "        normgf <- Euclidian_norm(gfeval)\n",
    "        Err_plot_aux[iteration] <- abs(feval-p_ast);\n",
    "        x_plot[,iteration] <- x\n",
    "        Err <- compute_error(x_ast,x)\n",
    "        cat(sprintf(\"%d    %.2e   %0.2e      %0.2e      %s\\n\",iteration,normgf,Err,Err_plot_aux[iteration],t))\n",
    "        if (t<tol_backtracking){ #if t is less than tol_backtracking then we need to check the reason\n",
    "            iter_salida <- iteration\n",
    "            iteration <- maxiter\n",
    "        }\n",
    "        iteration <- iteration + 1\n",
    "    } #while\n",
    "    cat(sprintf(\"Error of x with respect to x_ast: %.2e\\n\",Err))\n",
    "    cat(sprintf(\"Approximate solution:\"))\n",
    "    print(x)\n",
    "    cond <- Err_plot_aux > .Machine$double.eps*10**(-2)\n",
    "    Err_plot = Err_plot_aux[cond]\n",
    "    cond<- apply(x_plot,2,function(x) all(x==0))\n",
    "    x_plot <- x_plot[,!cond]\n",
    "    if (iteration == maxiter && t < tol_backtracking){\n",
    "        print(\"Backtracking value less than tol_backtracking, check approximation\")\n",
    "        iteration<-iter_salida\n",
    "    }\n",
    "   list(x,iteration-1,Err_plot,x_plot)\n",
    "    \n",
    "}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newtons method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newtons_method<-function(f, x_0, tol, \n",
    "                        tol_backtracking, x_ast, p_ast, maxiter){\n",
    "    '\n",
    "    Method of gradient descent to numerically approximate solution of min f.\n",
    "    Args:\n",
    "        f (expression): definition of function f.\n",
    "        x_0 (double): vector of initial point for gradient descent method.\n",
    "        tol (float): tolerance that will halt method. Controls norm of gradient of f.\n",
    "        tol_backtracking (float): tolerance that will halt method. Controls value of line search by backtracking.\n",
    "        x_ast (double): vector solution of min f, now its required that user knows the solution...\n",
    "        p_ast (double): vector value of f(x_ast), now its required that user knows the solution...\n",
    "        maxiter (int): maximum number of iterations\n",
    "    Returns:\n",
    "        x (double): vector approximation of x_ast.\n",
    "        iteration (int): number of iterations.\n",
    "        Err_plot (double): vector array of absolute error between p_ast and f(x) with x approximation.\n",
    "                          of x_ast. Useful for plotting.\n",
    "        x_plot (double): vector array that containts in columns vector of approximations. Last column\n",
    "                        contains x, approximation of solution. Useful for plotting.\n",
    "    '\n",
    "    iteration <- 1\n",
    "    x <- x_0\n",
    "    \n",
    "    feval <- f(x)\n",
    "    gfeval <- gradient_approximation(f,x)\n",
    "    Hfeval <- Hessian_approximation(f,x)\n",
    "    condHf <- kappa(Hfeval, exact=TRUE)\n",
    "    \n",
    "    normgf <- Euclidian_norm(gfeval)\n",
    "    \n",
    "    Err_plot_aux <- vector(\"double\",maxiter)\n",
    "    Err_plot_aux[iteration] <- abs(feval-p_ast)\n",
    "    \n",
    "    Err <- compute_error(x_ast,x)\n",
    "    n <- length(x)\n",
    "    x_plot <- matrix(0,nrow=n,ncol=maxiter)\n",
    "    x_plot[,iteration] <- x\n",
    "    \n",
    "    #Newton's direction and Newton's decrement\n",
    "    dir_Newton <- solve(Hfeval, gfeval)\n",
    "    dec_Newton <- sum(dir_Newton*(Hfeval%*%dir_Newton))\n",
    "    dir_Newton <- -dir_Newton\n",
    "    \n",
    "    cat(sprintf(\"I    Normagf   Error x_ast   Error p_ast   line search    condHf\\n\"))\n",
    "    cat(sprintf(\"%d    %.2e   %0.2e      %0.2e      %s\\n\",iteration,normgf,Err,Err_plot_aux[iteration],\"---\", condHf))\n",
    "    \n",
    "    stopping_criteria <- dec_Newton/2\n",
    "    iteration<-iteration + 1\n",
    "    while(stopping_criteria>tol && iteration <= maxiter){\n",
    "        der_direct <- -dec_Newton\n",
    "        t <- line_search_by_backtracking(f,dir_Newton,x,der_direct)\n",
    "        x <- x + t*dir_Newton\n",
    "        feval <- f(x)\n",
    "        gfeval <- gradient_approximation(f,x)\n",
    "        Hfeval <- Hessian_approximation(f,x)\n",
    "        normgf <- Euclidian_norm(gfeval)\n",
    "        condHf <- kappa(Hfeval, exact=TRUE)\n",
    "        #Newton's direction and Newton's decrement\n",
    "        dir_Newton = solve(Hfeval, gfeval)\n",
    "        dec_Newton = sum(dir_Newton*(Hfeval%*%dir_Newton))\n",
    "        dir_Newton <- -dir_Newton\n",
    "        Err_plot_aux[iteration] <- abs(feval-p_ast);\n",
    "        x_plot[,iteration] <- x\n",
    "        Err <- compute_error(x_ast,x)\n",
    "        cat(sprintf(\"%d    %.2e   %0.2e      %0.2e      %0.2e    %0.2e\\n\",iteration,normgf,Err,Err_plot_aux[iteration],t,condHf))\n",
    "        stopping_criteria = dec_Newton/2\n",
    "        if (t<tol_backtracking){ #if t is less than tol_backtracking then we need to check the reason\n",
    "            iter_salida <- iteration\n",
    "            iteration <- maxiter\n",
    "        }\n",
    "        iteration <- iteration + 1\n",
    "    } #while\n",
    "    cat(sprintf(\"Error of x with respect to x_ast: %.2e\\n\",Err))\n",
    "    cat(sprintf(\"Approximate solution:\"))\n",
    "    print(x)\n",
    "    cond <- Err_plot_aux > .Machine$double.eps*10**(-2)\n",
    "    Err_plot = Err_plot_aux[cond]\n",
    "    cond<- apply(x_plot,2,function(x) all(x==0))\n",
    "    x_plot <- x_plot[,!cond]\n",
    "    if (iteration == maxiter && t < tol_backtracking){\n",
    "        print(\"Backtracking value less than tol_backtracking, check approximation\")\n",
    "        iteration<-iter_salida\n",
    "    }\n",
    "   list(x,iteration-1,Err_plot,x_plot)\n",
    "    \n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg<-.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "quita_signo<-function(beta){\n",
    "    beta<-sign(beta)*beta\n",
    "    ind <- beta < .Machine$double.xmin & beta > -.Machine$double.xmin \n",
    "    beta[ind] <- .Machine$double.xmin \n",
    "    beta\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo <-function(beta)1/mpoints*(1/2*cte - sum(beta*(t(A)%*%y)) + 1/2*sum(beta*(t(A)%*%(A%*%beta)))) + reg*sum(quita_signo(beta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo <-function(beta)1/mpoints*(1/2*cte - sum(beta*(t(A)%*%y)) + 1/2*sum(beta*(t(A)%*%(A%*%beta)))) + reg*sum(quita_signo(beta[2:length(beta)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0<-c(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>-1.507055</td></tr>\n",
       "\t<tr><td> 6.587020</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 1 of type dbl\n",
       "\\begin{tabular}{l}\n",
       "\t -1.507055\\\\\n",
       "\t  6.587020\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 1 of type dbl\n",
       "\n",
       "| -1.507055 |\n",
       "|  6.587020 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     \n",
       "[1,] -1.507055\n",
       "[2,]  6.587020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gf_evaluation(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-1.50705474766255</li>\n",
       "\t<li>6.58701964084685</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -1.50705474766255\n",
       "\\item 6.58701964084685\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -1.50705474766255\n",
       "2. 6.58701964084685\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -1.507055  6.587020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradient_approximation(fo,beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 <- matrix(c(0,0),nrow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-1.53142094561076</li>\n",
       "\t<li>4.04841022927371</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -1.53142094561076\n",
       "\\item 4.04841022927371\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -1.53142094561076\n",
       "2. 4.04841022927371\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -1.531421  4.048410"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradient_approximation(fo,beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>-1.531421</td></tr>\n",
       "\t<tr><td> 3.548410</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 1 of type dbl\n",
       "\\begin{tabular}{l}\n",
       "\t -1.531421\\\\\n",
       "\t  3.548410\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 1 of type dbl\n",
       "\n",
       "| -1.531421 |\n",
       "|  3.548410 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     \n",
       "[1,] -1.531421\n",
       "[2,]  3.548410"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gf_evaluation(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- glmnet(A,y,alpha=1,lambda=reg,standardize=F,nlambda=1,thresh=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          s0\n",
      "V1  0.000000\n",
      "V2 -2.416619\n"
     ]
    }
   ],
   "source": [
    "print(as.matrix(fit$beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ast <- as.matrix(fit$beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 1 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>s0</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>V1</th><td> 0.000000</td></tr>\n",
       "\t<tr><th scope=row>V2</th><td>-2.416619</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 1 of type dbl\n",
       "\\begin{tabular}{r|l}\n",
       "  & s0\\\\\n",
       "\\hline\n",
       "\tV1 &  0.000000\\\\\n",
       "\tV2 & -2.416619\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 1 of type dbl\n",
       "\n",
       "| <!--/--> | s0 |\n",
       "|---|---|\n",
       "| V1 |  0.000000 |\n",
       "| V2 | -2.416619 |\n",
       "\n"
      ],
      "text/plain": [
       "   s0       \n",
       "V1  0.000000\n",
       "V2 -2.416619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ast <- fo(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3.08082216571328"
      ],
      "text/latex": [
       "3.08082216571328"
      ],
      "text/markdown": [
       "3.08082216571328"
      ],
      "text/plain": [
       "[1] 3.080822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0<-c(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol <- 1e-8\n",
    "tol_backtracking <- 1e-14\n",
    "maxiter <- 30\n",
    "p_ast <- fo(beta_ast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 2 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0.99831254</td><td>0.01065814</td></tr>\n",
       "\t<tr><td>0.01065814</td><td>1.26831878</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       "\t 0.99831254 & 0.01065814\\\\\n",
       "\t 0.01065814 & 1.26831878\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 2 of type dbl\n",
       "\n",
       "| 0.99831254 | 0.01065814 |\n",
       "| 0.01065814 | 1.26831878 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]      \n",
       "[1,] 0.99831254 0.01065814\n",
       "[2,] 0.01065814 1.26831878"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hessian_approximation(fo,beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 2 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>1.00000000</td><td>0.01218318</td></tr>\n",
       "\t<tr><td>0.01218318</td><td>1.26930474</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       "\t 1.00000000 & 0.01218318\\\\\n",
       "\t 0.01218318 & 1.26930474\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 2 of type dbl\n",
       "\n",
       "| 1.00000000 | 0.01218318 |\n",
       "| 0.01218318 | 1.26930474 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]      \n",
       "[1,] 1.00000000 0.01218318\n",
       "[2,] 0.01218318 1.26930474"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hessian_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search\n",
      "1    4.33e+00   1.00e+00      3.66e+00      ---\n",
      "2    1.63e+00   1.62e-01      9.03e-02      0.5\n",
      "3    4.98e-01   6.64e-01      1.12e+00      1\n",
      "4    1.34e-01   6.45e-01      1.21e+00      1\n",
      "5    3.64e-02   6.44e-01      1.22e+00      1\n",
      "6    1.09e-02   6.44e-01      1.22e+00      1\n",
      "7    5.43e-03   6.44e-01      1.22e+00      1\n",
      "8    2.68e-03   6.46e-01      1.22e+00      1\n",
      "9    7.22e-04   6.46e-01      1.22e+00      1\n",
      "10    1.95e-04   6.46e-01      1.22e+00      1\n",
      "11    5.82e-05   6.46e-01      1.22e+00      1\n",
      "12    2.91e-05   6.46e-01      1.22e+00      1\n",
      "13    1.42e-05   6.46e-01      1.22e+00      1\n",
      "14    3.71e-06   6.46e-01      1.22e+00      1\n",
      "15    9.77e-07   6.46e-01      1.22e+00      1\n",
      "16    4.92e-07   6.46e-01      1.22e+00      1\n",
      "17    2.66e-07   6.46e-01      1.22e+00      1\n",
      "18    7.02e-08   6.46e-01      1.22e+00      1\n",
      "19    2.78e-07   6.46e-01      1.22e+00      1\n",
      "20    2.66e-07   6.46e-01      1.22e+00      0.5\n",
      "21    1.78e-07   6.46e-01      1.22e+00      0.00390625\n",
      "22    2.53e-07   6.46e-01      1.22e+00      0.0078125\n",
      "23    2.53e-07   6.46e-01      1.22e+00      9.31322574615479e-10\n",
      "24    2.53e-07   6.46e-01      1.22e+00      9.31322574615479e-10\n",
      "25    2.53e-07   6.46e-01      1.22e+00      9.31322574615479e-10\n",
      "26    2.53e-07   6.46e-01      1.22e+00      9.31322574615479e-10\n",
      "27    2.53e-07   6.46e-01      1.22e+00      9.31322574615479e-10\n",
      "28    2.53e-07   6.46e-01      1.22e+00      9.31322574615479e-10\n",
      "29    2.53e-07   6.46e-01      1.22e+00      9.31322574615479e-10\n",
      "30    2.53e-07   6.46e-01      1.22e+00      9.31322574615479e-10\n",
      "Error of x with respect to x_ast: 6.46e-01\n",
      "Approximate solution:[1]  1.560863 -2.416619\n"
     ]
    }
   ],
   "source": [
    "l<-coordinate_descent(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  1.560863 -2.416619\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          s0\n",
      "V1  0.000000\n",
      "V2 -2.416619\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.86267533861601"
      ],
      "text/latex": [
       "1.86267533861601"
      ],
      "text/markdown": [
       "1.86267533861601"
      ],
      "text/plain": [
       "[1] 1.862675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 29 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td> 0.000000</td><td> 1.556082</td><td> 1.556082</td><td> 1.556082</td><td> 1.556082</td><td> 1.556082</td><td> 1.560837</td><td> 1.560837</td><td> 1.560837</td><td> 1.560837</td><td>⋯</td><td> 1.560863</td><td> 1.560863</td><td> 1.560863</td><td> 1.560863</td><td> 1.560863</td><td> 1.560863</td><td> 1.560863</td><td> 1.560863</td><td> 1.560863</td><td> 1.560863</td></tr>\n",
       "\t<tr><td>-2.024205</td><td>-2.024205</td><td>-2.522240</td><td>-2.388117</td><td>-2.424237</td><td>-2.414510</td><td>-2.414510</td><td>-2.417187</td><td>-2.416466</td><td>-2.416660</td><td>⋯</td><td>-2.416619</td><td>-2.416619</td><td>-2.416619</td><td>-2.416619</td><td>-2.416619</td><td>-2.416619</td><td>-2.416619</td><td>-2.416619</td><td>-2.416619</td><td>-2.416619</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 29 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       "\t  0.000000 &  1.556082 &  1.556082 &  1.556082 &  1.556082 &  1.556082 &  1.560837 &  1.560837 &  1.560837 &  1.560837 & ⋯ &  1.560863 &  1.560863 &  1.560863 &  1.560863 &  1.560863 &  1.560863 &  1.560863 &  1.560863 &  1.560863 &  1.560863\\\\\n",
       "\t -2.024205 & -2.024205 & -2.522240 & -2.388117 & -2.424237 & -2.414510 & -2.414510 & -2.417187 & -2.416466 & -2.416660 & ⋯ & -2.416619 & -2.416619 & -2.416619 & -2.416619 & -2.416619 & -2.416619 & -2.416619 & -2.416619 & -2.416619 & -2.416619\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 29 of type dbl\n",
       "\n",
       "|  0.000000 |  1.556082 |  1.556082 |  1.556082 |  1.556082 |  1.556082 |  1.560837 |  1.560837 |  1.560837 |  1.560837 | ⋯ |  1.560863 |  1.560863 |  1.560863 |  1.560863 |  1.560863 |  1.560863 |  1.560863 |  1.560863 |  1.560863 |  1.560863 |\n",
       "| -2.024205 | -2.024205 | -2.522240 | -2.388117 | -2.424237 | -2.414510 | -2.414510 | -2.417187 | -2.416466 | -2.416660 | ⋯ | -2.416619 | -2.416619 | -2.416619 | -2.416619 | -2.416619 | -2.416619 | -2.416619 | -2.416619 | -2.416619 | -2.416619 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]     \n",
       "[1,]  0.000000  1.556082  1.556082  1.556082  1.556082  1.556082  1.560837\n",
       "[2,] -2.024205 -2.024205 -2.522240 -2.388117 -2.424237 -2.414510 -2.414510\n",
       "     [,8]      [,9]      [,10]     [,11] [,12]     [,13]     [,14]    \n",
       "[1,]  1.560837  1.560837  1.560837 ⋯      1.560863  1.560863  1.560863\n",
       "[2,] -2.417187 -2.416466 -2.416660 ⋯     -2.416619 -2.416619 -2.416619\n",
       "     [,15]     [,16]     [,17]     [,18]     [,19]     [,20]     [,21]    \n",
       "[1,]  1.560863  1.560863  1.560863  1.560863  1.560863  1.560863  1.560863\n",
       "[2,] -2.416619 -2.416619 -2.416619 -2.416619 -2.416619 -2.416619 -2.416619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC8VBMVEUAAAABAQECAgIDAwME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\nQgIE/j9i2hAioJ2o7QAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg +\n",
    "geom_point(aes(x=beta_plot[1,],y=beta_plot[2,]),size=2) +\n",
    "#annotate(geom='text', x=0.5, y=0.47, \n",
    "#         label=TeX(\"x^{(0)}\", output='character'), parse=TRUE) + \n",
    "xlab('x') + ylab('y') + \n",
    "ggtitle(TeX('Iter del método de descenso en gradiente para $f_o$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search    condHf\n",
      "1    4.33e+00   1.00e+00      3.66e+00      ---\n",
      "2    1.00e+00   7.26e-01      8.24e-01      1.00e+00    1.27e+00\n",
      "3    3.68e-03   6.46e-01      1.22e+00      1.00e+00    1.27e+00\n",
      "4    2.53e-07   6.46e-01      1.22e+00      1.00e+00    1.27e+00\n",
      "Error of x with respect to x_ast: 6.46e-01\n",
      "Approximate solution:[1]  1.560863 -2.416620\n"
     ]
    }
   ],
   "source": [
    "l<-Newtons_method(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  1.560863 -2.416620\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          s0\n",
      "V1  0.000000\n",
      "V2 -2.416619\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.86267533861606"
      ],
      "text/latex": [
       "1.86267533861606"
      ],
      "text/markdown": [
       "1.86267533861606"
      ],
      "text/plain": [
       "[1] 1.862675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 3 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td> 1.568228</td><td> 1.561673</td><td> 1.560863</td></tr>\n",
       "\t<tr><td>-3.205128</td><td>-2.413804</td><td>-2.416620</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 3 of type dbl\n",
       "\\begin{tabular}{lll}\n",
       "\t  1.568228 &  1.561673 &  1.560863\\\\\n",
       "\t -3.205128 & -2.413804 & -2.416620\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 3 of type dbl\n",
       "\n",
       "|  1.568228 |  1.561673 |  1.560863 |\n",
       "| -3.205128 | -2.413804 | -2.416620 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      [,2]      [,3]     \n",
       "[1,]  1.568228  1.561673  1.560863\n",
       "[2,] -3.205128 -2.413804 -2.416620"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC8VBMVEUAAAABAQECAgIDAwME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\n5cCQpBwYkpQDQ5JyYEhSDgxJysH/B6kwIkQrnl9UAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg +\n",
    "geom_point(aes(x=beta_plot[1,],y=beta_plot[2,]),size=2) +\n",
    "#annotate(geom='text', x=0.5, y=0.47, \n",
    "#         label=TeX(\"x^{(0)}\", output='character'), parse=TRUE) + \n",
    "xlab('x') + ylab('y') + \n",
    "ggtitle(TeX('Iter del método de descenso en gradiente para $f_o$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo sin intercepto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y <- mtcars %>% select(mpg) %>% as.matrix()\n",
    "X <- mtcars %>% select(-mpg) %>% as.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "A<-X[,c(2,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cte <- sum(y*y)\n",
    "mpoints<-nrow(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "14042.31"
      ],
      "text/latex": [
       "14042.31"
      ],
      "text/markdown": [
       "14042.31"
      ],
      "text/plain": [
       "[1] 14042.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "32"
      ],
      "text/latex": [
       "32"
      ],
      "text/markdown": [
       "32"
      ],
      "text/plain": [
       "[1] 32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo <-function(beta)1/mpoints*(1/2*cte - sum(beta*(t(A)%*%y)) + 1/2*sum(beta*(t(A)%*%(A%*%beta)))) + reg*sum(quita_signo(beta))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- glmnet(A,y,alpha=1,lambda=reg,standardize=F,nlambda=1,intercept=F,thresh=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ast <- as.matrix(fit$beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              s0\n",
      "disp -0.01682177\n",
      "drat  6.59053287\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0<-c(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newtons method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>64876.0375042912</li>\n",
       "\t<li>723.540870239958</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 64876.0375042912\n",
       "\\item 723.540870239958\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 64876.0375042912\n",
       "2. 723.540870239958\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 64876.0375   723.5409"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradient_approximation(fo,beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>disp</th><td>64876.0371</td></tr>\n",
       "\t<tr><th scope=row>drat</th><td>  723.5409</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 1 of type dbl\n",
       "\\begin{tabular}{r|l}\n",
       "\tdisp & 64876.0371\\\\\n",
       "\tdrat &   723.5409\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 1 of type dbl\n",
       "\n",
       "| disp | 64876.0371 |\n",
       "| drat |   723.5409 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      \n",
       "disp 64876.0371\n",
       "drat   723.5409"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gf_evaluation(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 2 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>68106.6012</td><td>774.889486</td></tr>\n",
       "\t<tr><td>  774.8895</td><td>  3.637979</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       "\t 68106.6012 & 774.889486\\\\\n",
       "\t   774.8895 &   3.637979\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 2 of type dbl\n",
       "\n",
       "| 68106.6012 | 774.889486 |\n",
       "|   774.8895 |   3.637979 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]      \n",
       "[1,] 68106.6012 774.889486\n",
       "[2,]   774.8895   3.637979"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hessian_approximation(fo,beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>disp</th><th scope=col>drat</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>disp</th><td>68113.3584</td><td>784.21238</td></tr>\n",
       "\t<tr><th scope=row>drat</th><td>  784.2124</td><td> 13.21221</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 2 of type dbl\n",
       "\\begin{tabular}{r|ll}\n",
       "  & disp & drat\\\\\n",
       "\\hline\n",
       "\tdisp & 68113.3584 & 784.21238\\\\\n",
       "\tdrat &   784.2124 &  13.21221\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 2 of type dbl\n",
       "\n",
       "| <!--/--> | disp | drat |\n",
       "|---|---|---|\n",
       "| disp | 68113.3584 | 784.21238 |\n",
       "| drat |   784.2124 |  13.21221 |\n",
       "\n"
      ],
      "text/plain": [
       "     disp       drat     \n",
       "disp 68113.3584 784.21238\n",
       "drat   784.2124  13.21221"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hessian_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol <- 1e-8\n",
    "tol_backtracking <- 1e-14\n",
    "maxiter <- 30\n",
    "p_ast <- fo(beta_ast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search    condHf\n",
      "1    6.49e+04   8.62e-01      3.10e+04      ---\n",
      "2    4.89e+01   1.28e+00      1.50e+02      1.00e+00    1.64e+04\n",
      "3    1.42e+00   4.42e-02      1.78e-01      1.00e+00    1.66e+04\n",
      "4    2.95e-02   8.68e-04      7.21e-05      1.00e+00    1.62e+04\n",
      "5    3.69e-04   1.65e-05      6.86e-08      1.00e+00    1.57e+04\n",
      "Error of x with respect to x_ast: 1.65e-05\n",
      "Approximate solution:[1] -0.01682385  6.59064139\n"
     ]
    }
   ],
   "source": [
    "l<-Newtons_method(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -0.01682385  6.59064139\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              s0\n",
      "disp -0.01682177\n",
      "drat  6.59053287\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "9.77736750888745"
      ],
      "text/latex": [
       "9.77736750888745"
      ],
      "text/markdown": [
       "9.77736750888745"
      ],
      "text/plain": [
       "[1] 9.777368"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 5 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td> 0.07949562</td><td>-0.02019068</td><td>-0.01675652</td><td>-0.01682385</td></tr>\n",
       "\t<tr><td>1</td><td>-1.81796641</td><td> 6.88212076</td><td> 6.58481401</td><td> 6.59064139</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 5 of type dbl\n",
       "\\begin{tabular}{lllll}\n",
       "\t 1 &  0.07949562 & -0.02019068 & -0.01675652 & -0.01682385\\\\\n",
       "\t 1 & -1.81796641 &  6.88212076 &  6.58481401 &  6.59064139\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 5 of type dbl\n",
       "\n",
       "| 1 |  0.07949562 | -0.02019068 | -0.01675652 | -0.01682385 |\n",
       "| 1 | -1.81796641 |  6.88212076 |  6.58481401 |  6.59064139 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]        [,3]        [,4]        [,5]       \n",
       "[1,] 1     0.07949562 -0.02019068 -0.01675652 -0.01682385\n",
       "[2,] 1    -1.81796641  6.88212076  6.58481401  6.59064139"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC91BMVEUAAAABAQECAgIDAwME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\nrDmXFKuwzAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg +\n",
    "geom_point(aes(x=beta_plot[1,],y=beta_plot[2,]),size=2) +\n",
    "#annotate(geom='text', x=0.5, y=0.47, \n",
    "#         label=TeX(\"x^{(0)}\", output='character'), parse=TRUE) + \n",
    "xlab('x') + ylab('y') + \n",
    "ggtitle(TeX('Iter del método de descenso en gradiente para $f_o$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cambiando parámetro de regularización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg<-0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- glmnet(A,y,alpha=1,lambda=reg,standardize=F,nlambda=1,intercept=F,thresh=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ast <- as.matrix(fit$beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              s0\n",
      "disp -0.01766132\n",
      "drat  6.66307033\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0<-c(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol <- 1e-8\n",
    "tol_backtracking <- 1e-14\n",
    "maxiter <- 30\n",
    "p_ast <- fo(beta_ast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newtons method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search    condHf\n",
      "1    6.49e+04   8.64e-01      3.10e+04      ---\n",
      "2    9.82e+01   2.54e+00      6.05e+02      1.00e+00    1.60e+04\n",
      "3    2.51e+00   3.73e-02      1.30e-01      1.00e+00    1.60e+04\n",
      "4    1.66e-02   5.24e-04      2.77e-05      1.00e+00    1.66e+04\n",
      "5    5.20e-04   3.37e-05      6.50e-08      1.00e+00    1.59e+04\n",
      "Error of x with respect to x_ast: 3.37e-05\n",
      "Approximate solution:[1] -0.01766474  6.66329488\n"
     ]
    }
   ],
   "source": [
    "l<-Newtons_method(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -0.01766474  6.66329488\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              s0\n",
      "disp -0.01766132\n",
      "drat  6.66307033\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "7.78410717807856"
      ],
      "text/latex": [
       "7.78410717807856"
      ],
      "text/markdown": [
       "7.78410717807856"
      ],
      "text/plain": [
       "[1] 7.784107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 5 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>  0.1764839</td><td>-0.01483255</td><td>-0.01762187</td><td>-0.01766474</td></tr>\n",
       "\t<tr><td>1</td><td>-10.2852230</td><td> 6.41439908</td><td> 6.65957987</td><td> 6.66329488</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 5 of type dbl\n",
       "\\begin{tabular}{lllll}\n",
       "\t 1 &   0.1764839 & -0.01483255 & -0.01762187 & -0.01766474\\\\\n",
       "\t 1 & -10.2852230 &  6.41439908 &  6.65957987 &  6.66329488\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 5 of type dbl\n",
       "\n",
       "| 1 |   0.1764839 | -0.01483255 | -0.01762187 | -0.01766474 |\n",
       "| 1 | -10.2852230 |  6.41439908 |  6.65957987 |  6.66329488 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]        [,3]        [,4]        [,5]       \n",
       "[1,] 1      0.1764839 -0.01483255 -0.01762187 -0.01766474\n",
       "[2,] 1    -10.2852230  6.41439908  6.65957987  6.66329488"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC61BMVEUAAAABAQECAgIDAwME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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg +\n",
    "geom_point(aes(x=beta_plot[1,],y=beta_plot[2,]),size=2) +\n",
    "#annotate(geom='text', x=0.5, y=0.47, \n",
    "#         label=TeX(\"x^{(0)}\", output='character'), parse=TRUE) + \n",
    "xlab('x') + ylab('y') + \n",
    "ggtitle(TeX('Iter del método de descenso en gradiente para $f_o$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0<-c(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search\n",
      "1    4.02e+03   1.00e+00      2.12e+02      ---\n",
      "2    1.60e+02   1.00e+00      9.31e+01      1.52587890625e-05\n",
      "3    2.86e+01   1.00e+00      9.29e+01      1.52587890625e-05\n",
      "4    2.73e+03   4.76e-01      7.59e+01      0.125\n",
      "5    1.08e+02   4.76e-01      2.11e+01      1.52587890625e-05\n",
      "6    1.39e+01   4.76e-01      2.10e+01      1.52587890625e-05\n",
      "7    1.30e+03   2.28e-01      1.72e+01      0.125\n",
      "8    5.20e+01   2.28e-01      4.84e+00      1.52587890625e-05\n",
      "9    6.64e+00   2.28e-01      4.82e+00      1.52587890625e-05\n",
      "10    6.22e+02   1.09e-01      3.95e+00      0.125\n",
      "11    2.47e+01   1.09e-01      1.11e+00      1.52587890625e-05\n",
      "12    3.18e+00   1.09e-01      1.11e+00      1.52587890625e-05\n",
      "13    2.98e+02   5.22e-02      9.05e-01      0.125\n",
      "14    1.18e+01   5.22e-02      2.55e-01      1.52587890625e-05\n",
      "15    1.52e+00   5.22e-02      2.54e-01      1.52587890625e-05\n",
      "16    1.43e+02   2.50e-02      2.08e-01      0.125\n",
      "17    5.66e+00   2.50e-02      5.84e-02      1.52587890625e-05\n",
      "18    7.29e-01   2.50e-02      5.82e-02      1.52587890625e-05\n",
      "19    6.84e+01   1.20e-02      4.77e-02      0.125\n",
      "20    2.71e+00   1.20e-02      1.34e-02      1.52587890625e-05\n",
      "21    3.49e-01   1.20e-02      1.33e-02      1.52587890625e-05\n",
      "22    3.27e+01   5.72e-03      1.09e-02      0.125\n",
      "23    1.30e+00   5.72e-03      3.07e-03      1.52587890625e-05\n",
      "24    1.67e-01   5.72e-03      3.06e-03      1.52587890625e-05\n",
      "25    1.57e+01   2.73e-03      2.51e-03      0.125\n",
      "26    6.23e-01   2.73e-03      7.05e-04      1.52587890625e-05\n",
      "27    8.02e-02   2.73e-03      7.02e-04      1.52587890625e-05\n",
      "28    7.51e+00   1.29e-03      5.75e-04      0.125\n",
      "29    2.98e-01   1.29e-03      1.62e-04      1.52587890625e-05\n",
      "30    3.84e-02   1.29e-03      1.61e-04      1.52587890625e-05\n",
      "Error of x with respect to x_ast: 1.29e-03\n",
      "Approximate solution:[1] -0.01756272  6.65444873\n"
     ]
    }
   ],
   "source": [
    "l<-coordinate_descent(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -0.01756272  6.65444873\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              s0\n",
      "disp -0.01766132\n",
      "drat  6.66307033\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "7.78426833374324"
      ],
      "text/latex": [
       "7.78426833374324"
      ],
      "text/markdown": [
       "7.78426833374324"
      ],
      "text/plain": [
       "[1] 7.784268"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 29 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0.06136831</td><td>0.05895485</td><td>0.05895485</td><td>0.01724231</td><td>0.01888275</td><td>0.01888275</td><td>-0.0009476207</td><td>-0.0001616408</td><td>-0.0001616408</td><td>-0.00965363</td><td>⋯</td><td>-0.01674264</td><td>-0.01674264</td><td>-0.01724231</td><td>-0.01722266</td><td>-0.01722266</td><td>-0.01746201</td><td>-0.0174526</td><td>-0.0174526</td><td>-0.01756723</td><td>-0.01756272</td></tr>\n",
       "\t<tr><td>0.00000000</td><td>0.00000000</td><td>3.49381608</td><td>3.49381608</td><td>3.49381608</td><td>5.14563299</td><td> 5.1456329864</td><td> 5.1456329864</td><td> 5.9362877280</td><td> 5.93628773</td><td>⋯</td><td> 6.58333947</td><td> 6.62496245</td><td> 6.62496245</td><td> 6.62496245</td><td> 6.64489965</td><td> 6.64489965</td><td> 6.6448997</td><td> 6.6544487</td><td> 6.65444873</td><td> 6.65444873</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 29 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       "\t 0.06136831 & 0.05895485 & 0.05895485 & 0.01724231 & 0.01888275 & 0.01888275 & -0.0009476207 & -0.0001616408 & -0.0001616408 & -0.00965363 & ⋯ & -0.01674264 & -0.01674264 & -0.01724231 & -0.01722266 & -0.01722266 & -0.01746201 & -0.0174526 & -0.0174526 & -0.01756723 & -0.01756272\\\\\n",
       "\t 0.00000000 & 0.00000000 & 3.49381608 & 3.49381608 & 3.49381608 & 5.14563299 &  5.1456329864 &  5.1456329864 &  5.9362877280 &  5.93628773 & ⋯ &  6.58333947 &  6.62496245 &  6.62496245 &  6.62496245 &  6.64489965 &  6.64489965 &  6.6448997 &  6.6544487 &  6.65444873 &  6.65444873\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 29 of type dbl\n",
       "\n",
       "| 0.06136831 | 0.05895485 | 0.05895485 | 0.01724231 | 0.01888275 | 0.01888275 | -0.0009476207 | -0.0001616408 | -0.0001616408 | -0.00965363 | ⋯ | -0.01674264 | -0.01674264 | -0.01724231 | -0.01722266 | -0.01722266 | -0.01746201 | -0.0174526 | -0.0174526 | -0.01756723 | -0.01756272 |\n",
       "| 0.00000000 | 0.00000000 | 3.49381608 | 3.49381608 | 3.49381608 | 5.14563299 |  5.1456329864 |  5.1456329864 |  5.9362877280 |  5.93628773 | ⋯ |  6.58333947 |  6.62496245 |  6.62496245 |  6.62496245 |  6.64489965 |  6.64489965 |  6.6448997 |  6.6544487 |  6.65444873 |  6.65444873 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]       [,3]       [,4]       [,5]       [,6]      \n",
       "[1,] 0.06136831 0.05895485 0.05895485 0.01724231 0.01888275 0.01888275\n",
       "[2,] 0.00000000 0.00000000 3.49381608 3.49381608 3.49381608 5.14563299\n",
       "     [,7]          [,8]          [,9]          [,10]       [,11] [,12]      \n",
       "[1,] -0.0009476207 -0.0001616408 -0.0001616408 -0.00965363 ⋯     -0.01674264\n",
       "[2,]  5.1456329864  5.1456329864  5.9362877280  5.93628773 ⋯      6.58333947\n",
       "     [,13]       [,14]       [,15]       [,16]       [,17]       [,18]     \n",
       "[1,] -0.01674264 -0.01724231 -0.01722266 -0.01722266 -0.01746201 -0.0174526\n",
       "[2,]  6.62496245  6.62496245  6.62496245  6.64489965  6.64489965  6.6448997\n",
       "     [,19]      [,20]       [,21]      \n",
       "[1,] -0.0174526 -0.01756723 -0.01756272\n",
       "[2,]  6.6544487  6.65444873  6.65444873"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC/VBMVEUAAAABAQECAgIDAwME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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg +\n",
    "geom_point(aes(x=beta_plot[1,],y=beta_plot[2,]),size=2) +\n",
    "#annotate(geom='text', x=0.5, y=0.47, \n",
    "#         label=TeX(\"x^{(0)}\", output='character'), parse=TRUE) + \n",
    "xlab('x') + ylab('y') + \n",
    "ggtitle(TeX('Iter del método de descenso en gradiente para $f_o$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search\n",
      "1    4.02e+03   1.00e+00      2.12e+02      ---\n",
      "2    1.61e+02   1.00e+00      9.30e+01      1.52587890625e-05\n",
      "3    2.86e+01   1.00e+00      9.28e+01      1.52587890625e-05\n",
      "4    2.04e+02   9.98e-01      9.28e+01      0.00048828125\n",
      "5    2.89e+01   9.98e-01      9.25e+01      1.52587890625e-05\n",
      "6    1.28e+02   9.97e-01      9.24e+01      0.000244140625\n",
      "7    2.82e+01   9.97e-01      9.23e+01      1.52587890625e-05\n",
      "8    1.61e+02   9.95e-01      9.21e+01      0.00048828125\n",
      "9    2.84e+01   9.95e-01      9.19e+01      1.52587890625e-05\n",
      "10    2.04e+02   9.93e-01      9.18e+01      0.00048828125\n",
      "11    2.88e+01   9.92e-01      9.15e+01      1.52587890625e-05\n",
      "12    1.28e+02   9.91e-01      9.14e+01      0.000244140625\n",
      "13    2.81e+01   9.91e-01      9.13e+01      1.52587890625e-05\n",
      "14    1.61e+02   9.89e-01      9.11e+01      0.00048828125\n",
      "15    2.83e+01   9.89e-01      9.09e+01      1.52587890625e-05\n",
      "16    2.04e+02   9.87e-01      9.08e+01      0.00048828125\n",
      "17    2.87e+01   9.87e-01      9.05e+01      1.52587890625e-05\n",
      "18    1.28e+02   9.86e-01      9.04e+01      0.000244140625\n",
      "19    2.79e+01   9.86e-01      9.03e+01      1.52587890625e-05\n",
      "20    1.61e+02   9.84e-01      9.01e+01      0.00048828125\n",
      "21    2.81e+01   9.84e-01      8.99e+01      1.52587890625e-05\n",
      "22    2.04e+02   9.82e-01      8.99e+01      0.00048828125\n",
      "23    2.85e+01   9.82e-01      8.96e+01      1.52587890625e-05\n",
      "24    1.28e+02   9.81e-01      8.95e+01      0.000244140625\n",
      "25    2.78e+01   9.81e-01      8.94e+01      1.52587890625e-05\n",
      "26    1.61e+02   9.79e-01      8.92e+01      0.00048828125\n",
      "27    2.80e+01   9.79e-01      8.90e+01      1.52587890625e-05\n",
      "28    2.04e+02   9.77e-01      8.89e+01      0.00048828125\n",
      "29    2.84e+01   9.77e-01      8.86e+01      1.52587890625e-05\n",
      "30    1.28e+02   9.76e-01      8.85e+01      0.000244140625\n",
      "Error of x with respect to x_ast: 9.76e-01\n",
      "Approximate solution:[1] 0.05901972 0.16175495\n"
     ]
    }
   ],
   "source": [
    "l<-gradient_descent(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.05901972 0.16175495\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              s0\n",
      "disp -0.01766132\n",
      "drat  6.66307033\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "96.3340924948692"
      ],
      "text/latex": [
       "96.3340924948692"
      ],
      "text/markdown": [
       "96.3340924948692"
      ],
      "text/plain": [
       "[1] 96.33409"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 2 × 29 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0.061368308</td><td>0.058941308</td><td>0.06184346</td><td>0.05875461</td><td>0.06062378</td><td>0.05871641</td><td>0.06096286</td><td>0.05853562</td><td>0.06143894</td><td>0.05834978</td><td>⋯</td><td>0.05773067</td><td>0.06063629</td><td>0.05754652</td><td>0.05941755</td><td>0.05750965</td><td>0.05975933</td><td>0.05733139</td><td>0.06023815</td><td>0.05714807</td><td>0.05901972</td></tr>\n",
       "\t<tr><td>0.001131953</td><td>0.001529336</td><td>0.01517238</td><td>0.01556124</td><td>0.02237325</td><td>0.02277526</td><td>0.03636735</td><td>0.03676248</td><td>0.05033357</td><td>0.05072019</td><td>⋯</td><td>0.10667081</td><td>0.12009913</td><td>0.12048129</td><td>0.12718616</td><td>0.12758147</td><td>0.14095952</td><td>0.14134797</td><td>0.15470547</td><td>0.15508541</td><td>0.16175495</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 29 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       "\t 0.061368308 & 0.058941308 & 0.06184346 & 0.05875461 & 0.06062378 & 0.05871641 & 0.06096286 & 0.05853562 & 0.06143894 & 0.05834978 & ⋯ & 0.05773067 & 0.06063629 & 0.05754652 & 0.05941755 & 0.05750965 & 0.05975933 & 0.05733139 & 0.06023815 & 0.05714807 & 0.05901972\\\\\n",
       "\t 0.001131953 & 0.001529336 & 0.01517238 & 0.01556124 & 0.02237325 & 0.02277526 & 0.03636735 & 0.03676248 & 0.05033357 & 0.05072019 & ⋯ & 0.10667081 & 0.12009913 & 0.12048129 & 0.12718616 & 0.12758147 & 0.14095952 & 0.14134797 & 0.15470547 & 0.15508541 & 0.16175495\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 29 of type dbl\n",
       "\n",
       "| 0.061368308 | 0.058941308 | 0.06184346 | 0.05875461 | 0.06062378 | 0.05871641 | 0.06096286 | 0.05853562 | 0.06143894 | 0.05834978 | ⋯ | 0.05773067 | 0.06063629 | 0.05754652 | 0.05941755 | 0.05750965 | 0.05975933 | 0.05733139 | 0.06023815 | 0.05714807 | 0.05901972 |\n",
       "| 0.001131953 | 0.001529336 | 0.01517238 | 0.01556124 | 0.02237325 | 0.02277526 | 0.03636735 | 0.03676248 | 0.05033357 | 0.05072019 | ⋯ | 0.10667081 | 0.12009913 | 0.12048129 | 0.12718616 | 0.12758147 | 0.14095952 | 0.14134797 | 0.15470547 | 0.15508541 | 0.16175495 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]        [,2]        [,3]       [,4]       [,5]       [,6]      \n",
       "[1,] 0.061368308 0.058941308 0.06184346 0.05875461 0.06062378 0.05871641\n",
       "[2,] 0.001131953 0.001529336 0.01517238 0.01556124 0.02237325 0.02277526\n",
       "     [,7]       [,8]       [,9]       [,10]      [,11] [,12]      [,13]     \n",
       "[1,] 0.06096286 0.05853562 0.06143894 0.05834978 ⋯     0.05773067 0.06063629\n",
       "[2,] 0.03636735 0.03676248 0.05033357 0.05072019 ⋯     0.10667081 0.12009913\n",
       "     [,14]      [,15]      [,16]      [,17]      [,18]      [,19]     \n",
       "[1,] 0.05754652 0.05941755 0.05750965 0.05975933 0.05733139 0.06023815\n",
       "[2,] 0.12048129 0.12718616 0.12758147 0.14095952 0.14134797 0.15470547\n",
       "     [,20]      [,21]     \n",
       "[1,] 0.05714807 0.05901972\n",
       "[2,] 0.15508541 0.16175495"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME\nBAQFBQUGBgYHBwcICAgJCQkKCgoLCwsMDAwNDQ0ODg4PDw8QEBARERESEhITExMUFBQVFRUW\nFhYXFxcYGBgZGRkaGhobGxscHBwdHR0eHh4fHx8gICAhISEiIiIjIyMkJCQlJSUmJiYnJyco\nKCgpKSkqKiorKyssLCwtLS0uLi4vLy8wMDAxMTEyMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk6\nOjo7Ozs8PDw9PT0+Pj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tM\nTExNTU1OTk5PT09QUFBRUVFSUlJTU1NUVFRVVVVWVlZXV1dYWFhZWVlaWlpbW1tcXFxdXV1e\nXl5fX19gYGBhYWFiYmJjY2NkZGRlZWVmZmZnZ2doaGhpaWlqampra2tsbGxtbW1ubm5vb29w\ncHBxcXFycnJzc3N0dHR1dXV2dnZ3d3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGC\ngoKDg4OEhISFhYWGhoaHh4eIiIiJiYmKioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OU\nlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJydnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWm\npqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+wsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4\nuLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLDw8PExMTFxcXGxsbHx8fIyMjJycnK\nysrLy8vMzMzNzc3Ozs7Pz8/Q0NDR0dHS0tLT09PU1NTV1dXW1tbX19fY2NjZ2dna2trb29vc\n3Nzd3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp6enq6urr6+vs7Ozt7e3u\n7u7v7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8/Pz9/f3+/v7////i\nsF19AAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO3deYBVdf3/8Y8gm+K+5pJZlpXm\nhkv606+pWVleURHFBYQ0XMNdU0tyI+pb+lWoDC1K0dzLRL8uX9AQNRUNMBHUwRUQrijLALPe\n87vbmZl75877vu7cz8zc5fn8Y+Yu577Px3vOA+7cGQcXEFHRuZ5eAFElBCQiDwGJyENAIvIQ\nkIg8BCQiDwGJyENAIvJQ+UK6e+ysnl4CUVjZQnqy15ENPb0GojBvkHZ1DxT8mEbXr/2NW7jV\nwkMXbbXHys7uocAtlE1Kr/SitWezC/rHQRs593rP7Lsn8gxpQ7eugMd0HlLToTt8lL5o7hJI\neZ/Nwg6Z2pw+fY4566xFXTC5RCtTSG+M/U94EUg5Sy/6tpvzvQDuGkjXuau6YGoJV6aQ2gSk\nnMmL7hpIP3K3d8HUEs4rpN+7VEvi11fduM9G/b8+dlVqL72Du765UZsj9toxm22w9+3hwc7Y\nNgNS/IF/2meDrUcuDepv2LX/dpfWZW/fdpcLR3+h76bfujvXHjLuyr8GYZP3zv/qhgN3Ojo5\nctX4/Tfpv/OJT7TbKL78+7654UZHvtjuIbkWZDw0bNbRm7YuqOVZnXHB3lv22e7EV3IsOv1s\ndji6w0PWcgBit+01YPPj5iavZeyog90nGpsaempQPXmF9MrYPu7qsWPHxo/du192Wxzx/a3d\n7suTe+l9hdv1sB3WhBs/1c/tOfywXmNSBztz2yxIV/Ta48jN3W6rv9X/gEP7u2HZ27fZ5YyN\n3RdO+Nb6bnis3R4y7hLWkH+T+Zu4rw4ddvDAQ+OX39nFDTxyyH79j2g3x/W+Zr2vfW9H1+/V\nrIfkWpDx0LD/7ev2Gn5474tCSOlndVDv3Y865iuuz9/bLzr1bHY8usND1nIAzut9xGm7uwHP\nJq5l7Cj37pM9M3ZvFxk79iHjfKm0uuilXfM+7pzaIKg9yZ2W3Isb+GQQtJw0q7ZxN8U/Te+f\nPNhZ22ZCcls+FwTRr7rdv1ET/wp2QOJ9oKztw13WbusuaQqCV7dwt2XvIeMuZQ35NznHXZnY\nZG38T/XG3dzxn8Yvf/pkjv/uzZ4OgoYT3TGZD8m1IOuh6VZu5W6Jf3pugzSk8Fm9f3Hi6j29\ntl6XvejUs2mO7uCQtRyAgS/EP13vtl8bZO4o9+7DzuClXSfLhPSw27858Xn1Vr0Tf745N7bt\ntpPcvsnPP04e7KxtsyD9PvFponPJFw4jEidS1vbhLie5XZoSn29xu2TvIeMuZQ35NznePRNu\n9le3S114ud1/94TEtRq3cSzjIbkWZD003R/c/snP4d9Imc9qMMQ9mb3o1LNpju7gkKVz7ieJ\nT7GvuT9n7Sj37sOA1NkyIZ3pxqduPto9ldiLW9B221PdzcnPLycPdta2WZA+THx6ym2TvHqj\nu6Ld9uEuT3XXJj+vdu6jrD1k3KWsIf8m490ej65NXT/dXd/ykHb/3R8krw1wqzIekmtB1kPT\nneL+J/n5lRBS+KzWT5tw/dixh7hbsxedejbN0R0csnTh94KudyOzdpR792FA6myZkA53Lf01\nsRdX13bbQ13q5XQ0ebCzts2E1Cv55/GLbr/k1Qnugnbbh7v8lrsr9Zht3EtZe8i4S1lD/k3q\nvutcn70v/ndyeuu3orP/u1PLj+83mvWQ9guyHppzQa3P6v1bpx94Q7ttks+mObqDQxYeAFeb\n/HyX+3bWjnLvPgxInS0T0qHuhLHp5gTJN3jadqh7JPk5dbCzts1+1y7Ri+6A5OckpKztW3c5\nJfWYrZOQMvfQ5i5lDcom/7rmiA2d+1kmpA7+u9MaWh6Se0HWQzMW9EnLu3bJZvUaMPGtNbHg\nysRfjZmLTj2b5ugODll4AFogHZm1o9y7DwNSZ8uEdFrm6+csSJkvUbK2zQspa/vsl3a1iZdL\nmXvIuEtZg7hJ/d391vtP/KVd65/EHfx3t2pIPSTXgvI+NAhOTr7XEASvZkK6wN2Y/HxC4kzO\nevmXfDbN0R0csnBbl/rO9w3u9Kwd5d59WAjpwT37bXNuD/2UUrfmGdJmaQV3u6+sbbuXTEjh\nF80XJA921rZ5IWVtH+5ykvty8gv4iYkv4DP3kHGXsgZ5k6PdPcE97istPz3QwX93Ww2Jh+Ra\nkPDQ37sDk58vyYR0curvt2WbJs7kzEWnnk1zdAeHLNw29RMKsd3c5Kwd5d59WBrSg+ud/PiE\njY5oP7fi8gzpG+5fyWuN33DHJb7HF7x9U3IvmZDSb+P+c0DyYGdtmxdS1vbhLmu3dVc0B8Hc\nrRJvKWfuIeMuZQ35N/ndW4mLS7ZzLwSNX3fDEl+1r5zW4X938pRt85BcC7Iemm7FFm5i/NML\nG2ZCusYdHv9qZfUPXOJMzlx06tk0R3dwyMID4DZK3D3OfW5N1o5y7z4sDenrBwcJos8EFZ9n\nSNe4zYaeccbKIHj3a26DA0868iupt9uyIKW/sdgr/RZt5rZ5IWVt37LLGRu5XYYd2Sf1Tc7M\nPWTcJawh/yZ7ui8ff/pRGyS/Q7zgC26THww7aMAR7eZknLJtH5JrQcZDw6b2cXuPOKL3hW6j\ntpss3sptf+KQLbYdlTyTMxed/oasMbqDQ9ZyAM7r/e3h33D9p7XbUe7dp0tBWp5E3dDruqDi\n8wyp/sov9039vMnaWw7ZrM/n9r30+eResiAlftRlwJ6/D3/2JmPb/JAyt2/dZc2PduqzyaFT\nYjn2kHFX/jXk3+TRs/faqu/nv/NA8lsvK67ba8MBOw97qt2cjFM24yG5FtTxQ1t6+fubDNj7\n9nfdzhnP6oen79Tv86MXj02dyRmLTj+bxugODlnLAYhN3GPAZoNnt99RB7tPlYL0trs3cWXL\nC4OKr2z/x75q7k43tLt21e6PwIJannzno56/kai0WrIs8XHWNu7x7tpjcZCCrx8U/zCFr5Go\ntHqg9wEnnXLAeu7sbttjkZAecic+estA3rWj0uqdH311k/W3PPK+7ttjkZCCB/bsuzXfRyIi\nLSAReQhIRB4CEpGHgETkISAReQhIRB4CEpGHgETkISAReQhIRB4CEpGHgETkISARecgTpHW1\nrdXX13qqfo2nQXUNviatW+tp0NqGdfk30ibVeRpU2+Btkr9ToMHXpDpvp0Cbk6n19y55grQi\n2lpTc9RTjcs9DVoXfOZp0tpVngatCmo9TVpR52nQJ0G9p0lRf6dAzNekhk89DVrb5mz/FEid\nDEhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7IAkBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkAC\nkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSA\nBCQ7IEkBCUh2QJICEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJ\nAQlIdh4hzb997OQ3PUwCkhSQPFSCkFZetb5zrt8NxU8CkhSQPFSCkH7uUk0sehKQpIDkodKD\n9NFGaUg7Lit2FJCkgOSh0oP0pAubXewoIEkByUOlB+nvLZCeL3YUkKSA5KHSgzQ7dNT3/WJH\nAUkKSB4qPUjR/0pDOqHoSUCSApKHShDSnO2SjnYp/jtJQJICkodKENKqpefvsfneFy8sfhKQ\npIDkoVKExI8IKQHJR0BSApIUkDwEJCUgSQHJR0CSAhKQ7IAkBSQg2QFJCkhAsgOSFJCAZAck\nKSAByQ5IUkACkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkgAckO\nSFJAApIdkKSA1EWQlkz9ze0vFbxkICkBSaoiID2xU+IXfRzzboFLBpISkKQqAdKrG6d+9dSR\nBS4ZSErdCOnvw/Y6aLTyygJIXQJpZPjbEB8rbMlAUuo+SJclD+KAu/OPAlKXQNo1hHRVYUsG\nklK3QXoofRQ3np93FJC6BNL2IaQxhS0ZSErdBum48DCOzzsKSF0C6aDwCNxU2JKBpNRtkHYL\nD+MP844CUpdAuil9AAYW+Pt5gaTUbZD2DiGdlXcUkLoE0sffTR2A3xe4ZCApdRukM0JIk/KO\nAlKXQIp+/ItBG277vccLXTKQlLoN0ssDUo6+vCjvKCB1DaROBiSl7nv7+77NEo52fTn/KCAB\nya6qIUXfmXDepXcuFkYBCUh21Q1JDkhAsgOSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJ\nSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQ2vXKmONH3R1LX1kw7ozIrYkLUyOJZgOp0wFJqmIg\nzR9823vThtyVvjZn8rOjU5BOqYm3DkidDkhSFQNp3LnxD1OG1rXcMCYFaXjmZkAqNCBJVQyk\n4XfEP8yLzMuGdOzwky+bmbxh1bx4Sz9rrTn2maeaVnoaVB+s8jSpbo2nQbXBWk+TVtd7GrQi\naPA06bNmX4OaAl+TGn2dTHXB6pbLK1VIschD8Y9LIjOzIM15cv7cCZFHEhenD4r3Uh6PRJVY\nc8ulTkJKNn5E4mPNrfHeWdtaLLbWU83rPA1qDOp8Tar3NKg+aPA0qa7J06B1ga9Ja/2dAoG3\nSV1yMqmQOnppl+yRSGN4ka+RCo2vkaQq5mukDt5sSP2N1PqOA5AKDUhSFQMp8fb39MTb3zMv\nXxME9TU1Z4+rWRgEE6fNm31r5GEgdTogSVUMpODlMceNnBJLvI5bGf96KPl92MFBMGn0kJMv\nndG6FZAKDUhSlQNJC0iFBiQpIPkISEpAkgKSh4CkBCQpIPkISFJAApIdkKSABCQ7IEkBCUh2\nQJICEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ\n7IAkBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUk\nINkBSQpIQLIDkhSQuh/Syz876cwJH+S8C0hKQJKqdEi/6evi7fyvXPcBSUmEtDjvFkCSKk1I\nj7pUX8l1nIGkpECa8YMte+105tv2RkCSKk1IR6chubty3AkkJQHSPwYkn+Mvzje3ApJUaULa\nKYR0WY47gaSUH9LHX0g/yaeZmwFJqjQh7RhCujjHnUBSyg/pifBJ3miptRmQpEoT0nfDY/yn\nHHcCSSk/pDvCJ9mZr+2AJFWakO5PH+EdP8xxJ5CU8kMKn2TXa5G1GZCkShNS9OrkEd56eq77\ngKSUH9LC/mlIB5qbAUmqRCFFnz7nsME/fyvnXUBSEt61uyrlqN9UcysgSZUqJCMgKQmQlv0k\n8XfStvfYWwFJCkg+Kk9I0eg7D018wvwCKQokMSD5qFwhKQFJCkg+ApIUkIBkByQpIAHJDkhS\nQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7IAkBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2Q\npIAEJDsgSQEJSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7\nIEkBCUh2QJICEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlI\ndkCSAhKQ7IAkBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJSHZAkgIS\nkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBqZQgvfqTIw89Z4aP\nSUBSApJU2UG6ZwMXr+9vPIyqOEgL3269DCSpqoX0xkCXrO8zxc+qLEhLr/+8c9tftSR9FUhS\nVQvp5y7dqOJnVRakU1LPyw+Wpa4CSapqIQ0LIR1Q/KyKgvRI+MT8OXUdSFJVC+nU8Hw5qPhZ\nFQVpdPjEnJC6DiSpqoX0q/B8Oa/4WRUFKZL1JwyQpKoW0sJtUqfLgFeLn1VRkEaEkI5OXQeS\nVNVCiv7fdomzZZN7PYyqKEiTQ0g3p64DSap6IUXfu2P06b9a4GNSRUFaenDK0Z6LUteBJFXF\nkPgRodwtHNbbuV6Dwz9igCQFJA9VFqRo9J1H/9b6NzWQpIDkoUqDlBGQpIDkISApAUkKSD4C\nkhSQOlldm2KxOk/F6j0Nagq8TWr0NKgh8DapydOg+qDZ06Q6f6dAkH8brWZ/J1ND6xXfkFav\naK05tsJTTSs9DarPWGAx1a3xNGhNsM7TpNp6T4NWBo2eJq1o9jWoKfA1qXGVp0F1QW3L5VW+\nIfHSrtB4aSdVbS/tgFRoQJICko+ApAQkKSB5CEhKQJICko+AJAUkINkBSQpIQLIDkhSQgGQH\nJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJICEpDsgCQFpJKD9M6Fg7be96J3ihsEJCUgSZUn\npLk7JX9jzhdeL2oQkJS6FNKSGVNmLC58EJB8FId0VPp3uP2gqEFAUupKSJO3jR/Ebe4oeBCQ\nfNS4fEHvNKTebxUzCEhKXQhpSvowTi50EJB81Lj86fC3irqnixkEJKUuhPSl9FHccVmBg4Dk\no8blM1sgzSxmEJCUug7Say2H8YUCBwHJR43LP94ifQC2/LiYQUBS6jpI01sgPV7gICD5qHF5\ndFz6APyiqEFAUuo6SPNaIM0ucBCQfJT4PtLlfeJPf58rihsEJKUu/BrpwLSjQYUOApKPkj/Z\nMGfSlZPmFjkISEpdCGnGxklHA6cXOghIPuJHhJTKAVL0xe8NdBt+p/B3jIDkIyAplQWkaHTZ\nvELf+k4EJB8BSalMIHUuIPkISEpAkgKSh4CkBCQpIPkISFJAApIdkKSABCQ7IEkBCUh2QJIC\nEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7IAk\nBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUkINkB\nSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJICEpDsgCQFJCDZAUkKSECy\nA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7IAkBSQg2QFJCkhAsgOSFJCA\nZAckKSAByQ5IUkACkh2QpIAEJDsgSQGpnCAt+fVRu37rireFQUBSApJUxUH64GCXaIdZ+QcB\nSakDSMtenbm40FFAKiNIP3ap9s8/CEhKOSF9fPVmzvUd9lZho4BUPpCWbp6G5J7POwhISjkh\njUo9x7t9WNAoIJUPpPmhIzc57yAgKeWC9Ez4JP+8oFFAKh9IC1sg3ZN3EJCUckG6MnySDyxo\nFJDKB1L0K+lD3PvNvIOApJQL0pkhpC8VNApIZQTpt+lDPDL/ICAp8TeSVMVBil7dJ3GEBy/K\nPwhISubXSNcWNApI5QQp+uqvz7nuKWUQkJRyvmv3w5Sj3XnXLqwCIckBSSn395F+ujnfR8oI\nSD6qOkiJn2x4jp9saBOQfFSFkDoTkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ\n7IAkBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUk\nINkBSQpI7XplzPGj7o6lrywYd0bk1vY3A6nwgCRVMZDmD77tvWlD7kpfmzP52dG3tr8ZSIUH\nJKmKgTTu3PiHKUPrWm4Yc2uum4FUaECSqhhIw++If5gXmZcFKftmIBUakKQqBVIs8lD845LI\nzExIbW+ePijeS3k8ElVizS2Xiof0ymnx5jS2FgsaPRXzNag5aPI1ydegpqDZ1yRvT1Pgb5Kv\nQR5PJm+nQJuTqUGFxEu7rHhpJ8VLu+x4syEzIEkBKbvE+9zTE+9zz7x8TRDU19ScPa5mYZub\ngdTJgCRVMZCCl8ccN3JKLAgeiawMgppIosFtbgZSJwOSVOVA0gJSoQFJCkg+ApISkKSA5CEg\nKQFJCkg+ApIUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7IAkBSQg2QFJCkhA\nsgOSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQ\nKgTSgvEjTv/VgparQFICklQ1QXpoUxdv87+H14GkBCSpKoL0+kCXbON56RuAFDbhgE22OOyv\nue8DklQVQbrcpbsqfQOQ0p2eel5+lvNOIElVEaSjQkhHp28AUqp7089Ln5m57gWSVBVB+k4I\n6aj0DUBKNTR8Yi7JdS+QpKoI0oXZ5wuQUu0fPjFDct0LJKkqgvRK39Tp0v+19A1ASnVYCGlk\nrnuBJFVFkKK39086mhxeB1Kqq0NIk3LdCySpaoIUffnCbx950ayWq0BK9c52KUd7LMl1L5Ck\nqgpSVkBK9+LuCUeHvpHzTiBJAclHZQ4puuypm387o4P7gCQFJB+VOyQrIEkByUdAkgISkOyA\nJAUkINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJICEpDsgCQFJCDZ\nAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAlJFQfr7ZcOumJq4ACQl\nIElVHaRFxyZ/Y86JS4CkVbqQcv7SowIDUmc7L/073C4GklaJQnr1hO3X+/xpuX/xUQEBqZN9\nOCANaeNFQJIqTUgzkv/Wldv2tfwbmwGpk00Pf6uoew5IUqUJad/0UfxekZOA1MmeboH0LJCk\nShLSwvAorl9T3CQgdbKF6d+k7/p/ACSpkoT0TJsXFkUFpM42rPVfXgCSUklCerUF0pziJgGp\nsy3cL/n8H/Q+kLRKElLDFmlHXypyEpA63eJbTzzgpImJ70EASakkIcVuSkP6S5GTgOQhICmV\nJqToLxL/Rv1mvy12EpA8BCSlEoUUfffhCY9+UPQkIHkISEqlCslPQPIQkJSAJAUkHwFJCkhA\nsgOSFJCAZAckqSqH9CGQ8gUkqSqH1PvofzQByQxIUlUOafgAt8M17wPJCEhSVQ4p+GzCHq7X\nUX9rBFJHAUmq2iHFe+nMgW67q98FUu6AJAWkeKtGuPhfSzOBlCsgSQEpWPbrr7oNRp214Xp/\nAFKOgCRV7ZCanzyhj9t9woog+PRbOwIpR0CSqnJI1+7k+p+Wfk33l/WAlCMgSVU5JLfrb5aH\nl/99CZByBCSpKof0TCF2gFRUQJIqT0idD0iFBiQpIPkISEpAkgKSh4CkBCQpIPkISFJAApId\nkKSABCQ7IEkBCUh2QJICEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQk\nOyBJAQlIdkCSAhKQ7IAkBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2QpIDUydasbq05\nttpTzbWeBjVkLLCY6td5GrQuqPM0aW2jp0G1ga9Jq/2dAoGvSU3eToFgbcvlWu+QaluLxWo9\n1bwm/zZSjcFaT5Ma6jwNqgvqPU1a1+hp0JqgydOkWn+nQOBrUpO3UyBY13J5jW9IvLQrNF7a\nSVXbSzsgFRqQpIDkIyApAUkKSB4CkhKQpIDkIyBJAQlIdkCSAhKQ7IAkBaSqgbTg0ReWdGIS\nkKSAVCWQXvymc26zG5YVPAlIUkCqDkj/3sIlu6LgSUCSSp0CS+688Mxfzi1qEJB81GWQTk05\ncn3/U+gkIEklT4G5uyee434TihkEJB91GaRt05DcbwudBCSpxCmwdO/0k/xYEYOA5KMug9Q3\nhHRdoZOAJJU4BR4On+TvFzEISD7qMkg7hsd4UqGTgCSVOAWuCZ/kzxUxCEg+6jJIo9OHeMMF\nhU4CklTiFLgqhLRlEYOA5KMug7Rgp9Qh/u+CJwFJKnEK/CWEdEgRg4Dko677PtIbQ/o7t+uf\nCp8EJKnEKfDRDmlIdxQxCEg+6sqfbPh41sLOTAKSVPIUeHLzpKOzihkEJB/xs3ZKJQsp+sal\nh+976oNFDQKSj4CkVLqQPAQkHwFJCUhSQPIQkJSAJAUkHwFJCkhAsgOSFJCAZAckKSAByQ5I\nUkACkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApId\nkKSABCQ7IEkBCUh2QJICEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQk\nOyBJAQlIdkCSAhKQ7IAkBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJ\nSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJIC\nEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQALS29cee9joxzq6F0hSQKp6SDM+5xJd\n2MHdVQ1pyQfqKCBVO6TFX3Kp/pT7/iqG9Me9+q6302WLpFFAqnZI96Yduf+X+/7qhfSz1PNy\nyBJlFJCqHdI1IaTNc99ftZBm9U0/Mf+tjAJStUO6NoS0Re77qxbSdeETc4gyCkjVDunh8Hw5\nPPf9VQvprPCJ2VkZBaRqh7R0z/T58kDu+6sW0uUhpL2VUUCqdkjR13ZNnC19x3Vwd9VCejyE\n1NE3BjICUtVDii66bfSJP32po3urFlL06JSj7RYoo4AEJLvqhfThiPXjjg54WRoFJCDZVS+k\naHTBQ3fOEkcBCUh21QypgIAEJDsgSQEJSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkg\nAckOSFJAApIdkKSABCQ7IEkBCUh2QJICEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhS\nQAKSHZCkgAQkOyBJAQlIqebdfM6V9y1tfzuQpIAEpGR/2CDxG3P2+U+7O4AkBSQgJXoi/Tvc\n9luWfQ+QpEoE0qJr9t30izssdnMAABBXSURBVCc9n7zc05BeGXP8qLtj2demRhLNrlRIkfC3\nIf4t+x4gSZUGpA8PTB7EAcmj2MOQ5g++7b1pQ+7Kvjb1lJp46yoV0g4hpJ9l3wMkqdKA9JP0\nUdzuo2iPQxp3bvzDlKF1WdemDs/crMIgbR1C+kn2PUCSKg1I4T8a5+6N9jik4XfEP8yLzMu6\nNvXY4SdfNrNiIR0cHoHJ2fcASaokIC1bPzyMv4j2NKRY5KH4xyWRmVnX5jw5f+6EyCOJG2ef\nE+/1htZiQYOnYr4GNQeNBW1/V/oAbL+i3aQmT0tqCnxNamz2NKgh8PaE+xtUzMm0SQjpdp9L\nansy1RcLKdn4EYmP0wfFe8keU27Fzk0+/5s+39MLoWI6OoT0dlftobnlUidf2iV7JNIY/9i4\nMt6nn7TW3PyJpxo/zb+NVPylXYGPuOeE3Q/58dwck1Z7WdAnn8Rf2nmatLLO06DlQb2nSZ/4\nOwViRTz4qX4pR6ckrjQUegp01NpgZcvlz2RIHbzZkGx86zsOFfY1UsfxNZJUSXyNFI1O2SLh\naFjiTbuefrMh8Yb39MQb3jMvX9Pm2sRp82bfGnkYSJ0OSFJF/mTD+/ffcFv6H6Lp6W/Ivjzm\nuJFTYonXcSvbXJs0esjJl85o3QpIhQYkKX5EyEdAUgKSFJA8BCQlIEkByUdAkgISkOyAJAUk\nINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJICEpDsgCQFJCDZAUkK\nSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7IAkBSQg2QFJCkhAsgOS\nFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQH\nJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJICEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJ\nDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7IAkBSQg2QFJCkhAsgOSFJCAZBeHNOOUPXb+/uRi\nBwFJCkg+KklId/ZziUYWOQhIeXrriblRIPmpFCG9t7FL9afiBgHJbNo+8af485OB5KVShDQh\n7ch9u7hBQLJ6dsPUk/wHIPmoFCFdEEL6QnGDgGR1WPpJ3nINkDxUipCuCCF9rbhBQDL6aP3w\nWX4WSB4qRUgPh4d4RHGDgGT0evgku/uB5KFShLRiUOoID3ipuEFAMlrUJ4T0HJA8VIqQVr2x\nX/LF+4NFDgKS1XfSjrZdByQPlSSk6LJ/XP+Tye8XOwhIVi9skoL0F96181FpQvITkMxmHtLb\nua/dx/eRvAQkpYqEFI1+OOOdKD/Z4CcgKVUopFRA8hGQlIAkBSQPAUkJSFJA8hGQpIAEJDsg\nSQEJSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2\nQJICEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ\n7IAkBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUk\nINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJICEpDsgCQFJCDZAUkK\nSECyA5IUkDrZqk9ba27+1FONKzwNqgtWepq0rtbToNpgradJq+o9DfosaPA06VNvp0BT4GtS\ng7dToM3ZvsI3pLqG1mJBg6divgY1B42+JjV5GtQU+JrU2OxpUEPg7Qn3N8jfyeTtFGhzMtX7\nhsRLu0LjpZ1Utb20A1KhAUkKSD4CkhKQpIDkoe6D9P7H4iAgSQHJR+UG6f3zdnD99rtXGgQk\nKSD5qMwgfbC3S3aTMqi6IC168rcPLOjMICD5qMwgXZ1y5DZ4UxhUVZAe2C7+tPS9aGnhg4Dk\nozKDtHsakrtVGFRNkJ7ql3peLix8EJB8VGaQNg8hXS4MqiZIh6eflz7KX9WZAclHZQZp5xDS\nL4RBVQRpWd/wiZlc8CAg+ajMII0Kz5fnhUFVBOmj8HlxtxQ8CEg+KjNIs9Ov7U5XBlURpOhW\nIaSHCx4EJB+VGaTojD0Sb06dt1gZVE2QRqcdbb+o4EFA8lG5QYpGX7rzkXe0QdUE6e2vJh31\ne7DwQUDyUflB0qsmSNGF5+7ca/OjpndiEJB8BCSlMoAUr/BXdcmA5CMgKZUHpE4GJB8BSQlI\nUkDyEJCUgCQFJB8BSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJICEpDs\ngCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7ARIiyac\nevgZ9+TbCkhSQPJRWUJasFfyV+YMzvNLuYAk1ZOQFs/PeTOQfJQf0g/Sv8TtCnszIEn1HKT7\nB/Vxm52W49+iAZKP8kKau14a0lb2P2ICJKkeg/T71FH8YntJQPJRXkj3t/yi69fN7YAk1VOQ\n3t00fRRHt7sLSD4qANIb5nZAkuopSHeGR/Fz7e4Cko/yQprXKzwCy8ztgCTVU5B+GUJar90r\ndCD5KP+bDUPTR+Dn9mZAkuopSH8IIW3W7i4g+Sg/pHcPTh6AEXn+wVQgSfUUpDfCfxzt+HZ3\nAclHwjdkl9513rEXPZZvKyBJ9di7dpekHG38Urt7gOQjfkRIqvwhLbt6YNzRN6a1vwdIPgKS\nVPlDikY/fPqeWbneMAKSj4AkVQmQOgpIPgKSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJ\nSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJIC\nEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7IAk\nBSQg2QFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2QpIAEJDsgSQEJSHZAkgISkOyAJAUkINkB\nSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7IEkBCUh2QJICEpDsgCQFJCDZAUkKSECy\nA5IUkIBkByQpIAHJDkhSQAKSHZCkgAQkOyBJAQlIdkCSAhKQ7IqENPPCowb/dF7iEpCkgOSj\nioN0U18Xb9NHokAS6xykZe+3vw1IHioRSP/nUm3+NpDEOgPpsf/a0G33w7ezbgWSh0oE0qlp\nSO6XQBLrBKS7kn/tu10WZN4MJA+VCKR9QkinA0mscEgfbpV+ks/MvB1IHioRSINCSCOBJFY4\npPvDJ3nLzNt7GtIrY44fdXes3bXMm4EkNTI8xjcBSaxwSDeHT7L7KOP2HoY0f/Bt700bclf2\ntcybgaT1XOrVu9vmXSCJFQ7pT6GjAcsybu9hSOPOjX+YMrQu61rmzUASm9Q/6ejpKJDECof0\nZvpPK/e9zNt7GNLwO+If5kXmZV3LvBlIav++ZujwX9UkLgFJqhPv2l2c/gvpn5k39yykWOSh\n+MclkZmZ19re/P6f4y2sbS0Wq/VU8xpPgxqDtZ4mNdR5GlQX1HuatK7R06A1QZOnSbX+ToGg\n4IesvmqDuKMvPZV1c5O3UyBY13J5jUdI0wfFeynPX2xE3dfKf94/t7lb9tS6l+Jf2i1/Kd7i\nFa01x1Z4qmmVp0H1wWpPk+rWeBq0JljnaVJtg6dBK4NGT5NW+DsFAl+TGr2dAkFty+VVMiTe\nbMiMn/6W4odWs0u8zz098T73zMvXtLnWcgFInQxIUhUDKXh5zHEjp8SC4JHIyjbXWi8AqXMB\nSapyIGkBqdCAJAUkHwFJCUhSQPIQkJSAJAUkHwFJCkhAsgOSFJCAZAckKSAByQ5IUkACkh2Q\npIAEJDsgSQEJSHZAkgISkOyAJAUkINkBSQpIQLIDkhSQgGQHJCkgAckOSFJAApIdkKSABCQ7\nIEkBCUh2QJICEpDsgCQFJCDZAUkKSECyA5IUkIBkByQpIAHJDkhSQAKSHZCkgOSh3/6P/5lF\n9tiNS3t6Cdm9cWPJ/cMDa2+8r6eX0K47xvf0Cto17cYPctzaBZAiR/qfWWQ3DHq7p5eQ3ZOD\n7u7pJWS3YtAFPb2Edp1yYE+voF23DHotx61A6qGAJAWkkgpISkCSAlJJBSSpaoZEVH0BichD\nQCLyEJCIPFQ8pFfGHD/q7lj2tamRRLOD4KLkhWPWFr0ff0uK3X/WkBG/XtadK8q3pIa/nnX8\n6H9064o6WFKwZtKo4864r939JbGmBePOiNzavSvKt6Snf3ra0Aue8gAp8a/JTmv512Rbrk09\npSbeuiD4KPF59LXF7sbnkh487unFc8/t1neo8i3pdyfPWPTsSY+WwJLqLzj/mQWznsu+vzTW\nNGfys6O7GVK+JV055ZU3bo88XjykDv7Z86nD22zzduSVYnfjc0nXXR3/8FikoXSWFDvh3sQt\nw5t7fkkPnLIq1/2lsaZ4Y7oZkrCkILjq6uIhDb8j/mFeZF7WtanHDj/5spnpbW45s1tfIeRb\n0t9OejP49MqxJbSkpmP/Fr/lwUiuH+Lq5iVdNP53I0ZPXJV9f2msKeh+SMKSguDSXxUNKRZ5\nKP5xSWRm1rU5T86fOyHySPLW1UMeLHIvnpf0wLHHRsauK6UlXXvme7GaUZF/9/yShh33q7dm\nnXVJLPP+0lhT4tZuhqQsKXj62Le6DFKy8SOSn/52/Ioi9+J3STNP/t/3Zp1/bTf+LZl3SZ+N\nO2bwaX+MzOn5JZ14WmMQzI38p5QghWtK3FoikNouacaQf3p4s6GDv/qSPRJpTOx99G+K3Ynf\nJY26PX5hfuTNElpSEDRGmx+PdOc7iR0s6ezL4xdWRKaX0ku7ljUFJfPSrs2SHh/yYuABUgdf\njCUbn/xa+tXuPRj5l3TKH+MXFqT+NCmRJSVqPv+iblxRR0uaOKIpCF6PvFFKbza0rCkomTcb\nWpf016GzE/d4eft7euINwZmXr2lzbeK0ebNvjTyc2OL6Hxe7D89LmjB02qK5F57ZnadIviXN\neWzeC1ed8FY3rqijJX005Ob35p4bf/HfcksJram+pubscTULS2lJk459vKam5gMP35B9ecxx\nI6fEEq9QVra5Nmn0kJMvnZG4f9ngx4veh98l1f3lR0NGjF9cSkt6/fzjT7q2pltX1MGSgjcv\nH3L6LRm3lM6aapLfwB5cSks6JbmkH/EjQkQ+AhKRh4BE5CEgEXkISEQeAhKRh4BE5CEgEXkI\nSEQeAhKRh4BE5CEglXNN/9Xv1finp3p174+fUfuAVNYt2mqXVcHirXf6NP+m1KUBqbx7Yr2T\nmg/r86+eXgYBqcy70h3sft3TiyAglXtN+7jvdfP/NEQ5AlKZ98YGbpdV+TejLg5I5d3a3Ta+\nxZ3c06sgIJV5P3T3Bxe7ST29DAJSWXe3OzcIGvYf8HpPL6TqA1I599bAvRK/C+ndTb+2pqeX\nUu0BichDQCLyEJCIPAQkIg8BichDQCLyEJCIPAQkIg8BichDQCLyEJCIPAQkIg/9f6mWe3Hc\nnxHmAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg +\n",
    "geom_point(aes(x=beta_plot[1,],y=beta_plot[2,]),size=2) +\n",
    "#annotate(geom='text', x=0.5, y=0.47, \n",
    "#         label=TeX(\"x^{(0)}\", output='character'), parse=TRUE) + \n",
    "xlab('x') + ylab('y') + \n",
    "ggtitle(TeX('Iter del método de descenso en gradiente para $f_o$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "A<-X[,c(2,4,5,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- glmnet(A,y,alpha=1,lambda=reg,standardize=F,nlambda=1,intercept=F,thresh=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ast <- as.matrix(fit$beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                s0\n",
      "disp  0.0006973293\n",
      "drat  2.6120443627\n",
      "wt   -3.6222009972\n",
      "qsec  1.2403485581\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0<-c(1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol <- 1e-8\n",
    "tol_backtracking <- 1e-14\n",
    "maxiter <- 30\n",
    "p_ast <- fo(beta_ast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newtons method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search    condHf\n",
      "1    6.99e+04   1.08e+00      3.57e+04      ---\n",
      "2    1.62e+01   1.41e+00      6.99e+00      1.00e+00    4.71e+05\n",
      "3    1.58e+00   1.00e+00      2.09e+00      1.00e+00    5.34e+05\n",
      "4    3.38e-01   1.89e-01      1.33e-01      1.00e+00    3.24e+05\n",
      "5    3.03e-01   3.61e-02      4.24e-03      1.00e+00    7.76e+05\n",
      "6    2.92e-02   5.76e-03      6.96e-05      1.00e+00    5.27e+05\n",
      "7    5.44e-03   7.19e-04      1.07e-05      1.00e+00    3.14e+05\n",
      "8    2.18e-03   1.62e-03      1.64e-05      1.00e+00    3.32e+06\n",
      "9    3.01e-03   3.30e-03      2.16e-05      1.25e-01    4.48e+05\n",
      "10    1.01e-04   3.43e-03      2.20e-05      1.00e+00    1.97e+06\n",
      "Error of x with respect to x_ast: 3.43e-03\n",
      "Approximate solution:[1]  0.0006261966  2.6223707978 -3.6105443552  1.2371047935\n"
     ]
    }
   ],
   "source": [
    "l<-Newtons_method(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  0.0006261966  2.6223707978 -3.6105443552  1.2371047935\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                s0\n",
      "disp  0.0006973293\n",
      "drat  2.6120443627\n",
      "wt   -3.6222009972\n",
      "qsec  1.2403485581\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "4.59592896526597"
      ],
      "text/latex": [
       "4.59592896526597"
      ],
      "text/markdown": [
       "4.59592896526597"
      ],
      "text/plain": [
       "[1] 4.595929"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 10 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>-0.05606289</td><td>-0.01851005</td><td>-0.003576263</td><td> 0.0009944162</td><td> 0.0005168405</td><td> 0.0007160974</td><td> 0.0006791189</td><td> 0.0006377508</td><td> 0.0006261966</td></tr>\n",
       "\t<tr><td>1</td><td>-0.12200766</td><td> 5.97538040</td><td> 1.869463441</td><td> 2.7751959837</td><td> 2.6038033655</td><td> 2.6095959668</td><td> 2.6183362938</td><td> 2.6231848830</td><td> 2.6223707978</td></tr>\n",
       "\t<tr><td>1</td><td> 2.31423223</td><td>-0.55655647</td><td>-3.169499864</td><td>-3.6324961838</td><td>-3.5968211157</td><td>-3.6243745447</td><td>-3.6184323138</td><td>-3.6122536944</td><td>-3.6105443552</td></tr>\n",
       "\t<tr><td>1</td><td> 1.48267081</td><td> 0.26564075</td><td> 1.362212247</td><td> 1.2057895393</td><td> 1.2396914838</td><td> 1.2409809623</td><td> 1.2386540494</td><td> 1.2371100579</td><td> 1.2371047935</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 10 of type dbl\n",
       "\\begin{tabular}{llllllllll}\n",
       "\t 1 & -0.05606289 & -0.01851005 & -0.003576263 &  0.0009944162 &  0.0005168405 &  0.0007160974 &  0.0006791189 &  0.0006377508 &  0.0006261966\\\\\n",
       "\t 1 & -0.12200766 &  5.97538040 &  1.869463441 &  2.7751959837 &  2.6038033655 &  2.6095959668 &  2.6183362938 &  2.6231848830 &  2.6223707978\\\\\n",
       "\t 1 &  2.31423223 & -0.55655647 & -3.169499864 & -3.6324961838 & -3.5968211157 & -3.6243745447 & -3.6184323138 & -3.6122536944 & -3.6105443552\\\\\n",
       "\t 1 &  1.48267081 &  0.26564075 &  1.362212247 &  1.2057895393 &  1.2396914838 &  1.2409809623 &  1.2386540494 &  1.2371100579 &  1.2371047935\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 10 of type dbl\n",
       "\n",
       "| 1 | -0.05606289 | -0.01851005 | -0.003576263 |  0.0009944162 |  0.0005168405 |  0.0007160974 |  0.0006791189 |  0.0006377508 |  0.0006261966 |\n",
       "| 1 | -0.12200766 |  5.97538040 |  1.869463441 |  2.7751959837 |  2.6038033655 |  2.6095959668 |  2.6183362938 |  2.6231848830 |  2.6223707978 |\n",
       "| 1 |  2.31423223 | -0.55655647 | -3.169499864 | -3.6324961838 | -3.5968211157 | -3.6243745447 | -3.6184323138 | -3.6122536944 | -3.6105443552 |\n",
       "| 1 |  1.48267081 |  0.26564075 |  1.362212247 |  1.2057895393 |  1.2396914838 |  1.2409809623 |  1.2386540494 |  1.2371100579 |  1.2371047935 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]        [,3]        [,4]         [,5]          [,6]         \n",
       "[1,] 1    -0.05606289 -0.01851005 -0.003576263  0.0009944162  0.0005168405\n",
       "[2,] 1    -0.12200766  5.97538040  1.869463441  2.7751959837  2.6038033655\n",
       "[3,] 1     2.31423223 -0.55655647 -3.169499864 -3.6324961838 -3.5968211157\n",
       "[4,] 1     1.48267081  0.26564075  1.362212247  1.2057895393  1.2396914838\n",
       "     [,7]          [,8]          [,9]          [,10]        \n",
       "[1,]  0.0007160974  0.0006791189  0.0006377508  0.0006261966\n",
       "[2,]  2.6095959668  2.6183362938  2.6231848830  2.6223707978\n",
       "[3,] -3.6243745447 -3.6184323138 -3.6122536944 -3.6105443552\n",
       "[4,]  1.2409809623  1.2386540494  1.2371100579  1.2371047935"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg<-.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y <- mtcars %>% select(mpg) %>% as.matrix()\n",
    "X <- mtcars %>% select(-mpg) %>% as.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A<-X[,c(2,4)]\n",
    "A<-X[,c(2,4,5,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cte <- sum(y*y)\n",
    "mpoints<-nrow(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "14042.31"
      ],
      "text/latex": [
       "14042.31"
      ],
      "text/markdown": [
       "14042.31"
      ],
      "text/plain": [
       "[1] 14042.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "32"
      ],
      "text/latex": [
       "32"
      ],
      "text/markdown": [
       "32"
      ],
      "text/plain": [
       "[1] 32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo <-function(beta)1/mpoints*(1/2*cte - sum(beta*(t(A)%*%y)) + 1/2*sum(beta*(t(A)%*%(A%*%beta)))) + reg/2*sum(beta*beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre class=language-r><code>function (beta) \n",
       "1/mpoints * (1/2 * cte - sum(beta * (t(A) %*% y)) + 1/2 * sum(beta * \n",
       "<span style=white-space:pre-wrap>    (t(A) %*% (A %*% beta)))) + reg/2 * sum(beta * beta)</span></code></pre>"
      ],
      "text/latex": [
       "\\begin{minted}{r}\n",
       "function (beta) \n",
       "1/mpoints * (1/2 * cte - sum(beta * (t(A) \\%*\\% y)) + 1/2 * sum(beta * \n",
       "    (t(A) \\%*\\% (A \\%*\\% beta)))) + reg/2 * sum(beta * beta)\n",
       "\\end{minted}"
      ],
      "text/markdown": [
       "```r\n",
       "function (beta) \n",
       "1/mpoints * (1/2 * cte - sum(beta * (t(A) %*% y)) + 1/2 * sum(beta * \n",
       "    (t(A) %*% (A %*% beta)))) + reg/2 * sum(beta * beta)\n",
       "```"
      ],
      "text/plain": [
       "function(beta)1/mpoints*(1/2*cte - sum(beta*(t(A)%*%y)) + 1/2*sum(beta*(t(A)%*%(A%*%beta)))) + reg/2*sum(beta*beta)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hessian_evaluation<-function(beta)1/mpoints*t(A)%*%A + reg*diag(rep(length(beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_evaluation<- function(beta) 1/mpoints * t(A)%*%(A%*%beta-y) + reg*beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0<-c(1.5,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>103804.6204485</li>\n",
       "\t<li>1191.13537948579</li>\n",
       "\t<li>1290.35033751279</li>\n",
       "\t<li>6118.18832112476</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 103804.6204485\n",
       "\\item 1191.13537948579\n",
       "\\item 1290.35033751279\n",
       "\\item 6118.18832112476\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 103804.6204485\n",
       "2. 1191.13537948579\n",
       "3. 1290.35033751279\n",
       "4. 6118.18832112476\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 103804.620   1191.135   1290.350   6118.188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradient_approximation(fo,beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>disp</th><td>103804.622</td></tr>\n",
       "\t<tr><th scope=row>drat</th><td>  1191.136</td></tr>\n",
       "\t<tr><th scope=row>wt</th><td>  1290.350</td></tr>\n",
       "\t<tr><th scope=row>qsec</th><td>  6118.187</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 1 of type dbl\n",
       "\\begin{tabular}{r|l}\n",
       "\tdisp & 103804.622\\\\\n",
       "\tdrat &   1191.136\\\\\n",
       "\twt &   1290.350\\\\\n",
       "\tqsec &   6118.187\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 1 of type dbl\n",
       "\n",
       "| disp | 103804.622 |\n",
       "| drat |   1191.136 |\n",
       "| wt |   1290.350 |\n",
       "| qsec |   6118.187 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      \n",
       "disp 103804.622\n",
       "drat   1191.136\n",
       "wt     1290.350\n",
       "qsec   6118.187"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gf_evaluation(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 4 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>68117.5152</td><td>742.14768</td><td>844.01108</td><td>4030.88052</td></tr>\n",
       "\t<tr><td>  742.1477</td><td> 58.20766</td><td> 29.10383</td><td>  87.31149</td></tr>\n",
       "\t<tr><td>  844.0111</td><td> 29.10383</td><td> 29.10383</td><td>  58.20766</td></tr>\n",
       "\t<tr><td> 4030.8805</td><td> 87.31149</td><td> 58.20766</td><td> 334.69405</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 4 of type dbl\n",
       "\\begin{tabular}{llll}\n",
       "\t 68117.5152 & 742.14768 & 844.01108 & 4030.88052\\\\\n",
       "\t   742.1477 &  58.20766 &  29.10383 &   87.31149\\\\\n",
       "\t   844.0111 &  29.10383 &  29.10383 &   58.20766\\\\\n",
       "\t  4030.8805 &  87.31149 &  58.20766 &  334.69405\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 4 of type dbl\n",
       "\n",
       "| 68117.5152 | 742.14768 | 844.01108 | 4030.88052 |\n",
       "|   742.1477 |  58.20766 |  29.10383 |   87.31149 |\n",
       "|   844.0111 |  29.10383 |  29.10383 |   58.20766 |\n",
       "|  4030.8805 |  87.31149 |  58.20766 |  334.69405 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]      [,3]      [,4]      \n",
       "[1,] 68117.5152 742.14768 844.01108 4030.88052\n",
       "[2,]   742.1477  58.20766  29.10383   87.31149\n",
       "[3,]   844.0111  29.10383  29.10383   58.20766\n",
       "[4,]  4030.8805  87.31149  58.20766  334.69405"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hessian_approximation(fo,beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>disp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>disp</th><td>68113.8584</td><td>784.21238</td><td>846.60903</td><td>4025.04700</td></tr>\n",
       "\t<tr><th scope=row>drat</th><td>  784.2124</td><td> 13.71221</td><td> 11.20997</td><td>  64.27856</td></tr>\n",
       "\t<tr><th scope=row>wt</th><td>  846.6090</td><td> 11.20997</td><td> 11.77816</td><td>  57.12796</td></tr>\n",
       "\t<tr><th scope=row>qsec</th><td> 4025.0470</td><td> 64.27856</td><td> 57.12796</td><td> 322.17126</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & disp & drat & wt & qsec\\\\\n",
       "\\hline\n",
       "\tdisp & 68113.8584 & 784.21238 & 846.60903 & 4025.04700\\\\\n",
       "\tdrat &   784.2124 &  13.71221 &  11.20997 &   64.27856\\\\\n",
       "\twt &   846.6090 &  11.20997 &  11.77816 &   57.12796\\\\\n",
       "\tqsec &  4025.0470 &  64.27856 &  57.12796 &  322.17126\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | disp | drat | wt | qsec |\n",
       "|---|---|---|---|---|\n",
       "| disp | 68113.8584 | 784.21238 | 846.60903 | 4025.04700 |\n",
       "| drat |   784.2124 |  13.71221 |  11.20997 |   64.27856 |\n",
       "| wt |   846.6090 |  11.20997 |  11.77816 |   57.12796 |\n",
       "| qsec |  4025.0470 |  64.27856 |  57.12796 |  322.17126 |\n",
       "\n"
      ],
      "text/plain": [
       "     disp       drat      wt        qsec      \n",
       "disp 68113.8584 784.21238 846.60903 4025.04700\n",
       "drat   784.2124  13.71221  11.20997   64.27856\n",
       "wt     846.6090  11.20997  11.77816   57.12796\n",
       "qsec  4025.0470  64.27856  57.12796  322.17126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hessian_evaluation(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1.5</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.5\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.5\n",
       "2. 1\n",
       "3. 1\n",
       "4. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.5 1.0 1.0 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0<-c(0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-4022.03340854612</li>\n",
       "\t<li>-74.3836551464483</li>\n",
       "\t<li>-59.679774722099</li>\n",
       "\t<li>-362.960778943489</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -4022.03340854612\n",
       "\\item -74.3836551464483\n",
       "\\item -59.679774722099\n",
       "\\item -362.960778943489\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -4022.03340854612\n",
       "2. -74.3836551464483\n",
       "3. -59.679774722099\n",
       "4. -362.960778943489\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -4022.03341   -74.38366   -59.67977  -362.96078"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradient_approximation(fo,beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>disp</th><td>-4022.03375</td></tr>\n",
       "\t<tr><th scope=row>drat</th><td>  -74.38366</td></tr>\n",
       "\t<tr><th scope=row>wt</th><td>  -59.67977</td></tr>\n",
       "\t<tr><th scope=row>qsec</th><td> -362.96078</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 1 of type dbl\n",
       "\\begin{tabular}{r|l}\n",
       "\tdisp & -4022.03375\\\\\n",
       "\tdrat &   -74.38366\\\\\n",
       "\twt &   -59.67977\\\\\n",
       "\tqsec &  -362.96078\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 1 of type dbl\n",
       "\n",
       "| disp | -4022.03375 |\n",
       "| drat |   -74.38366 |\n",
       "| wt |   -59.67977 |\n",
       "| qsec |  -362.96078 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       \n",
       "disp -4022.03375\n",
       "drat   -74.38366\n",
       "wt     -59.67977\n",
       "qsec  -362.96078"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gf_evaluation(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 4 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>68113.8204</td><td>784.21181</td><td>846.62588</td><td>4025.05407</td></tr>\n",
       "\t<tr><td>  784.2118</td><td> 13.72769</td><td> 11.22658</td><td>  64.28991</td></tr>\n",
       "\t<tr><td>  846.6259</td><td> 11.22658</td><td> 11.79501</td><td>  57.12764</td></tr>\n",
       "\t<tr><td> 4025.0541</td><td> 64.28991</td><td> 57.12764</td><td> 322.16008</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 4 of type dbl\n",
       "\\begin{tabular}{llll}\n",
       "\t 68113.8204 & 784.21181 & 846.62588 & 4025.05407\\\\\n",
       "\t   784.2118 &  13.72769 &  11.22658 &   64.28991\\\\\n",
       "\t   846.6259 &  11.22658 &  11.79501 &   57.12764\\\\\n",
       "\t  4025.0541 &  64.28991 &  57.12764 &  322.16008\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 4 of type dbl\n",
       "\n",
       "| 68113.8204 | 784.21181 | 846.62588 | 4025.05407 |\n",
       "|   784.2118 |  13.72769 |  11.22658 |   64.28991 |\n",
       "|   846.6259 |  11.22658 |  11.79501 |   57.12764 |\n",
       "|  4025.0541 |  64.28991 |  57.12764 |  322.16008 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]      [,3]      [,4]      \n",
       "[1,] 68113.8204 784.21181 846.62588 4025.05407\n",
       "[2,]   784.2118  13.72769  11.22658   64.28991\n",
       "[3,]   846.6259  11.22658  11.79501   57.12764\n",
       "[4,]  4025.0541  64.28991  57.12764  322.16008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hessian_approximation(fo,beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>disp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>disp</th><td>68113.8584</td><td>784.21238</td><td>846.60903</td><td>4025.04700</td></tr>\n",
       "\t<tr><th scope=row>drat</th><td>  784.2124</td><td> 13.71221</td><td> 11.20997</td><td>  64.27856</td></tr>\n",
       "\t<tr><th scope=row>wt</th><td>  846.6090</td><td> 11.20997</td><td> 11.77816</td><td>  57.12796</td></tr>\n",
       "\t<tr><th scope=row>qsec</th><td> 4025.0470</td><td> 64.27856</td><td> 57.12796</td><td> 322.17126</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & disp & drat & wt & qsec\\\\\n",
       "\\hline\n",
       "\tdisp & 68113.8584 & 784.21238 & 846.60903 & 4025.04700\\\\\n",
       "\tdrat &   784.2124 &  13.71221 &  11.20997 &   64.27856\\\\\n",
       "\twt &   846.6090 &  11.20997 &  11.77816 &   57.12796\\\\\n",
       "\tqsec &  4025.0470 &  64.27856 &  57.12796 &  322.17126\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | disp | drat | wt | qsec |\n",
       "|---|---|---|---|---|\n",
       "| disp | 68113.8584 | 784.21238 | 846.60903 | 4025.04700 |\n",
       "| drat |   784.2124 |  13.71221 |  11.20997 |   64.27856 |\n",
       "| wt |   846.6090 |  11.20997 |  11.77816 |   57.12796 |\n",
       "| qsec |  4025.0470 |  64.27856 |  57.12796 |  322.17126 |\n",
       "\n"
      ],
      "text/plain": [
       "     disp       drat      wt        qsec      \n",
       "disp 68113.8584 784.21238 846.60903 4025.04700\n",
       "drat   784.2124  13.71221  11.20997   64.27856\n",
       "wt     846.6090  11.20997  11.77816   57.12796\n",
       "qsec  4025.0470  64.27856  57.12796  322.17126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hessian_evaluation(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- glmnet(A,y,alpha=0,lambda=reg,standardize=F,nlambda=1,intercept=F,thresh=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ast <- as.matrix(fit$beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               s0\n",
      "disp -0.002266897\n",
      "drat  2.574343046\n",
      "wt   -3.235364158\n",
      "qsec  1.216575201\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0<-c(0,0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newtons method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "3. 0\n",
       "4. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0 0 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol <- 1e-8\n",
    "tol_backtracking <- 1e-14\n",
    "maxiter <- 30\n",
    "p_ast <- fo(beta_ast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search    condHf\n",
      "1    4.04e+03   1.00e+00      2.12e+02      ---\n",
      "2    2.26e-02   5.28e-01      1.90e+00      1.00e+00    9.34e+04\n",
      "3    3.07e-03   5.27e-01      1.90e+00      1.00e+00    1.21e+05\n",
      "4    7.55e-04   5.27e-01      1.90e+00      1.00e+00    1.24e+05\n",
      "5    7.47e-05   5.27e-01      1.90e+00      1.00e+00    1.07e+05\n",
      "Error of x with respect to x_ast: 5.27e-01\n",
      "Approximate solution:[1] -0.01818806  1.57681450 -1.19395750  1.25095429\n"
     ]
    }
   ],
   "source": [
    "l<-Newtons_method(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -0.01818806  1.57681450 -1.19395750  1.25095429\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               s0\n",
      "disp -0.002266897\n",
      "drat  2.574343046\n",
      "wt   -3.235364158\n",
      "qsec  1.216575201\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.94685758721091"
      ],
      "text/latex": [
       "5.94685758721091"
      ],
      "text/markdown": [
       "5.94685758721091"
      ],
      "text/plain": [
       "[1] 5.946858"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 29 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>-0.01814363</td><td>-0.01816322</td><td>-0.01819045</td><td>-0.01818806</td><td>-0.01818871</td><td>-0.01818874</td><td>-0.01818876</td><td>-0.01818877</td><td>-0.01818877</td><td>-0.01818877</td><td>⋯</td><td>-0.01818877</td><td>-0.01818877</td><td>-0.01818877</td><td>-0.01818877</td><td>-0.01818877</td><td>-0.01818877</td><td>-0.01818877</td><td>-0.01818877</td><td>-0.01818877</td><td>-0.01818877</td></tr>\n",
       "\t<tr><td> 1.55616018</td><td> 1.57502924</td><td> 1.57745397</td><td> 1.57681450</td><td> 1.57683735</td><td> 1.57684258</td><td> 1.57684266</td><td> 1.57684249</td><td> 1.57684249</td><td> 1.57684249</td><td>⋯</td><td> 1.57684248</td><td> 1.57684248</td><td> 1.57684248</td><td> 1.57684248</td><td> 1.57684248</td><td> 1.57684248</td><td> 1.57684248</td><td> 1.57684248</td><td> 1.57684248</td><td> 1.57684248</td></tr>\n",
       "\t<tr><td>-1.20239992</td><td>-1.19746132</td><td>-1.19357550</td><td>-1.19395750</td><td>-1.19386751</td><td>-1.19386388</td><td>-1.19386079</td><td>-1.19386003</td><td>-1.19386003</td><td>-1.19386004</td><td>⋯</td><td>-1.19386004</td><td>-1.19386004</td><td>-1.19386004</td><td>-1.19386004</td><td>-1.19386004</td><td>-1.19386004</td><td>-1.19386004</td><td>-1.19386004</td><td>-1.19386004</td><td>-1.19386004</td></tr>\n",
       "\t<tr><td> 1.25600518</td><td> 1.25161864</td><td> 1.25078981</td><td> 1.25095429</td><td> 1.25094206</td><td> 1.25094067</td><td> 1.25094046</td><td> 1.25094040</td><td> 1.25094040</td><td> 1.25094040</td><td>⋯</td><td> 1.25094040</td><td> 1.25094040</td><td> 1.25094040</td><td> 1.25094040</td><td> 1.25094040</td><td> 1.25094040</td><td> 1.25094040</td><td> 1.25094040</td><td> 1.25094040</td><td> 1.25094040</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 29 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       "\t -0.01814363 & -0.01816322 & -0.01819045 & -0.01818806 & -0.01818871 & -0.01818874 & -0.01818876 & -0.01818877 & -0.01818877 & -0.01818877 & ⋯ & -0.01818877 & -0.01818877 & -0.01818877 & -0.01818877 & -0.01818877 & -0.01818877 & -0.01818877 & -0.01818877 & -0.01818877 & -0.01818877\\\\\n",
       "\t  1.55616018 &  1.57502924 &  1.57745397 &  1.57681450 &  1.57683735 &  1.57684258 &  1.57684266 &  1.57684249 &  1.57684249 &  1.57684249 & ⋯ &  1.57684248 &  1.57684248 &  1.57684248 &  1.57684248 &  1.57684248 &  1.57684248 &  1.57684248 &  1.57684248 &  1.57684248 &  1.57684248\\\\\n",
       "\t -1.20239992 & -1.19746132 & -1.19357550 & -1.19395750 & -1.19386751 & -1.19386388 & -1.19386079 & -1.19386003 & -1.19386003 & -1.19386004 & ⋯ & -1.19386004 & -1.19386004 & -1.19386004 & -1.19386004 & -1.19386004 & -1.19386004 & -1.19386004 & -1.19386004 & -1.19386004 & -1.19386004\\\\\n",
       "\t  1.25600518 &  1.25161864 &  1.25078981 &  1.25095429 &  1.25094206 &  1.25094067 &  1.25094046 &  1.25094040 &  1.25094040 &  1.25094040 & ⋯ &  1.25094040 &  1.25094040 &  1.25094040 &  1.25094040 &  1.25094040 &  1.25094040 &  1.25094040 &  1.25094040 &  1.25094040 &  1.25094040\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 29 of type dbl\n",
       "\n",
       "| -0.01814363 | -0.01816322 | -0.01819045 | -0.01818806 | -0.01818871 | -0.01818874 | -0.01818876 | -0.01818877 | -0.01818877 | -0.01818877 | ⋯ | -0.01818877 | -0.01818877 | -0.01818877 | -0.01818877 | -0.01818877 | -0.01818877 | -0.01818877 | -0.01818877 | -0.01818877 | -0.01818877 |\n",
       "|  1.55616018 |  1.57502924 |  1.57745397 |  1.57681450 |  1.57683735 |  1.57684258 |  1.57684266 |  1.57684249 |  1.57684249 |  1.57684249 | ⋯ |  1.57684248 |  1.57684248 |  1.57684248 |  1.57684248 |  1.57684248 |  1.57684248 |  1.57684248 |  1.57684248 |  1.57684248 |  1.57684248 |\n",
       "| -1.20239992 | -1.19746132 | -1.19357550 | -1.19395750 | -1.19386751 | -1.19386388 | -1.19386079 | -1.19386003 | -1.19386003 | -1.19386004 | ⋯ | -1.19386004 | -1.19386004 | -1.19386004 | -1.19386004 | -1.19386004 | -1.19386004 | -1.19386004 | -1.19386004 | -1.19386004 | -1.19386004 |\n",
       "|  1.25600518 |  1.25161864 |  1.25078981 |  1.25095429 |  1.25094206 |  1.25094067 |  1.25094046 |  1.25094040 |  1.25094040 |  1.25094040 | ⋯ |  1.25094040 |  1.25094040 |  1.25094040 |  1.25094040 |  1.25094040 |  1.25094040 |  1.25094040 |  1.25094040 |  1.25094040 |  1.25094040 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]        [,2]        [,3]        [,4]        [,5]        [,6]       \n",
       "[1,] -0.01814363 -0.01816322 -0.01819045 -0.01818806 -0.01818871 -0.01818874\n",
       "[2,]  1.55616018  1.57502924  1.57745397  1.57681450  1.57683735  1.57684258\n",
       "[3,] -1.20239992 -1.19746132 -1.19357550 -1.19395750 -1.19386751 -1.19386388\n",
       "[4,]  1.25600518  1.25161864  1.25078981  1.25095429  1.25094206  1.25094067\n",
       "     [,7]        [,8]        [,9]        [,10]       [,11] [,12]      \n",
       "[1,] -0.01818876 -0.01818877 -0.01818877 -0.01818877 ⋯     -0.01818877\n",
       "[2,]  1.57684266  1.57684249  1.57684249  1.57684249 ⋯      1.57684248\n",
       "[3,] -1.19386079 -1.19386003 -1.19386003 -1.19386004 ⋯     -1.19386004\n",
       "[4,]  1.25094046  1.25094040  1.25094040  1.25094040 ⋯      1.25094040\n",
       "     [,13]       [,14]       [,15]       [,16]       [,17]       [,18]      \n",
       "[1,] -0.01818877 -0.01818877 -0.01818877 -0.01818877 -0.01818877 -0.01818877\n",
       "[2,]  1.57684248  1.57684248  1.57684248  1.57684248  1.57684248  1.57684248\n",
       "[3,] -1.19386004 -1.19386004 -1.19386004 -1.19386004 -1.19386004 -1.19386004\n",
       "[4,]  1.25094040  1.25094040  1.25094040  1.25094040  1.25094040  1.25094040\n",
       "     [,19]       [,20]       [,21]      \n",
       "[1,] -0.01818877 -0.01818877 -0.01818877\n",
       "[2,]  1.57684248  1.57684248  1.57684248\n",
       "[3,] -1.19386004 -1.19386004 -1.19386004\n",
       "[4,]  1.25094040  1.25094040  1.25094040"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAC8VBMVEUAAAABAQECAgIDAwME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\nu1UWAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg +\n",
    "geom_point(aes(x=beta_plot[1,],y=beta_plot[2,]),size=2) +\n",
    "#annotate(geom='text', x=0.5, y=0.47, \n",
    "#         label=TeX(\"x^{(0)}\", output='character'), parse=TRUE) + \n",
    "xlab('x') + ylab('y') + \n",
    "ggtitle(TeX('Iter del método de descenso en gradiente para $f_o$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search\n",
      "1    4.04e+03   1.00e+00      2.12e+02      ---\n",
      "2    1.98e+02   1.00e+00      9.30e+01      1.52587890625e-05\n",
      "3    1.29e+02   1.00e+00      9.28e+01      1.52587890625e-05\n",
      "4    1.97e+03   9.74e-01      6.99e+01      0.00390625\n",
      "5    1.20e+02   9.74e-01      4.15e+01      1.52587890625e-05\n",
      "6    1.31e+03   9.63e-01      3.02e+01      0.00390625\n",
      "7    7.89e+01   9.63e-01      1.75e+01      1.52587890625e-05\n",
      "8    8.57e+02   9.60e-01      1.27e+01      0.00390625\n",
      "9    5.15e+01   9.60e-01      7.31e+00      1.52587890625e-05\n",
      "10    5.59e+02   9.59e-01      5.25e+00      0.00390625\n",
      "11    3.37e+01   9.59e-01      2.96e+00      1.52587890625e-05\n",
      "12    3.65e+02   9.60e-01      2.08e+00      0.00390625\n",
      "13    2.21e+01   9.60e-01      1.11e+00      1.52587890625e-05\n",
      "14    2.38e+02   9.60e-01      7.34e-01      0.00390625\n",
      "15    1.45e+01   9.60e-01      3.20e-01      1.52587890625e-05\n",
      "16    1.55e+02   9.60e-01      1.61e-01      0.00390625\n",
      "17    9.60e+00   9.60e-01      1.55e-02      1.52587890625e-05\n",
      "18    1.01e+02   9.61e-01      8.30e-02      0.00390625\n",
      "19    6.44e+00   9.61e-01      1.58e-01      1.52587890625e-05\n",
      "20    6.60e+01   9.61e-01      1.87e-01      0.00390625\n",
      "21    4.44e+00   9.61e-01      2.19e-01      1.52587890625e-05\n",
      "22    4.31e+01   9.61e-01      2.31e-01      0.00390625\n",
      "23    3.20e+00   9.61e-01      2.44e-01      1.52587890625e-05\n",
      "24    2.81e+01   9.61e-01      2.50e-01      0.00390625\n",
      "25    2.48e+00   9.61e-01      2.55e-01      1.52587890625e-05\n",
      "26    8.18e+01   9.46e-01      3.57e-01      0.0625\n",
      "27    3.58e+00   9.46e-01      4.06e-01      1.52587890625e-05\n",
      "28    1.67e+00   9.46e-01      4.06e-01      1.52587890625e-05\n",
      "29    5.82e+01   9.36e-01      4.55e-01      0.0625\n",
      "30    3.25e+00   9.36e-01      4.80e-01      1.52587890625e-05\n",
      "Error of x with respect to x_ast: 9.36e-01\n",
      "Approximate solution:[1] -0.03003033  0.17906435  0.00000000  1.47198616\n"
     ]
    }
   ],
   "source": [
    "l<-coordinate_descent(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -0.03003033  0.17906435  0.00000000  1.47198616\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               s0\n",
      "disp -0.002266897\n",
      "drat  2.574343046\n",
      "wt   -3.235364158\n",
      "qsec  1.216575201\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "7.36712584893743"
      ],
      "text/latex": [
       "7.36712584893743"
      ],
      "text/markdown": [
       "7.36712584893743"
      ],
      "text/plain": [
       "[1] 7.367126"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 29 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0.06137136</td><td>0.05895732</td><td>0.05895732</td><td>0.02890624</td><td>0.02890624</td><td>0.008861516</td><td>0.008861516</td><td>-0.004219583</td><td>-0.004219583</td><td>-0.01275184</td><td>⋯</td><td>-0.02686602</td><td>-0.02686602</td><td>-0.02752299</td><td>-0.02752299</td><td>-0.0279515</td><td>-0.0279515</td><td>-0.02919589</td><td>-0.02914694</td><td>-0.02914694</td><td>-0.03003033</td></tr>\n",
       "\t<tr><td>0.00000000</td><td>0.00000000</td><td>0.00000000</td><td>0.00000000</td><td>0.00000000</td><td>0.000000000</td><td>0.000000000</td><td> 0.000000000</td><td> 0.000000000</td><td> 0.00000000</td><td>⋯</td><td> 0.00000000</td><td> 0.00000000</td><td> 0.00000000</td><td> 0.00000000</td><td> 0.0000000</td><td> 0.1054010</td><td> 0.10540102</td><td> 0.10540102</td><td> 0.17906435</td><td> 0.17906435</td></tr>\n",
       "\t<tr><td>0.00000000</td><td>0.00000000</td><td>0.00000000</td><td>0.00000000</td><td>0.00000000</td><td>0.000000000</td><td>0.000000000</td><td> 0.000000000</td><td> 0.000000000</td><td> 0.00000000</td><td>⋯</td><td> 0.00000000</td><td> 0.00000000</td><td> 0.00000000</td><td> 0.00000000</td><td> 0.0000000</td><td> 0.0000000</td><td> 0.00000000</td><td> 0.00000000</td><td> 0.00000000</td><td> 0.00000000</td></tr>\n",
       "\t<tr><td>0.00000000</td><td>0.00000000</td><td>0.49083910</td><td>0.49083910</td><td>0.83645455</td><td>0.836454553</td><td>1.062279338</td><td> 1.062279338</td><td> 1.209579842</td><td> 1.20957984</td><td>⋯</td><td> 1.45324634</td><td> 1.46458836</td><td> 1.46458836</td><td> 1.47198616</td><td> 1.4719862</td><td> 1.4719862</td><td> 1.47198616</td><td> 1.47198616</td><td> 1.47198616</td><td> 1.47198616</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 29 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       "\t 0.06137136 & 0.05895732 & 0.05895732 & 0.02890624 & 0.02890624 & 0.008861516 & 0.008861516 & -0.004219583 & -0.004219583 & -0.01275184 & ⋯ & -0.02686602 & -0.02686602 & -0.02752299 & -0.02752299 & -0.0279515 & -0.0279515 & -0.02919589 & -0.02914694 & -0.02914694 & -0.03003033\\\\\n",
       "\t 0.00000000 & 0.00000000 & 0.00000000 & 0.00000000 & 0.00000000 & 0.000000000 & 0.000000000 &  0.000000000 &  0.000000000 &  0.00000000 & ⋯ &  0.00000000 &  0.00000000 &  0.00000000 &  0.00000000 &  0.0000000 &  0.1054010 &  0.10540102 &  0.10540102 &  0.17906435 &  0.17906435\\\\\n",
       "\t 0.00000000 & 0.00000000 & 0.00000000 & 0.00000000 & 0.00000000 & 0.000000000 & 0.000000000 &  0.000000000 &  0.000000000 &  0.00000000 & ⋯ &  0.00000000 &  0.00000000 &  0.00000000 &  0.00000000 &  0.0000000 &  0.0000000 &  0.00000000 &  0.00000000 &  0.00000000 &  0.00000000\\\\\n",
       "\t 0.00000000 & 0.00000000 & 0.49083910 & 0.49083910 & 0.83645455 & 0.836454553 & 1.062279338 &  1.062279338 &  1.209579842 &  1.20957984 & ⋯ &  1.45324634 &  1.46458836 &  1.46458836 &  1.47198616 &  1.4719862 &  1.4719862 &  1.47198616 &  1.47198616 &  1.47198616 &  1.47198616\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 29 of type dbl\n",
       "\n",
       "| 0.06137136 | 0.05895732 | 0.05895732 | 0.02890624 | 0.02890624 | 0.008861516 | 0.008861516 | -0.004219583 | -0.004219583 | -0.01275184 | ⋯ | -0.02686602 | -0.02686602 | -0.02752299 | -0.02752299 | -0.0279515 | -0.0279515 | -0.02919589 | -0.02914694 | -0.02914694 | -0.03003033 |\n",
       "| 0.00000000 | 0.00000000 | 0.00000000 | 0.00000000 | 0.00000000 | 0.000000000 | 0.000000000 |  0.000000000 |  0.000000000 |  0.00000000 | ⋯ |  0.00000000 |  0.00000000 |  0.00000000 |  0.00000000 |  0.0000000 |  0.1054010 |  0.10540102 |  0.10540102 |  0.17906435 |  0.17906435 |\n",
       "| 0.00000000 | 0.00000000 | 0.00000000 | 0.00000000 | 0.00000000 | 0.000000000 | 0.000000000 |  0.000000000 |  0.000000000 |  0.00000000 | ⋯ |  0.00000000 |  0.00000000 |  0.00000000 |  0.00000000 |  0.0000000 |  0.0000000 |  0.00000000 |  0.00000000 |  0.00000000 |  0.00000000 |\n",
       "| 0.00000000 | 0.00000000 | 0.49083910 | 0.49083910 | 0.83645455 | 0.836454553 | 1.062279338 |  1.062279338 |  1.209579842 |  1.20957984 | ⋯ |  1.45324634 |  1.46458836 |  1.46458836 |  1.47198616 |  1.4719862 |  1.4719862 |  1.47198616 |  1.47198616 |  1.47198616 |  1.47198616 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]       [,3]       [,4]       [,5]       [,6]       \n",
       "[1,] 0.06137136 0.05895732 0.05895732 0.02890624 0.02890624 0.008861516\n",
       "[2,] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.000000000\n",
       "[3,] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.000000000\n",
       "[4,] 0.00000000 0.00000000 0.49083910 0.49083910 0.83645455 0.836454553\n",
       "     [,7]        [,8]         [,9]         [,10]       [,11] [,12]      \n",
       "[1,] 0.008861516 -0.004219583 -0.004219583 -0.01275184 ⋯     -0.02686602\n",
       "[2,] 0.000000000  0.000000000  0.000000000  0.00000000 ⋯      0.00000000\n",
       "[3,] 0.000000000  0.000000000  0.000000000  0.00000000 ⋯      0.00000000\n",
       "[4,] 1.062279338  1.062279338  1.209579842  1.20957984 ⋯      1.45324634\n",
       "     [,13]       [,14]       [,15]       [,16]      [,17]      [,18]      \n",
       "[1,] -0.02686602 -0.02752299 -0.02752299 -0.0279515 -0.0279515 -0.02919589\n",
       "[2,]  0.00000000  0.00000000  0.00000000  0.0000000  0.1054010  0.10540102\n",
       "[3,]  0.00000000  0.00000000  0.00000000  0.0000000  0.0000000  0.00000000\n",
       "[4,]  1.46458836  1.46458836  1.47198616  1.4719862  1.4719862  1.47198616\n",
       "     [,19]       [,20]       [,21]      \n",
       "[1,] -0.02914694 -0.02914694 -0.03003033\n",
       "[2,]  0.10540102  0.17906435  0.17906435\n",
       "[3,]  0.00000000  0.00000000  0.00000000\n",
       "[4,]  1.47198616  1.47198616  1.47198616"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I    Normagf   Error x_ast   Error p_ast   line search\n",
      "1    4.04e+03   1.00e+00      2.12e+02      ---\n",
      "2    2.17e+02   1.00e+00      9.23e+01      1.52587890625e-05\n",
      "3    2.29e+02   9.99e-01      9.19e+01      3.0517578125e-05\n",
      "4    2.42e+02   9.99e-01      9.14e+01      3.0517578125e-05\n",
      "5    2.58e+02   9.99e-01      9.10e+01      3.0517578125e-05\n",
      "6    2.74e+02   9.98e-01      9.06e+01      3.0517578125e-05\n",
      "7    2.93e+02   9.98e-01      9.01e+01      3.0517578125e-05\n",
      "8    3.14e+02   9.98e-01      8.98e+01      3.0517578125e-05\n",
      "9    1.26e+02   9.98e-01      8.89e+01      1.52587890625e-05\n",
      "10    1.65e+03   9.80e-01      8.05e+01      0.001953125\n",
      "11    1.26e+02   9.80e-01      6.05e+01      1.52587890625e-05\n",
      "12    2.49e+02   9.79e-01      6.02e+01      6.103515625e-05\n",
      "13    1.04e+02   9.79e-01      5.97e+01      1.52587890625e-05\n",
      "14    1.30e+03   9.66e-01      5.30e+01      0.001953125\n",
      "15    1.02e+02   9.66e-01      4.06e+01      1.52587890625e-05\n",
      "16    1.97e+02   9.66e-01      4.03e+01      6.103515625e-05\n",
      "17    8.51e+01   9.66e-01      4.00e+01      1.52587890625e-05\n",
      "18    1.02e+03   9.57e-01      3.48e+01      0.001953125\n",
      "19    8.28e+01   9.57e-01      2.71e+01      1.52587890625e-05\n",
      "20    1.57e+02   9.57e-01      2.70e+01      6.103515625e-05\n",
      "21    1.67e+02   9.57e-01      2.68e+01      3.0517578125e-05\n",
      "22    6.96e+01   9.57e-01      2.66e+01      1.52587890625e-05\n",
      "23    8.76e+02   9.51e-01      2.36e+01      0.001953125\n",
      "24    6.86e+01   9.51e-01      1.80e+01      1.52587890625e-05\n",
      "25    1.33e+02   9.50e-01      1.79e+01      6.103515625e-05\n",
      "26    5.71e+01   9.50e-01      1.77e+01      1.52587890625e-05\n",
      "27    6.90e+02   9.46e-01      1.54e+01      0.001953125\n",
      "28    5.56e+01   9.46e-01      1.19e+01      1.52587890625e-05\n",
      "29    1.05e+02   9.46e-01      1.18e+01      6.103515625e-05\n",
      "30    1.13e+02   9.46e-01      1.18e+01      3.0517578125e-05\n",
      "Error of x with respect to x_ast: 9.46e-01\n",
      "Approximate solution:[1] 0.004279252 0.205278374 0.066525382 0.899007102\n"
     ]
    }
   ],
   "source": [
    "l<-gradient_descent(fo, beta_0, tol, tol_backtracking, beta_ast, p_ast, maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta <- l[[1]]\n",
    "total_of_iterations <- l[[2]]\n",
    "Err_plot <- l[[3]]\n",
    "beta_plot <- l[[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.004279252 0.205278374 0.066525382 0.899007102\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               s0\n",
      "disp -0.002266897\n",
      "drat  2.574343046\n",
      "wt   -3.235364158\n",
      "qsec  1.216575201\n"
     ]
    }
   ],
   "source": [
    "print(beta_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.6328348494032"
      ],
      "text/latex": [
       "19.6328348494032"
      ],
      "text/markdown": [
       "19.6328348494032"
      ],
      "text/plain": [
       "[1] 19.63283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fo(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 4 × 29 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>0.0613713594</td><td>0.055812283</td><td>0.061356524</td><td>0.054837957</td><td>0.061427394</td><td>0.053775854</td><td>0.061598968</td><td>0.057104308</td><td>0.06638388</td><td>0.04118335</td><td>⋯</td><td>0.01624017</td><td>0.01849698</td><td>-0.002597636</td><td>0.01066072</td><td>0.008144258</td><td>0.009918957</td><td>-0.006960285</td><td>0.003476457</td><td>0.001488231</td><td>0.004279252</td></tr>\n",
       "\t<tr><td>0.0011350045</td><td>0.001924608</td><td>0.002840018</td><td>0.003614141</td><td>0.004537196</td><td>0.005293861</td><td>0.006226759</td><td>0.006595194</td><td>0.06042558</td><td>0.06048518</td><td>⋯</td><td>0.14673379</td><td>0.14699905</td><td> 0.177339900</td><td>0.17769337</td><td>0.178465769</td><td>0.178685594</td><td> 0.203978047</td><td>0.204266036</td><td>0.204912916</td><td>0.205278374</td></tr>\n",
       "\t<tr><td>0.0009106411</td><td>0.001135933</td><td>0.001498435</td><td>0.001710055</td><td>0.002083819</td><td>0.002279618</td><td>0.002666998</td><td>0.002755719</td><td>0.02135455</td><td>0.02115816</td><td>⋯</td><td>0.04920217</td><td>0.04930356</td><td> 0.058412031</td><td>0.05863503</td><td>0.058835839</td><td>0.058915545</td><td> 0.066070591</td><td>0.066245544</td><td>0.066401148</td><td>0.066525382</td></tr>\n",
       "\t<tr><td>0.0055383420</td><td>0.009018228</td><td>0.013144805</td><td>0.016547358</td><td>0.020715276</td><td>0.024030342</td><td>0.028250864</td><td>0.029858649</td><td>0.26992173</td><td>0.26997815</td><td>⋯</td><td>0.64874391</td><td>0.64990882</td><td> 0.780498877</td><td>0.78213502</td><td>0.785388061</td><td>0.786338952</td><td> 0.893466552</td><td>0.894782487</td><td>0.897454623</td><td>0.899007102</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 4 × 29 of type dbl\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       "\t 0.0613713594 & 0.055812283 & 0.061356524 & 0.054837957 & 0.061427394 & 0.053775854 & 0.061598968 & 0.057104308 & 0.06638388 & 0.04118335 & ⋯ & 0.01624017 & 0.01849698 & -0.002597636 & 0.01066072 & 0.008144258 & 0.009918957 & -0.006960285 & 0.003476457 & 0.001488231 & 0.004279252\\\\\n",
       "\t 0.0011350045 & 0.001924608 & 0.002840018 & 0.003614141 & 0.004537196 & 0.005293861 & 0.006226759 & 0.006595194 & 0.06042558 & 0.06048518 & ⋯ & 0.14673379 & 0.14699905 &  0.177339900 & 0.17769337 & 0.178465769 & 0.178685594 &  0.203978047 & 0.204266036 & 0.204912916 & 0.205278374\\\\\n",
       "\t 0.0009106411 & 0.001135933 & 0.001498435 & 0.001710055 & 0.002083819 & 0.002279618 & 0.002666998 & 0.002755719 & 0.02135455 & 0.02115816 & ⋯ & 0.04920217 & 0.04930356 &  0.058412031 & 0.05863503 & 0.058835839 & 0.058915545 &  0.066070591 & 0.066245544 & 0.066401148 & 0.066525382\\\\\n",
       "\t 0.0055383420 & 0.009018228 & 0.013144805 & 0.016547358 & 0.020715276 & 0.024030342 & 0.028250864 & 0.029858649 & 0.26992173 & 0.26997815 & ⋯ & 0.64874391 & 0.64990882 &  0.780498877 & 0.78213502 & 0.785388061 & 0.786338952 &  0.893466552 & 0.894782487 & 0.897454623 & 0.899007102\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 4 × 29 of type dbl\n",
       "\n",
       "| 0.0613713594 | 0.055812283 | 0.061356524 | 0.054837957 | 0.061427394 | 0.053775854 | 0.061598968 | 0.057104308 | 0.06638388 | 0.04118335 | ⋯ | 0.01624017 | 0.01849698 | -0.002597636 | 0.01066072 | 0.008144258 | 0.009918957 | -0.006960285 | 0.003476457 | 0.001488231 | 0.004279252 |\n",
       "| 0.0011350045 | 0.001924608 | 0.002840018 | 0.003614141 | 0.004537196 | 0.005293861 | 0.006226759 | 0.006595194 | 0.06042558 | 0.06048518 | ⋯ | 0.14673379 | 0.14699905 |  0.177339900 | 0.17769337 | 0.178465769 | 0.178685594 |  0.203978047 | 0.204266036 | 0.204912916 | 0.205278374 |\n",
       "| 0.0009106411 | 0.001135933 | 0.001498435 | 0.001710055 | 0.002083819 | 0.002279618 | 0.002666998 | 0.002755719 | 0.02135455 | 0.02115816 | ⋯ | 0.04920217 | 0.04930356 |  0.058412031 | 0.05863503 | 0.058835839 | 0.058915545 |  0.066070591 | 0.066245544 | 0.066401148 | 0.066525382 |\n",
       "| 0.0055383420 | 0.009018228 | 0.013144805 | 0.016547358 | 0.020715276 | 0.024030342 | 0.028250864 | 0.029858649 | 0.26992173 | 0.26997815 | ⋯ | 0.64874391 | 0.64990882 |  0.780498877 | 0.78213502 | 0.785388061 | 0.786338952 |  0.893466552 | 0.894782487 | 0.897454623 | 0.899007102 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]         [,2]        [,3]        [,4]        [,5]        [,6]       \n",
       "[1,] 0.0613713594 0.055812283 0.061356524 0.054837957 0.061427394 0.053775854\n",
       "[2,] 0.0011350045 0.001924608 0.002840018 0.003614141 0.004537196 0.005293861\n",
       "[3,] 0.0009106411 0.001135933 0.001498435 0.001710055 0.002083819 0.002279618\n",
       "[4,] 0.0055383420 0.009018228 0.013144805 0.016547358 0.020715276 0.024030342\n",
       "     [,7]        [,8]        [,9]       [,10]      [,11] [,12]      [,13]     \n",
       "[1,] 0.061598968 0.057104308 0.06638388 0.04118335 ⋯     0.01624017 0.01849698\n",
       "[2,] 0.006226759 0.006595194 0.06042558 0.06048518 ⋯     0.14673379 0.14699905\n",
       "[3,] 0.002666998 0.002755719 0.02135455 0.02115816 ⋯     0.04920217 0.04930356\n",
       "[4,] 0.028250864 0.029858649 0.26992173 0.26997815 ⋯     0.64874391 0.64990882\n",
       "     [,14]        [,15]      [,16]       [,17]       [,18]        [,19]      \n",
       "[1,] -0.002597636 0.01066072 0.008144258 0.009918957 -0.006960285 0.003476457\n",
       "[2,]  0.177339900 0.17769337 0.178465769 0.178685594  0.203978047 0.204266036\n",
       "[3,]  0.058412031 0.05863503 0.058835839 0.058915545  0.066070591 0.066245544\n",
       "[4,]  0.780498877 0.78213502 0.785388061 0.786338952  0.893466552 0.894782487\n",
       "     [,20]       [,21]      \n",
       "[1,] 0.001488231 0.004279252\n",
       "[2,] 0.204912916 0.205278374\n",
       "[3,] 0.066401148 0.066525382\n",
       "[4,] 0.897454623 0.899007102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for glmnet {glmnet}\"><tr><td>glmnet {glmnet}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>fit a GLM with lasso or elasticnet regularization</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Fit a generalized linear model via penalized maximum likelihood.  The\n",
       "regularization path is computed for the lasso or elasticnet penalty at a\n",
       "grid of values for the regularization parameter lambda. Can deal with all\n",
       "shapes of data, including very large sparse data matrices. Fits linear,\n",
       "logistic and multinomial, poisson, and Cox regression models.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "glmnet(x, y, family = c(\"gaussian\", \"binomial\", \"poisson\", \"multinomial\",\n",
       "  \"cox\", \"mgaussian\"), weights, offset = NULL, alpha = 1,\n",
       "  nlambda = 100, lambda.min.ratio = ifelse(nobs &lt; nvars, 0.01, 1e-04),\n",
       "  lambda = NULL, standardize = TRUE, intercept = TRUE,\n",
       "  thresh = 1e-07, dfmax = nvars + 1, pmax = min(dfmax * 2 + 20,\n",
       "  nvars), exclude, penalty.factor = rep(1, nvars), lower.limits = -Inf,\n",
       "  upper.limits = Inf, maxit = 1e+05, type.gaussian = ifelse(nvars &lt;\n",
       "  500, \"covariance\", \"naive\"), type.logistic = c(\"Newton\",\n",
       "  \"modified.Newton\"), standardize.response = FALSE,\n",
       "  type.multinomial = c(\"ungrouped\", \"grouped\"), relax = FALSE,\n",
       "  trace.it = 0, ...)\n",
       "\n",
       "relax.glmnet(fit, x, ..., maxp = n - 3, path = FALSE,\n",
       "  check.args = TRUE)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>x</code></td>\n",
       "<td>\n",
       "<p>input matrix, of dimension nobs x nvars; each row is an observation\n",
       "vector. Can be in sparse matrix format (inherit from class\n",
       "<code>\"sparseMatrix\"</code> as in package <code>Matrix</code>; not yet available for\n",
       "<code>family=\"cox\"</code>)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>y</code></td>\n",
       "<td>\n",
       "<p>response variable. Quantitative for <code>family=\"gaussian\"</code>, or\n",
       "<code>family=\"poisson\"</code> (non-negative counts). For <code>family=\"binomial\"</code>\n",
       "should be either a factor with two levels, or a two-column matrix of counts\n",
       "or proportions (the second column is treated as the target class; for a\n",
       "factor, the last level in alphabetical order is the target class). For\n",
       "<code>family=\"multinomial\"</code>, can be a <code>nc&gt;=2</code> level factor, or a matrix\n",
       "with <code>nc</code> columns of counts or proportions.  For either\n",
       "<code>\"binomial\"</code> or <code>\"multinomial\"</code>, if <code>y</code> is presented as a\n",
       "vector, it will be coerced into a factor. For <code>family=\"cox\"</code>, <code>y</code>\n",
       "should be a two-column matrix with columns named 'time' and 'status'. The\n",
       "latter is a binary variable, with '1' indicating death, and '0' indicating\n",
       "right censored. The function <code>Surv()</code> in package <span class=\"pkg\">survival</span>\n",
       "produces such a matrix. For <code>family=\"mgaussian\"</code>, <code>y</code> is a matrix\n",
       "of quantitative responses.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>family</code></td>\n",
       "<td>\n",
       "<p>Response type (see above)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>weights</code></td>\n",
       "<td>\n",
       "<p>observation weights. Can be total counts if responses are\n",
       "proportion matrices. Default is 1 for each observation</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>offset</code></td>\n",
       "<td>\n",
       "<p>A vector of length <code>nobs</code> that is included in the linear\n",
       "predictor (a <code>nobs x nc</code> matrix for the <code>\"multinomial\"</code> family).\n",
       "Useful for the <code>\"poisson\"</code> family (e.g. log of exposure time), or for\n",
       "refining a model by starting at a current fit. Default is <code>NULL</code>. If\n",
       "supplied, then values must also be supplied to the <code>predict</code> function.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>alpha</code></td>\n",
       "<td>\n",
       "<p>The elasticnet mixing parameter, with <i>0&le;&alpha;&le; 1</i>.\n",
       "The penalty is defined as\n",
       "</p>\n",
       "<p style=\"text-align: center;\"><i>(1-&alpha;)/2||&beta;||_2^2+&alpha;||&beta;||_1.</i></p>\n",
       " <p><code>alpha=1</code> is the\n",
       "lasso penalty, and <code>alpha=0</code> the ridge penalty.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>nlambda</code></td>\n",
       "<td>\n",
       "<p>The number of <code>lambda</code> values - default is 100.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>lambda.min.ratio</code></td>\n",
       "<td>\n",
       "<p>Smallest value for <code>lambda</code>, as a fraction of\n",
       "<code>lambda.max</code>, the (data derived) entry value (i.e. the smallest value\n",
       "for which all coefficients are zero). The default depends on the sample size\n",
       "<code>nobs</code> relative to the number of variables <code>nvars</code>. If <code>nobs\n",
       "&gt; nvars</code>, the default is <code>0.0001</code>, close to zero.  If <code>nobs &lt;\n",
       "nvars</code>, the default is <code>0.01</code>.  A very small value of\n",
       "<code>lambda.min.ratio</code> will lead to a saturated fit in the <code>nobs &lt;\n",
       "nvars</code> case. This is undefined for <code>\"binomial\"</code> and\n",
       "<code>\"multinomial\"</code> models, and <code>glmnet</code> will exit gracefully when the\n",
       "percentage deviance explained is almost 1.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>lambda</code></td>\n",
       "<td>\n",
       "<p>A user supplied <code>lambda</code> sequence. Typical usage is to\n",
       "have the program compute its own <code>lambda</code> sequence based on\n",
       "<code>nlambda</code> and <code>lambda.min.ratio</code>. Supplying a value of\n",
       "<code>lambda</code> overrides this. WARNING: use with care. Avoid supplying a\n",
       "single value for <code>lambda</code> (for predictions after CV use\n",
       "<code>predict()</code> instead).  Supply instead a decreasing sequence of\n",
       "<code>lambda</code> values. <code>glmnet</code> relies on its warms starts for speed,\n",
       "and its often faster to fit a whole path than compute a single fit.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>standardize</code></td>\n",
       "<td>\n",
       "<p>Logical flag for x variable standardization, prior to\n",
       "fitting the model sequence. The coefficients are always returned on the\n",
       "original scale. Default is <code>standardize=TRUE</code>.  If variables are in the\n",
       "same units already, you might not wish to standardize. See details below for\n",
       "y standardization with <code>family=\"gaussian\"</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>intercept</code></td>\n",
       "<td>\n",
       "<p>Should intercept(s) be fitted (default=TRUE) or set to zero\n",
       "(FALSE)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>thresh</code></td>\n",
       "<td>\n",
       "<p>Convergence threshold for coordinate descent. Each inner\n",
       "coordinate-descent loop continues until the maximum change in the objective\n",
       "after any coefficient update is less than <code>thresh</code> times the null\n",
       "deviance. Defaults value is <code>1E-7</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>dfmax</code></td>\n",
       "<td>\n",
       "<p>Limit the maximum number of variables in the model. Useful for\n",
       "very large <code>nvars</code>, if a partial path is desired.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>pmax</code></td>\n",
       "<td>\n",
       "<p>Limit the maximum number of variables ever to be nonzero</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>exclude</code></td>\n",
       "<td>\n",
       "<p>Indices of variables to be excluded from the model. Default\n",
       "is none. Equivalent to an infinite penalty factor (next item).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>penalty.factor</code></td>\n",
       "<td>\n",
       "<p>Separate penalty factors can be applied to each\n",
       "coefficient. This is a number that multiplies <code>lambda</code> to allow\n",
       "differential shrinkage. Can be 0 for some variables, which implies no\n",
       "shrinkage, and that variable is always included in the model. Default is 1\n",
       "for all variables (and implicitly infinity for variables listed in\n",
       "<code>exclude</code>). Note: the penalty factors are internally rescaled to sum to\n",
       "nvars, and the lambda sequence will reflect this change.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>lower.limits</code></td>\n",
       "<td>\n",
       "<p>Vector of lower limits for each coefficient; default\n",
       "<code>-Inf</code>. Each of these must be non-positive. Can be presented as a\n",
       "single value (which will then be replicated), else a vector of length\n",
       "<code>nvars</code></p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>upper.limits</code></td>\n",
       "<td>\n",
       "<p>Vector of upper limits for each coefficient; default\n",
       "<code>Inf</code>. See <code>lower.limits</code></p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>maxit</code></td>\n",
       "<td>\n",
       "<p>Maximum number of passes over the data for all lambda values;\n",
       "default is 10^5.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>type.gaussian</code></td>\n",
       "<td>\n",
       "<p>Two algorithm types are supported for (only)\n",
       "<code>family=\"gaussian\"</code>. The default when <code>nvar&lt;500</code> is\n",
       "<code>type.gaussian=\"covariance\"</code>, and saves all inner-products ever\n",
       "computed. This can be much faster than <code>type.gaussian=\"naive\"</code>, which\n",
       "loops through <code>nobs</code> every time an inner-product is computed. The\n",
       "latter can be far more efficient for <code>nvar &gt;&gt; nobs</code> situations, or when\n",
       "<code>nvar &gt; 500</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>type.logistic</code></td>\n",
       "<td>\n",
       "<p>If <code>\"Newton\"</code> then the exact hessian is used\n",
       "(default), while <code>\"modified.Newton\"</code> uses an upper-bound on the\n",
       "hessian, and can be faster.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>standardize.response</code></td>\n",
       "<td>\n",
       "<p>This is for the <code>family=\"mgaussian\"</code>\n",
       "family, and allows the user to standardize the response variables</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>type.multinomial</code></td>\n",
       "<td>\n",
       "<p>If <code>\"grouped\"</code> then a grouped lasso penalty is\n",
       "used on the multinomial coefficients for a variable. This ensures they are\n",
       "all in our out together. The default is <code>\"ungrouped\"</code></p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>relax</code></td>\n",
       "<td>\n",
       "<p>If <code>TRUE</code> then for each <em>active set</em> in the path of\n",
       "solutions, the model is refit without any regularization. See <code>details</code>\n",
       "for more information. This argument is new, and users may experience convergence issues\n",
       "with small datasets, especially with non-gaussian families. Limiting the\n",
       "value of 'maxp' can alleviate these issues in some cases.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>trace.it</code></td>\n",
       "<td>\n",
       "<p>If <code>trace.it=1</code>, then a progress bar is displayed;\n",
       "useful for big models that take a long time to fit.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>Additional argument used in <code>relax.glmnet</code>. These include\n",
       "some of the original arguments to 'glmnet', and each must be named if used.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>fit</code></td>\n",
       "<td>\n",
       "<p>For <code>relax.glmnet</code> a fitted 'glmnet' object</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>maxp</code></td>\n",
       "<td>\n",
       "<p>a limit on how many relaxed coefficients are allowed. Default is\n",
       "'n-3', where 'n' is the sample size. This may not be sufficient for\n",
       "non-gaussian familes, in which case users should supply a smaller value.\n",
       "This argument can be supplied directly to 'glmnet'.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>path</code></td>\n",
       "<td>\n",
       "<p>Since <code>glmnet</code> does not do stepsize optimization, the Newton\n",
       "algorithm can get stuck and not converge, especially with relaxed fits. With <code>path=TRUE</code>,\n",
       "each relaxed fit on a particular set of variables is computed pathwise using the original sequence\n",
       "of lambda values (with a zero attached to the end). Not needed for Gaussian models, and should not\n",
       "be used unless needed, since will lead to longer compute times. Default is <code>path=FALSE</code>.\n",
       "appropriate subset of variables</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>check.args</code></td>\n",
       "<td>\n",
       "<p>Should <code>relax.glmnet</code> make sure that all the data\n",
       "dependent arguments used in creating 'fit' have been resupplied. Default is\n",
       "'TRUE'.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>The sequence of models implied by <code>lambda</code> is fit by coordinate\n",
       "descent. For <code>family=\"gaussian\"</code> this is the lasso sequence if\n",
       "<code>alpha=1</code>, else it is the elasticnet sequence.  For the other families,\n",
       "this is a lasso or elasticnet regularization path for fitting the\n",
       "generalized linear regression paths, by maximizing the appropriate penalized\n",
       "log-likelihood (partial likelihood for the &quot;cox&quot; model). Sometimes the\n",
       "sequence is truncated before <code>nlambda</code> values of <code>lambda</code> have\n",
       "been used, because of instabilities in the inverse link functions near a\n",
       "saturated fit. <code>glmnet(...,family=\"binomial\")</code> fits a traditional\n",
       "logistic regression model for the log-odds.\n",
       "<code>glmnet(...,family=\"multinomial\")</code> fits a symmetric multinomial model,\n",
       "where each class is represented by a linear model (on the log-scale). The\n",
       "penalties take care of redundancies. A two-class <code>\"multinomial\"</code> model\n",
       "will produce the same fit as the corresponding <code>\"binomial\"</code> model,\n",
       "except the pair of coefficient matrices will be equal in magnitude and\n",
       "opposite in sign, and half the <code>\"binomial\"</code> values.  Note that the\n",
       "objective function for <code>\"gaussian\"</code> is </p>\n",
       "<p style=\"text-align: center;\"><i>1/2 RSS/nobs +\n",
       "&lambda;*penalty,</i></p>\n",
       "<p> and for the other models it is </p>\n",
       "<p style=\"text-align: center;\"><i>-loglik/nobs +\n",
       "&lambda;*penalty.</i></p>\n",
       "<p> Note also that for <code>\"gaussian\"</code>, <code>glmnet</code>\n",
       "standardizes y to have unit variance (using 1/n rather than 1/(n-1) formula)\n",
       "before computing its lambda sequence (and then unstandardizes the resulting\n",
       "coefficients); if you wish to reproduce/compare results with other software,\n",
       "best to supply a standardized y. The coefficients for any predictor\n",
       "variables with zero variance are set to zero for all values of lambda.  The\n",
       "latest two features in glmnet are the <code>family=\"mgaussian\"</code> family and\n",
       "the <code>type.multinomial=\"grouped\"</code> option for multinomial fitting. The\n",
       "former allows a multi-response gaussian model to be fit, using a &quot;group\n",
       "-lasso&quot; penalty on the coefficients for each variable. Tying the responses\n",
       "together like this is called &quot;multi-task&quot; learning in some domains. The\n",
       "grouped multinomial allows the same penalty for the\n",
       "<code>family=\"multinomial\"</code> model, which is also multi-responsed. For both\n",
       "of these the penalty on the coefficient vector for variable j is\n",
       "</p>\n",
       "<p style=\"text-align: center;\"><i>(1-&alpha;)/2||&beta;_j||_2^2+&alpha;||&beta;_j||_2.</i></p>\n",
       "<p> When <code>alpha=1</code>\n",
       "this is a group-lasso penalty, and otherwise it mixes with quadratic just\n",
       "like elasticnet. A small detail in the Cox model: if death times are tied\n",
       "with censored times, we assume the censored times occurred just\n",
       "<em>before</em> the death times in computing the Breslow approximation; if\n",
       "users prefer the usual convention of <em>after</em>, they can add a small\n",
       "number to all censoring times to achieve this effect.  If <code>relax=TRUE</code>\n",
       "a duplicate sequence of models is produced, where each active set in the\n",
       "elastic-net path is refit without regularization. The result of this is a\n",
       "matching <code>\"glmnet\"</code> object which is stored on the original object in a\n",
       "component named <code>\"relaxed\"</code>, and is part of the glmnet output.\n",
       "Generally users will not call <code>relax.glmnet</code> directly, unless the\n",
       "original 'glmnet' object took a long time to fit. But if they do, they must\n",
       "supply the fit, and all the original arguments used to create that fit. They\n",
       "can limit the length of the relaxed path via 'maxp'.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>An object with S3 class <code>\"glmnet\",\"*\" </code>, where <code>\"*\"</code> is\n",
       "<code>\"elnet\"</code>, <code>\"lognet\"</code>, <code>\"multnet\"</code>, <code>\"fishnet\"</code>\n",
       "(poisson), <code>\"coxnet\"</code> or <code>\"mrelnet\"</code> for the various types of\n",
       "models. If the model was created with <code>relax=TRUE</code> then this class has\n",
       "a prefix class of <code>\"relaxed\"</code>.  </p>\n",
       "<table summary=\"R valueblock\">\n",
       "<tr valign=\"top\"><td><code>call</code></td>\n",
       "<td>\n",
       "<p>the call that produced this\n",
       "object</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>a0</code></td>\n",
       "<td>\n",
       "<p>Intercept sequence of length <code>length(lambda)</code></p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>beta</code></td>\n",
       "<td>\n",
       "<p>For <code>\"elnet\"</code>, <code>\"lognet\"</code>, <code>\"fishnet\"</code> and\n",
       "<code>\"coxnet\"</code> models, a <code>nvars x length(lambda)</code> matrix of\n",
       "coefficients, stored in sparse column format (<code>\"CsparseMatrix\"</code>). For\n",
       "<code>\"multnet\"</code> and <code>\"mgaussian\"</code>, a list of <code>nc</code> such matrices,\n",
       "one for each class.</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>lambda</code></td>\n",
       "<td>\n",
       "<p>The actual sequence of <code>lambda</code>\n",
       "values used. When <code>alpha=0</code>, the largest lambda reported does not quite\n",
       "give the zero coefficients reported (<code>lambda=inf</code> would in principle).\n",
       "Instead, the largest <code>lambda</code> for <code>alpha=0.001</code> is used, and the\n",
       "sequence of <code>lambda</code> values is derived from this.</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>dev.ratio</code></td>\n",
       "<td>\n",
       "<p>The\n",
       "fraction of (null) deviance explained (for <code>\"elnet\"</code>, this is the\n",
       "R-square). The deviance calculations incorporate weights if present in the\n",
       "model. The deviance is defined to be 2*(loglike_sat - loglike), where\n",
       "loglike_sat is the log-likelihood for the saturated model (a model with a\n",
       "free parameter per observation). Hence dev.ratio=1-dev/nulldev.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>nulldev</code></td>\n",
       "<td>\n",
       "<p>Null deviance (per observation). This is defined to be\n",
       "2*(loglike_sat -loglike(Null)); The NULL model refers to the intercept\n",
       "model, except for the Cox, where it is the 0 model.</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>df</code></td>\n",
       "<td>\n",
       "<p>The number of\n",
       "nonzero coefficients for each value of <code>lambda</code>. For <code>\"multnet\"</code>,\n",
       "this is the number of variables with a nonzero coefficient for <em>any</em>\n",
       "class.</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>dfmat</code></td>\n",
       "<td>\n",
       "<p>For <code>\"multnet\"</code> and <code>\"mrelnet\"</code> only. A\n",
       "matrix consisting of the number of nonzero coefficients per class</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>dim</code></td>\n",
       "<td>\n",
       "<p>dimension of coefficient matrix (ices)</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>nobs</code></td>\n",
       "<td>\n",
       "<p>number of\n",
       "observations</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>npasses</code></td>\n",
       "<td>\n",
       "<p>total passes over the data summed over all\n",
       "lambda values</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>offset</code></td>\n",
       "<td>\n",
       "<p>a logical variable indicating whether an offset\n",
       "was included in the model</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>jerr</code></td>\n",
       "<td>\n",
       "<p>error flag, for warnings and errors\n",
       "(largely for internal debugging).</p>\n",
       "</td></tr> <tr valign=\"top\"><td><code>relaxed</code></td>\n",
       "<td>\n",
       "<p>If <code>relax=TRUE</code>, this\n",
       "additional item is another glmnet object with different values for\n",
       "<code>beta</code> and <code>dev.ratio</code></p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>Jerome Friedman, Trevor Hastie, Balasubramanian Narasimhan, Noah\n",
       "Simon and Rob Tibshirani<br /> Maintainer: Trevor Hastie\n",
       "<a href=\"mailto:hastie@stanford.edu\">hastie@stanford.edu</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Friedman, J., Hastie, T. and Tibshirani, R. (2008)\n",
       "<em>Regularization Paths for Generalized Linear Models via Coordinate\n",
       "Descent</em>, <a href=\"https://web.stanford.edu/~hastie/Papers/glmnet.pdf\">https://web.stanford.edu/~hastie/Papers/glmnet.pdf</a><br />\n",
       "<em>Journal of Statistical Software, Vol. 33(1), 1-22 Feb 2010</em><br />\n",
       "<a href=\"https://www.jstatsoft.org/v33/i01/\">https://www.jstatsoft.org/v33/i01/</a><br /> Simon, N., Friedman, J., Hastie,\n",
       "T., Tibshirani, R. (2011) <em>Regularization Paths for Cox's Proportional\n",
       "Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.\n",
       "39(5) 1-13</em><br /> <a href=\"https://www.jstatsoft.org/v39/i05/\">https://www.jstatsoft.org/v39/i05/</a><br /> Tibshirani,\n",
       "Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N.,Taylor, J. and\n",
       "Tibshirani, Ryan. (2012) <em>Strong Rules for Discarding Predictors in\n",
       "Lasso-type Problems, JRSSB vol 74</em>,<br />\n",
       "<a href=\"https://statweb.stanford.edu/~tibs/ftp/strong.pdf\">https://statweb.stanford.edu/~tibs/ftp/strong.pdf</a><br /> <em>Stanford\n",
       "Statistics Technical Report</em><br /> <a href=\"https://arxiv.org/abs/1707.08692\">https://arxiv.org/abs/1707.08692</a><br />\n",
       "Hastie, T., Tibshirani, Robert, Tibshirani, Ryan (2019) <em>Extended\n",
       "Comparisons of Best Subset Selection, Forward Stepwise Selection, and the\n",
       "Lasso</em><br /> <em>Glmnet Vignette</em>\n",
       "<a href=\"https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html\">https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>print</code>, <code>predict</code>, <code>coef</code> and <code>plot</code> methods,\n",
       "and the <code>cv.glmnet</code> function.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "\n",
       "# Gaussian\n",
       "x = matrix(rnorm(100 * 20), 100, 20)\n",
       "y = rnorm(100)\n",
       "fit1 = glmnet(x, y)\n",
       "print(fit1)\n",
       "coef(fit1, s = 0.01)  # extract coefficients at a single value of lambda\n",
       "predict(fit1, newx = x[1:10, ], s = c(0.01, 0.005))  # make predictions\n",
       "\n",
       "# Relaxed\n",
       "fit1r = glmnet(x, y, relax = TRUE)  # can be used with any model\n",
       "\n",
       "# multivariate gaussian\n",
       "y = matrix(rnorm(100 * 3), 100, 3)\n",
       "fit1m = glmnet(x, y, family = \"mgaussian\")\n",
       "plot(fit1m, type.coef = \"2norm\")\n",
       "\n",
       "# binomial\n",
       "g2 = sample(1:2, 100, replace = TRUE)\n",
       "fit2 = glmnet(x, g2, family = \"binomial\")\n",
       "fit2r = glmnet(x,g2, family = \"binomial\", relax=TRUE)\n",
       "fit2rp = glmnet(x,g2, family = \"binomial\", relax=TRUE, path=TRUE)\n",
       "\n",
       "# multinomial\n",
       "g4 = sample(1:4, 100, replace = TRUE)\n",
       "fit3 = glmnet(x, g4, family = \"multinomial\")\n",
       "fit3a = glmnet(x, g4, family = \"multinomial\", type.multinomial = \"grouped\")\n",
       "# poisson\n",
       "N = 500\n",
       "p = 20\n",
       "nzc = 5\n",
       "x = matrix(rnorm(N * p), N, p)\n",
       "beta = rnorm(nzc)\n",
       "f = x[, seq(nzc)] %*% beta\n",
       "mu = exp(f)\n",
       "y = rpois(N, mu)\n",
       "fit = glmnet(x, y, family = \"poisson\")\n",
       "plot(fit)\n",
       "pfit = predict(fit, x, s = 0.001, type = \"response\")\n",
       "plot(pfit, y)\n",
       "\n",
       "# Cox\n",
       "set.seed(10101)\n",
       "N = 1000\n",
       "p = 30\n",
       "nzc = p/3\n",
       "x = matrix(rnorm(N * p), N, p)\n",
       "beta = rnorm(nzc)\n",
       "fx = x[, seq(nzc)] %*% beta/3\n",
       "hx = exp(fx)\n",
       "ty = rexp(N, hx)\n",
       "tcens = rbinom(n = N, prob = 0.3, size = 1)  # censoring indicator\n",
       "y = cbind(time = ty, status = 1 - tcens)  # y=Surv(ty,1-tcens) with library(survival)\n",
       "fit = glmnet(x, y, family = \"cox\")\n",
       "plot(fit)\n",
       "\n",
       "# Sparse\n",
       "n = 10000\n",
       "p = 200\n",
       "nzc = trunc(p/10)\n",
       "x = matrix(rnorm(n * p), n, p)\n",
       "iz = sample(1:(n * p), size = n * p * 0.85, replace = FALSE)\n",
       "x[iz] = 0\n",
       "sx = Matrix(x, sparse = TRUE)\n",
       "inherits(sx, \"sparseMatrix\")  #confirm that it is sparse\n",
       "beta = rnorm(nzc)\n",
       "fx = x[, seq(nzc)] %*% beta\n",
       "eps = rnorm(n)\n",
       "y = fx + eps\n",
       "px = exp(fx)\n",
       "px = px/(1 + px)\n",
       "ly = rbinom(n = length(px), prob = px, size = 1)\n",
       "system.time(fit1 &lt;- glmnet(sx, y))\n",
       "system.time(fit2n &lt;- glmnet(x, y))\n",
       "\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>glmnet</em> version 3.0-2 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{glmnet}{fit a GLM with lasso or elasticnet regularization}{glmnet}\n",
       "\\aliasA{relax.glmnet}{glmnet}{relax.glmnet}\n",
       "\\keyword{models}{glmnet}\n",
       "\\keyword{regression}{glmnet}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Fit a generalized linear model via penalized maximum likelihood.  The\n",
       "regularization path is computed for the lasso or elasticnet penalty at a\n",
       "grid of values for the regularization parameter lambda. Can deal with all\n",
       "shapes of data, including very large sparse data matrices. Fits linear,\n",
       "logistic and multinomial, poisson, and Cox regression models.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "glmnet(x, y, family = c(\"gaussian\", \"binomial\", \"poisson\", \"multinomial\",\n",
       "  \"cox\", \"mgaussian\"), weights, offset = NULL, alpha = 1,\n",
       "  nlambda = 100, lambda.min.ratio = ifelse(nobs < nvars, 0.01, 1e-04),\n",
       "  lambda = NULL, standardize = TRUE, intercept = TRUE,\n",
       "  thresh = 1e-07, dfmax = nvars + 1, pmax = min(dfmax * 2 + 20,\n",
       "  nvars), exclude, penalty.factor = rep(1, nvars), lower.limits = -Inf,\n",
       "  upper.limits = Inf, maxit = 1e+05, type.gaussian = ifelse(nvars <\n",
       "  500, \"covariance\", \"naive\"), type.logistic = c(\"Newton\",\n",
       "  \"modified.Newton\"), standardize.response = FALSE,\n",
       "  type.multinomial = c(\"ungrouped\", \"grouped\"), relax = FALSE,\n",
       "  trace.it = 0, ...)\n",
       "\n",
       "relax.glmnet(fit, x, ..., maxp = n - 3, path = FALSE,\n",
       "  check.args = TRUE)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{x}] input matrix, of dimension nobs x nvars; each row is an observation\n",
       "vector. Can be in sparse matrix format (inherit from class\n",
       "\\code{\"sparseMatrix\"} as in package \\code{Matrix}; not yet available for\n",
       "\\code{family=\"cox\"})\n",
       "\n",
       "\\item[\\code{y}] response variable. Quantitative for \\code{family=\"gaussian\"}, or\n",
       "\\code{family=\"poisson\"} (non-negative counts). For \\code{family=\"binomial\"}\n",
       "should be either a factor with two levels, or a two-column matrix of counts\n",
       "or proportions (the second column is treated as the target class; for a\n",
       "factor, the last level in alphabetical order is the target class). For\n",
       "\\code{family=\"multinomial\"}, can be a \\code{nc>=2} level factor, or a matrix\n",
       "with \\code{nc} columns of counts or proportions.  For either\n",
       "\\code{\"binomial\"} or \\code{\"multinomial\"}, if \\code{y} is presented as a\n",
       "vector, it will be coerced into a factor. For \\code{family=\"cox\"}, \\code{y}\n",
       "should be a two-column matrix with columns named 'time' and 'status'. The\n",
       "latter is a binary variable, with '1' indicating death, and '0' indicating\n",
       "right censored. The function \\code{Surv()} in package \\pkg{survival}\n",
       "produces such a matrix. For \\code{family=\"mgaussian\"}, \\code{y} is a matrix\n",
       "of quantitative responses.\n",
       "\n",
       "\\item[\\code{family}] Response type (see above)\n",
       "\n",
       "\\item[\\code{weights}] observation weights. Can be total counts if responses are\n",
       "proportion matrices. Default is 1 for each observation\n",
       "\n",
       "\\item[\\code{offset}] A vector of length \\code{nobs} that is included in the linear\n",
       "predictor (a \\code{nobs x nc} matrix for the \\code{\"multinomial\"} family).\n",
       "Useful for the \\code{\"poisson\"} family (e.g. log of exposure time), or for\n",
       "refining a model by starting at a current fit. Default is \\code{NULL}. If\n",
       "supplied, then values must also be supplied to the \\code{predict} function.\n",
       "\n",
       "\\item[\\code{alpha}] The elasticnet mixing parameter, with \\eqn{0\\le\\alpha\\le 1}{}.\n",
       "The penalty is defined as\n",
       "\\deqn{(1-\\alpha)/2||\\beta||_2^2+\\alpha||\\beta||_1.}{} \\code{alpha=1} is the\n",
       "lasso penalty, and \\code{alpha=0} the ridge penalty.\n",
       "\n",
       "\\item[\\code{nlambda}] The number of \\code{lambda} values - default is 100.\n",
       "\n",
       "\\item[\\code{lambda.min.ratio}] Smallest value for \\code{lambda}, as a fraction of\n",
       "\\code{lambda.max}, the (data derived) entry value (i.e. the smallest value\n",
       "for which all coefficients are zero). The default depends on the sample size\n",
       "\\code{nobs} relative to the number of variables \\code{nvars}. If \\code{nobs\n",
       "> nvars}, the default is \\code{0.0001}, close to zero.  If \\code{nobs <\n",
       "nvars}, the default is \\code{0.01}.  A very small value of\n",
       "\\code{lambda.min.ratio} will lead to a saturated fit in the \\code{nobs <\n",
       "nvars} case. This is undefined for \\code{\"binomial\"} and\n",
       "\\code{\"multinomial\"} models, and \\code{glmnet} will exit gracefully when the\n",
       "percentage deviance explained is almost 1.\n",
       "\n",
       "\\item[\\code{lambda}] A user supplied \\code{lambda} sequence. Typical usage is to\n",
       "have the program compute its own \\code{lambda} sequence based on\n",
       "\\code{nlambda} and \\code{lambda.min.ratio}. Supplying a value of\n",
       "\\code{lambda} overrides this. WARNING: use with care. Avoid supplying a\n",
       "single value for \\code{lambda} (for predictions after CV use\n",
       "\\code{predict()} instead).  Supply instead a decreasing sequence of\n",
       "\\code{lambda} values. \\code{glmnet} relies on its warms starts for speed,\n",
       "and its often faster to fit a whole path than compute a single fit.\n",
       "\n",
       "\\item[\\code{standardize}] Logical flag for x variable standardization, prior to\n",
       "fitting the model sequence. The coefficients are always returned on the\n",
       "original scale. Default is \\code{standardize=TRUE}.  If variables are in the\n",
       "same units already, you might not wish to standardize. See details below for\n",
       "y standardization with \\code{family=\"gaussian\"}.\n",
       "\n",
       "\\item[\\code{intercept}] Should intercept(s) be fitted (default=TRUE) or set to zero\n",
       "(FALSE)\n",
       "\n",
       "\\item[\\code{thresh}] Convergence threshold for coordinate descent. Each inner\n",
       "coordinate-descent loop continues until the maximum change in the objective\n",
       "after any coefficient update is less than \\code{thresh} times the null\n",
       "deviance. Defaults value is \\code{1E-7}.\n",
       "\n",
       "\\item[\\code{dfmax}] Limit the maximum number of variables in the model. Useful for\n",
       "very large \\code{nvars}, if a partial path is desired.\n",
       "\n",
       "\\item[\\code{pmax}] Limit the maximum number of variables ever to be nonzero\n",
       "\n",
       "\\item[\\code{exclude}] Indices of variables to be excluded from the model. Default\n",
       "is none. Equivalent to an infinite penalty factor (next item).\n",
       "\n",
       "\\item[\\code{penalty.factor}] Separate penalty factors can be applied to each\n",
       "coefficient. This is a number that multiplies \\code{lambda} to allow\n",
       "differential shrinkage. Can be 0 for some variables, which implies no\n",
       "shrinkage, and that variable is always included in the model. Default is 1\n",
       "for all variables (and implicitly infinity for variables listed in\n",
       "\\code{exclude}). Note: the penalty factors are internally rescaled to sum to\n",
       "nvars, and the lambda sequence will reflect this change.\n",
       "\n",
       "\\item[\\code{lower.limits}] Vector of lower limits for each coefficient; default\n",
       "\\code{-Inf}. Each of these must be non-positive. Can be presented as a\n",
       "single value (which will then be replicated), else a vector of length\n",
       "\\code{nvars}\n",
       "\n",
       "\\item[\\code{upper.limits}] Vector of upper limits for each coefficient; default\n",
       "\\code{Inf}. See \\code{lower.limits}\n",
       "\n",
       "\\item[\\code{maxit}] Maximum number of passes over the data for all lambda values;\n",
       "default is 10\\textasciicircum{}5.\n",
       "\n",
       "\\item[\\code{type.gaussian}] Two algorithm types are supported for (only)\n",
       "\\code{family=\"gaussian\"}. The default when \\code{nvar<500} is\n",
       "\\code{type.gaussian=\"covariance\"}, and saves all inner-products ever\n",
       "computed. This can be much faster than \\code{type.gaussian=\"naive\"}, which\n",
       "loops through \\code{nobs} every time an inner-product is computed. The\n",
       "latter can be far more efficient for \\code{nvar >{}> nobs} situations, or when\n",
       "\\code{nvar > 500}.\n",
       "\n",
       "\\item[\\code{type.logistic}] If \\code{\"Newton\"} then the exact hessian is used\n",
       "(default), while \\code{\"modified.Newton\"} uses an upper-bound on the\n",
       "hessian, and can be faster.\n",
       "\n",
       "\\item[\\code{standardize.response}] This is for the \\code{family=\"mgaussian\"}\n",
       "family, and allows the user to standardize the response variables\n",
       "\n",
       "\\item[\\code{type.multinomial}] If \\code{\"grouped\"} then a grouped lasso penalty is\n",
       "used on the multinomial coefficients for a variable. This ensures they are\n",
       "all in our out together. The default is \\code{\"ungrouped\"}\n",
       "\n",
       "\\item[\\code{relax}] If \\code{TRUE} then for each \\emph{active set} in the path of\n",
       "solutions, the model is refit without any regularization. See \\code{details}\n",
       "for more information. This argument is new, and users may experience convergence issues\n",
       "with small datasets, especially with non-gaussian families. Limiting the\n",
       "value of 'maxp' can alleviate these issues in some cases.\n",
       "\n",
       "\\item[\\code{trace.it}] If \\code{trace.it=1}, then a progress bar is displayed;\n",
       "useful for big models that take a long time to fit.\n",
       "\n",
       "\\item[\\code{...}] Additional argument used in \\code{relax.glmnet}. These include\n",
       "some of the original arguments to 'glmnet', and each must be named if used.\n",
       "\n",
       "\\item[\\code{fit}] For \\code{relax.glmnet} a fitted 'glmnet' object\n",
       "\n",
       "\\item[\\code{maxp}] a limit on how many relaxed coefficients are allowed. Default is\n",
       "'n-3', where 'n' is the sample size. This may not be sufficient for\n",
       "non-gaussian familes, in which case users should supply a smaller value.\n",
       "This argument can be supplied directly to 'glmnet'.\n",
       "\n",
       "\\item[\\code{path}] Since \\code{glmnet} does not do stepsize optimization, the Newton\n",
       "algorithm can get stuck and not converge, especially with relaxed fits. With \\code{path=TRUE},\n",
       "each relaxed fit on a particular set of variables is computed pathwise using the original sequence\n",
       "of lambda values (with a zero attached to the end). Not needed for Gaussian models, and should not\n",
       "be used unless needed, since will lead to longer compute times. Default is \\code{path=FALSE}.\n",
       "appropriate subset of variables\n",
       "\n",
       "\\item[\\code{check.args}] Should \\code{relax.glmnet} make sure that all the data\n",
       "dependent arguments used in creating 'fit' have been resupplied. Default is\n",
       "'TRUE'.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "The sequence of models implied by \\code{lambda} is fit by coordinate\n",
       "descent. For \\code{family=\"gaussian\"} this is the lasso sequence if\n",
       "\\code{alpha=1}, else it is the elasticnet sequence.  For the other families,\n",
       "this is a lasso or elasticnet regularization path for fitting the\n",
       "generalized linear regression paths, by maximizing the appropriate penalized\n",
       "log-likelihood (partial likelihood for the \"cox\" model). Sometimes the\n",
       "sequence is truncated before \\code{nlambda} values of \\code{lambda} have\n",
       "been used, because of instabilities in the inverse link functions near a\n",
       "saturated fit. \\code{glmnet(...,family=\"binomial\")} fits a traditional\n",
       "logistic regression model for the log-odds.\n",
       "\\code{glmnet(...,family=\"multinomial\")} fits a symmetric multinomial model,\n",
       "where each class is represented by a linear model (on the log-scale). The\n",
       "penalties take care of redundancies. A two-class \\code{\"multinomial\"} model\n",
       "will produce the same fit as the corresponding \\code{\"binomial\"} model,\n",
       "except the pair of coefficient matrices will be equal in magnitude and\n",
       "opposite in sign, and half the \\code{\"binomial\"} values.  Note that the\n",
       "objective function for \\code{\"gaussian\"} is \\deqn{1/2 RSS/nobs +\n",
       "\\lambda*penalty,}{} and for the other models it is \\deqn{-loglik/nobs +\n",
       "\\lambda*penalty.}{} Note also that for \\code{\"gaussian\"}, \\code{glmnet}\n",
       "standardizes y to have unit variance (using 1/n rather than 1/(n-1) formula)\n",
       "before computing its lambda sequence (and then unstandardizes the resulting\n",
       "coefficients); if you wish to reproduce/compare results with other software,\n",
       "best to supply a standardized y. The coefficients for any predictor\n",
       "variables with zero variance are set to zero for all values of lambda.  The\n",
       "latest two features in glmnet are the \\code{family=\"mgaussian\"} family and\n",
       "the \\code{type.multinomial=\"grouped\"} option for multinomial fitting. The\n",
       "former allows a multi-response gaussian model to be fit, using a \"group\n",
       "-lasso\" penalty on the coefficients for each variable. Tying the responses\n",
       "together like this is called \"multi-task\" learning in some domains. The\n",
       "grouped multinomial allows the same penalty for the\n",
       "\\code{family=\"multinomial\"} model, which is also multi-responsed. For both\n",
       "of these the penalty on the coefficient vector for variable j is\n",
       "\\deqn{(1-\\alpha)/2||\\beta_j||_2^2+\\alpha||\\beta_j||_2.}{} When \\code{alpha=1}\n",
       "this is a group-lasso penalty, and otherwise it mixes with quadratic just\n",
       "like elasticnet. A small detail in the Cox model: if death times are tied\n",
       "with censored times, we assume the censored times occurred just\n",
       "\\emph{before} the death times in computing the Breslow approximation; if\n",
       "users prefer the usual convention of \\emph{after}, they can add a small\n",
       "number to all censoring times to achieve this effect.  If \\code{relax=TRUE}\n",
       "a duplicate sequence of models is produced, where each active set in the\n",
       "elastic-net path is refit without regularization. The result of this is a\n",
       "matching \\code{\"glmnet\"} object which is stored on the original object in a\n",
       "component named \\code{\"relaxed\"}, and is part of the glmnet output.\n",
       "Generally users will not call \\code{relax.glmnet} directly, unless the\n",
       "original 'glmnet' object took a long time to fit. But if they do, they must\n",
       "supply the fit, and all the original arguments used to create that fit. They\n",
       "can limit the length of the relaxed path via 'maxp'.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "An object with S3 class \\code{\"glmnet\",\"*\" }, where \\code{\"*\"} is\n",
       "\\code{\"elnet\"}, \\code{\"lognet\"}, \\code{\"multnet\"}, \\code{\"fishnet\"}\n",
       "(poisson), \\code{\"coxnet\"} or \\code{\"mrelnet\"} for the various types of\n",
       "models. If the model was created with \\code{relax=TRUE} then this class has\n",
       "a prefix class of \\code{\"relaxed\"}.  \\begin{ldescription}\n",
       "\\item[\\code{call}] the call that produced this\n",
       "object\\item[\\code{a0}] Intercept sequence of length \\code{length(lambda)}\n",
       "\\item[\\code{beta}] For \\code{\"elnet\"}, \\code{\"lognet\"}, \\code{\"fishnet\"} and\n",
       "\\code{\"coxnet\"} models, a \\code{nvars x length(lambda)} matrix of\n",
       "coefficients, stored in sparse column format (\\code{\"CsparseMatrix\"}). For\n",
       "\\code{\"multnet\"} and \\code{\"mgaussian\"}, a list of \\code{nc} such matrices,\n",
       "one for each class.\\item[\\code{lambda}] The actual sequence of \\code{lambda}\n",
       "values used. When \\code{alpha=0}, the largest lambda reported does not quite\n",
       "give the zero coefficients reported (\\code{lambda=inf} would in principle).\n",
       "Instead, the largest \\code{lambda} for \\code{alpha=0.001} is used, and the\n",
       "sequence of \\code{lambda} values is derived from this.\\item[\\code{dev.ratio}] The\n",
       "fraction of (null) deviance explained (for \\code{\"elnet\"}, this is the\n",
       "R-square). The deviance calculations incorporate weights if present in the\n",
       "model. The deviance is defined to be 2*(loglike\\_sat - loglike), where\n",
       "loglike\\_sat is the log-likelihood for the saturated model (a model with a\n",
       "free parameter per observation). Hence dev.ratio=1-dev/nulldev.\n",
       "\\item[\\code{nulldev}] Null deviance (per observation). This is defined to be\n",
       "2*(loglike\\_sat -loglike(Null)); The NULL model refers to the intercept\n",
       "model, except for the Cox, where it is the 0 model.\\item[\\code{df}] The number of\n",
       "nonzero coefficients for each value of \\code{lambda}. For \\code{\"multnet\"},\n",
       "this is the number of variables with a nonzero coefficient for \\emph{any}\n",
       "class.\\item[\\code{dfmat}] For \\code{\"multnet\"} and \\code{\"mrelnet\"} only. A\n",
       "matrix consisting of the number of nonzero coefficients per class\n",
       "\\item[\\code{dim}] dimension of coefficient matrix (ices)\\item[\\code{nobs}] number of\n",
       "observations\\item[\\code{npasses}] total passes over the data summed over all\n",
       "lambda values\\item[\\code{offset}] a logical variable indicating whether an offset\n",
       "was included in the model\\item[\\code{jerr}] error flag, for warnings and errors\n",
       "(largely for internal debugging).\\item[\\code{relaxed}] If \\code{relax=TRUE}, this\n",
       "additional item is another glmnet object with different values for\n",
       "\\code{beta} and \\code{dev.ratio}\n",
       "\\end{ldescription}\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "Jerome Friedman, Trevor Hastie, Balasubramanian Narasimhan, Noah\n",
       "Simon and Rob Tibshirani\\\\{} Maintainer: Trevor Hastie\n",
       "\\email{hastie@stanford.edu}\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Friedman, J., Hastie, T. and Tibshirani, R. (2008)\n",
       "\\emph{Regularization Paths for Generalized Linear Models via Coordinate\n",
       "Descent}, \\url{https://web.stanford.edu/~hastie/Papers/glmnet.pdf}\\\\{}\n",
       "\\emph{Journal of Statistical Software, Vol. 33(1), 1-22 Feb 2010}\\\\{}\n",
       "\\url{https://www.jstatsoft.org/v33/i01/}\\\\{} Simon, N., Friedman, J., Hastie,\n",
       "T., Tibshirani, R. (2011) \\emph{Regularization Paths for Cox's Proportional\n",
       "Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.\n",
       "39(5) 1-13}\\\\{} \\url{https://www.jstatsoft.org/v39/i05/}\\\\{} Tibshirani,\n",
       "Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N.,Taylor, J. and\n",
       "Tibshirani, Ryan. (2012) \\emph{Strong Rules for Discarding Predictors in\n",
       "Lasso-type Problems, JRSSB vol 74},\\\\{}\n",
       "\\url{https://statweb.stanford.edu/~tibs/ftp/strong.pdf}\\\\{} \\emph{Stanford\n",
       "Statistics Technical Report}\\\\{} \\url{https://arxiv.org/abs/1707.08692}\\\\{}\n",
       "Hastie, T., Tibshirani, Robert, Tibshirani, Ryan (2019) \\emph{Extended\n",
       "Comparisons of Best Subset Selection, Forward Stepwise Selection, and the\n",
       "Lasso}\\\\{} \\emph{Glmnet Vignette}\n",
       "\\url{https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html}\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{print}, \\code{predict}, \\code{coef} and \\code{plot} methods,\n",
       "and the \\code{cv.glmnet} function.\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "\n",
       "# Gaussian\n",
       "x = matrix(rnorm(100 * 20), 100, 20)\n",
       "y = rnorm(100)\n",
       "fit1 = glmnet(x, y)\n",
       "print(fit1)\n",
       "coef(fit1, s = 0.01)  # extract coefficients at a single value of lambda\n",
       "predict(fit1, newx = x[1:10, ], s = c(0.01, 0.005))  # make predictions\n",
       "\n",
       "# Relaxed\n",
       "fit1r = glmnet(x, y, relax = TRUE)  # can be used with any model\n",
       "\n",
       "# multivariate gaussian\n",
       "y = matrix(rnorm(100 * 3), 100, 3)\n",
       "fit1m = glmnet(x, y, family = \"mgaussian\")\n",
       "plot(fit1m, type.coef = \"2norm\")\n",
       "\n",
       "# binomial\n",
       "g2 = sample(1:2, 100, replace = TRUE)\n",
       "fit2 = glmnet(x, g2, family = \"binomial\")\n",
       "fit2r = glmnet(x,g2, family = \"binomial\", relax=TRUE)\n",
       "fit2rp = glmnet(x,g2, family = \"binomial\", relax=TRUE, path=TRUE)\n",
       "\n",
       "# multinomial\n",
       "g4 = sample(1:4, 100, replace = TRUE)\n",
       "fit3 = glmnet(x, g4, family = \"multinomial\")\n",
       "fit3a = glmnet(x, g4, family = \"multinomial\", type.multinomial = \"grouped\")\n",
       "# poisson\n",
       "N = 500\n",
       "p = 20\n",
       "nzc = 5\n",
       "x = matrix(rnorm(N * p), N, p)\n",
       "beta = rnorm(nzc)\n",
       "f = x[, seq(nzc)] %*% beta\n",
       "mu = exp(f)\n",
       "y = rpois(N, mu)\n",
       "fit = glmnet(x, y, family = \"poisson\")\n",
       "plot(fit)\n",
       "pfit = predict(fit, x, s = 0.001, type = \"response\")\n",
       "plot(pfit, y)\n",
       "\n",
       "# Cox\n",
       "set.seed(10101)\n",
       "N = 1000\n",
       "p = 30\n",
       "nzc = p/3\n",
       "x = matrix(rnorm(N * p), N, p)\n",
       "beta = rnorm(nzc)\n",
       "fx = x[, seq(nzc)] %*% beta/3\n",
       "hx = exp(fx)\n",
       "ty = rexp(N, hx)\n",
       "tcens = rbinom(n = N, prob = 0.3, size = 1)  # censoring indicator\n",
       "y = cbind(time = ty, status = 1 - tcens)  # y=Surv(ty,1-tcens) with library(survival)\n",
       "fit = glmnet(x, y, family = \"cox\")\n",
       "plot(fit)\n",
       "\n",
       "# Sparse\n",
       "n = 10000\n",
       "p = 200\n",
       "nzc = trunc(p/10)\n",
       "x = matrix(rnorm(n * p), n, p)\n",
       "iz = sample(1:(n * p), size = n * p * 0.85, replace = FALSE)\n",
       "x[iz] = 0\n",
       "sx = Matrix(x, sparse = TRUE)\n",
       "inherits(sx, \"sparseMatrix\")  #confirm that it is sparse\n",
       "beta = rnorm(nzc)\n",
       "fx = x[, seq(nzc)] %*% beta\n",
       "eps = rnorm(n)\n",
       "y = fx + eps\n",
       "px = exp(fx)\n",
       "px = px/(1 + px)\n",
       "ly = rbinom(n = length(px), prob = px, size = 1)\n",
       "system.time(fit1 <- glmnet(sx, y))\n",
       "system.time(fit2n <- glmnet(x, y))\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "glmnet                 package:glmnet                  R Documentation\n",
       "\n",
       "_\bf_\bi_\bt _\ba _\bG_\bL_\bM _\bw_\bi_\bt_\bh _\bl_\ba_\bs_\bs_\bo _\bo_\br _\be_\bl_\ba_\bs_\bt_\bi_\bc_\bn_\be_\bt _\br_\be_\bg_\bu_\bl_\ba_\br_\bi_\bz_\ba_\bt_\bi_\bo_\bn\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Fit a generalized linear model via penalized maximum likelihood.\n",
       "     The regularization path is computed for the lasso or elasticnet\n",
       "     penalty at a grid of values for the regularization parameter\n",
       "     lambda. Can deal with all shapes of data, including very large\n",
       "     sparse data matrices. Fits linear, logistic and multinomial,\n",
       "     poisson, and Cox regression models.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     glmnet(x, y, family = c(\"gaussian\", \"binomial\", \"poisson\", \"multinomial\",\n",
       "       \"cox\", \"mgaussian\"), weights, offset = NULL, alpha = 1,\n",
       "       nlambda = 100, lambda.min.ratio = ifelse(nobs < nvars, 0.01, 1e-04),\n",
       "       lambda = NULL, standardize = TRUE, intercept = TRUE,\n",
       "       thresh = 1e-07, dfmax = nvars + 1, pmax = min(dfmax * 2 + 20,\n",
       "       nvars), exclude, penalty.factor = rep(1, nvars), lower.limits = -Inf,\n",
       "       upper.limits = Inf, maxit = 1e+05, type.gaussian = ifelse(nvars <\n",
       "       500, \"covariance\", \"naive\"), type.logistic = c(\"Newton\",\n",
       "       \"modified.Newton\"), standardize.response = FALSE,\n",
       "       type.multinomial = c(\"ungrouped\", \"grouped\"), relax = FALSE,\n",
       "       trace.it = 0, ...)\n",
       "     \n",
       "     relax.glmnet(fit, x, ..., maxp = n - 3, path = FALSE,\n",
       "       check.args = TRUE)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "       x: input matrix, of dimension nobs x nvars; each row is an\n",
       "          observation vector. Can be in sparse matrix format (inherit\n",
       "          from class ‘\"sparseMatrix\"’ as in package ‘Matrix’; not yet\n",
       "          available for ‘family=\"cox\"’)\n",
       "\n",
       "       y: response variable. Quantitative for ‘family=\"gaussian\"’, or\n",
       "          ‘family=\"poisson\"’ (non-negative counts). For\n",
       "          ‘family=\"binomial\"’ should be either a factor with two\n",
       "          levels, or a two-column matrix of counts or proportions (the\n",
       "          second column is treated as the target class; for a factor,\n",
       "          the last level in alphabetical order is the target class).\n",
       "          For ‘family=\"multinomial\"’, can be a ‘nc>=2’ level factor, or\n",
       "          a matrix with ‘nc’ columns of counts or proportions.  For\n",
       "          either ‘\"binomial\"’ or ‘\"multinomial\"’, if ‘y’ is presented\n",
       "          as a vector, it will be coerced into a factor. For\n",
       "          ‘family=\"cox\"’, ‘y’ should be a two-column matrix with\n",
       "          columns named 'time' and 'status'. The latter is a binary\n",
       "          variable, with '1' indicating death, and '0' indicating right\n",
       "          censored. The function ‘Surv()’ in package ‘survival’\n",
       "          produces such a matrix. For ‘family=\"mgaussian\"’, ‘y’ is a\n",
       "          matrix of quantitative responses.\n",
       "\n",
       "  family: Response type (see above)\n",
       "\n",
       " weights: observation weights. Can be total counts if responses are\n",
       "          proportion matrices. Default is 1 for each observation\n",
       "\n",
       "  offset: A vector of length ‘nobs’ that is included in the linear\n",
       "          predictor (a ‘nobs x nc’ matrix for the ‘\"multinomial\"’\n",
       "          family). Useful for the ‘\"poisson\"’ family (e.g. log of\n",
       "          exposure time), or for refining a model by starting at a\n",
       "          current fit. Default is ‘NULL’. If supplied, then values must\n",
       "          also be supplied to the ‘predict’ function.\n",
       "\n",
       "   alpha: The elasticnet mixing parameter, with 0<=alpha<= 1. The\n",
       "          penalty is defined as\n",
       "\n",
       "                     (1-alpha)/2||beta||_2^2+alpha||beta||_1.           \n",
       "          \n",
       "          ‘alpha=1’ is the lasso penalty, and ‘alpha=0’ the ridge\n",
       "          penalty.\n",
       "\n",
       " nlambda: The number of ‘lambda’ values - default is 100.\n",
       "\n",
       "lambda.min.ratio: Smallest value for ‘lambda’, as a fraction of\n",
       "          ‘lambda.max’, the (data derived) entry value (i.e. the\n",
       "          smallest value for which all coefficients are zero). The\n",
       "          default depends on the sample size ‘nobs’ relative to the\n",
       "          number of variables ‘nvars’. If ‘nobs > nvars’, the default\n",
       "          is ‘0.0001’, close to zero.  If ‘nobs < nvars’, the default\n",
       "          is ‘0.01’.  A very small value of ‘lambda.min.ratio’ will\n",
       "          lead to a saturated fit in the ‘nobs < nvars’ case. This is\n",
       "          undefined for ‘\"binomial\"’ and ‘\"multinomial\"’ models, and\n",
       "          ‘glmnet’ will exit gracefully when the percentage deviance\n",
       "          explained is almost 1.\n",
       "\n",
       "  lambda: A user supplied ‘lambda’ sequence. Typical usage is to have\n",
       "          the program compute its own ‘lambda’ sequence based on\n",
       "          ‘nlambda’ and ‘lambda.min.ratio’. Supplying a value of\n",
       "          ‘lambda’ overrides this. WARNING: use with care. Avoid\n",
       "          supplying a single value for ‘lambda’ (for predictions after\n",
       "          CV use ‘predict()’ instead).  Supply instead a decreasing\n",
       "          sequence of ‘lambda’ values. ‘glmnet’ relies on its warms\n",
       "          starts for speed, and its often faster to fit a whole path\n",
       "          than compute a single fit.\n",
       "\n",
       "standardize: Logical flag for x variable standardization, prior to\n",
       "          fitting the model sequence. The coefficients are always\n",
       "          returned on the original scale. Default is\n",
       "          ‘standardize=TRUE’.  If variables are in the same units\n",
       "          already, you might not wish to standardize. See details below\n",
       "          for y standardization with ‘family=\"gaussian\"’.\n",
       "\n",
       "intercept: Should intercept(s) be fitted (default=TRUE) or set to zero\n",
       "          (FALSE)\n",
       "\n",
       "  thresh: Convergence threshold for coordinate descent. Each inner\n",
       "          coordinate-descent loop continues until the maximum change in\n",
       "          the objective after any coefficient update is less than\n",
       "          ‘thresh’ times the null deviance. Defaults value is ‘1E-7’.\n",
       "\n",
       "   dfmax: Limit the maximum number of variables in the model. Useful\n",
       "          for very large ‘nvars’, if a partial path is desired.\n",
       "\n",
       "    pmax: Limit the maximum number of variables ever to be nonzero\n",
       "\n",
       " exclude: Indices of variables to be excluded from the model. Default\n",
       "          is none. Equivalent to an infinite penalty factor (next\n",
       "          item).\n",
       "\n",
       "penalty.factor: Separate penalty factors can be applied to each\n",
       "          coefficient. This is a number that multiplies ‘lambda’ to\n",
       "          allow differential shrinkage. Can be 0 for some variables,\n",
       "          which implies no shrinkage, and that variable is always\n",
       "          included in the model. Default is 1 for all variables (and\n",
       "          implicitly infinity for variables listed in ‘exclude’). Note:\n",
       "          the penalty factors are internally rescaled to sum to nvars,\n",
       "          and the lambda sequence will reflect this change.\n",
       "\n",
       "lower.limits: Vector of lower limits for each coefficient; default\n",
       "          ‘-Inf’. Each of these must be non-positive. Can be presented\n",
       "          as a single value (which will then be replicated), else a\n",
       "          vector of length ‘nvars’\n",
       "\n",
       "upper.limits: Vector of upper limits for each coefficient; default\n",
       "          ‘Inf’. See ‘lower.limits’\n",
       "\n",
       "   maxit: Maximum number of passes over the data for all lambda values;\n",
       "          default is 10^5.\n",
       "\n",
       "type.gaussian: Two algorithm types are supported for (only)\n",
       "          ‘family=\"gaussian\"’. The default when ‘nvar<500’ is\n",
       "          ‘type.gaussian=\"covariance\"’, and saves all inner-products\n",
       "          ever computed. This can be much faster than\n",
       "          ‘type.gaussian=\"naive\"’, which loops through ‘nobs’ every\n",
       "          time an inner-product is computed. The latter can be far more\n",
       "          efficient for ‘nvar >> nobs’ situations, or when ‘nvar >\n",
       "          500’.\n",
       "\n",
       "type.logistic: If ‘\"Newton\"’ then the exact hessian is used (default),\n",
       "          while ‘\"modified.Newton\"’ uses an upper-bound on the hessian,\n",
       "          and can be faster.\n",
       "\n",
       "standardize.response: This is for the ‘family=\"mgaussian\"’ family, and\n",
       "          allows the user to standardize the response variables\n",
       "\n",
       "type.multinomial: If ‘\"grouped\"’ then a grouped lasso penalty is used\n",
       "          on the multinomial coefficients for a variable. This ensures\n",
       "          they are all in our out together. The default is\n",
       "          ‘\"ungrouped\"’\n",
       "\n",
       "   relax: If ‘TRUE’ then for each _active set_ in the path of\n",
       "          solutions, the model is refit without any regularization. See\n",
       "          ‘details’ for more information. This argument is new, and\n",
       "          users may experience convergence issues with small datasets,\n",
       "          especially with non-gaussian families. Limiting the value of\n",
       "          'maxp' can alleviate these issues in some cases.\n",
       "\n",
       "trace.it: If ‘trace.it=1’, then a progress bar is displayed; useful for\n",
       "          big models that take a long time to fit.\n",
       "\n",
       "     ...: Additional argument used in ‘relax.glmnet’. These include\n",
       "          some of the original arguments to 'glmnet', and each must be\n",
       "          named if used.\n",
       "\n",
       "     fit: For ‘relax.glmnet’ a fitted 'glmnet' object\n",
       "\n",
       "    maxp: a limit on how many relaxed coefficients are allowed. Default\n",
       "          is 'n-3', where 'n' is the sample size. This may not be\n",
       "          sufficient for non-gaussian familes, in which case users\n",
       "          should supply a smaller value. This argument can be supplied\n",
       "          directly to 'glmnet'.\n",
       "\n",
       "    path: Since ‘glmnet’ does not do stepsize optimization, the Newton\n",
       "          algorithm can get stuck and not converge, especially with\n",
       "          relaxed fits. With ‘path=TRUE’, each relaxed fit on a\n",
       "          particular set of variables is computed pathwise using the\n",
       "          original sequence of lambda values (with a zero attached to\n",
       "          the end). Not needed for Gaussian models, and should not be\n",
       "          used unless needed, since will lead to longer compute times.\n",
       "          Default is ‘path=FALSE’. appropriate subset of variables\n",
       "\n",
       "check.args: Should ‘relax.glmnet’ make sure that all the data dependent\n",
       "          arguments used in creating 'fit' have been resupplied.\n",
       "          Default is 'TRUE'.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The sequence of models implied by ‘lambda’ is fit by coordinate\n",
       "     descent. For ‘family=\"gaussian\"’ this is the lasso sequence if\n",
       "     ‘alpha=1’, else it is the elasticnet sequence.  For the other\n",
       "     families, this is a lasso or elasticnet regularization path for\n",
       "     fitting the generalized linear regression paths, by maximizing the\n",
       "     appropriate penalized log-likelihood (partial likelihood for the\n",
       "     \"cox\" model). Sometimes the sequence is truncated before ‘nlambda’\n",
       "     values of ‘lambda’ have been used, because of instabilities in the\n",
       "     inverse link functions near a saturated fit.\n",
       "     ‘glmnet(...,family=\"binomial\")’ fits a traditional logistic\n",
       "     regression model for the log-odds.\n",
       "     ‘glmnet(...,family=\"multinomial\")’ fits a symmetric multinomial\n",
       "     model, where each class is represented by a linear model (on the\n",
       "     log-scale). The penalties take care of redundancies. A two-class\n",
       "     ‘\"multinomial\"’ model will produce the same fit as the\n",
       "     corresponding ‘\"binomial\"’ model, except the pair of coefficient\n",
       "     matrices will be equal in magnitude and opposite in sign, and half\n",
       "     the ‘\"binomial\"’ values.  Note that the objective function for\n",
       "     ‘\"gaussian\"’ is\n",
       "\n",
       "                        1/2 RSS/nobs +lambda*penalty,                   \n",
       "     \n",
       "     and for the other models it is\n",
       "\n",
       "                        -loglik/nobs +lambda*penalty.                   \n",
       "     \n",
       "     Note also that for ‘\"gaussian\"’, ‘glmnet’ standardizes y to have\n",
       "     unit variance (using 1/n rather than 1/(n-1) formula) before\n",
       "     computing its lambda sequence (and then unstandardizes the\n",
       "     resulting coefficients); if you wish to reproduce/compare results\n",
       "     with other software, best to supply a standardized y. The\n",
       "     coefficients for any predictor variables with zero variance are\n",
       "     set to zero for all values of lambda.  The latest two features in\n",
       "     glmnet are the ‘family=\"mgaussian\"’ family and the\n",
       "     ‘type.multinomial=\"grouped\"’ option for multinomial fitting. The\n",
       "     former allows a multi-response gaussian model to be fit, using a\n",
       "     \"group -lasso\" penalty on the coefficients for each variable.\n",
       "     Tying the responses together like this is called \"multi-task\"\n",
       "     learning in some domains. The grouped multinomial allows the same\n",
       "     penalty for the ‘family=\"multinomial\"’ model, which is also\n",
       "     multi-responsed. For both of these the penalty on the coefficient\n",
       "     vector for variable j is\n",
       "\n",
       "                (1-alpha)/2||beta_j||_2^2+alpha||beta_j||_2.            \n",
       "     \n",
       "     When ‘alpha=1’ this is a group-lasso penalty, and otherwise it\n",
       "     mixes with quadratic just like elasticnet. A small detail in the\n",
       "     Cox model: if death times are tied with censored times, we assume\n",
       "     the censored times occurred just _before_ the death times in\n",
       "     computing the Breslow approximation; if users prefer the usual\n",
       "     convention of _after_, they can add a small number to all\n",
       "     censoring times to achieve this effect.  If ‘relax=TRUE’ a\n",
       "     duplicate sequence of models is produced, where each active set in\n",
       "     the elastic-net path is refit without regularization. The result\n",
       "     of this is a matching ‘\"glmnet\"’ object which is stored on the\n",
       "     original object in a component named ‘\"relaxed\"’, and is part of\n",
       "     the glmnet output. Generally users will not call ‘relax.glmnet’\n",
       "     directly, unless the original 'glmnet' object took a long time to\n",
       "     fit. But if they do, they must supply the fit, and all the\n",
       "     original arguments used to create that fit. They can limit the\n",
       "     length of the relaxed path via 'maxp'.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     An object with S3 class ‘\"glmnet\",\"*\" ’, where ‘\"*\"’ is ‘\"elnet\"’,\n",
       "     ‘\"lognet\"’, ‘\"multnet\"’, ‘\"fishnet\"’ (poisson), ‘\"coxnet\"’ or\n",
       "     ‘\"mrelnet\"’ for the various types of models. If the model was\n",
       "     created with ‘relax=TRUE’ then this class has a prefix class of\n",
       "     ‘\"relaxed\"’.\n",
       "\n",
       "    call: the call that produced this object\n",
       "\n",
       "      a0: Intercept sequence of length ‘length(lambda)’\n",
       "\n",
       "    beta: For ‘\"elnet\"’, ‘\"lognet\"’, ‘\"fishnet\"’ and ‘\"coxnet\"’ models,\n",
       "          a ‘nvars x length(lambda)’ matrix of coefficients, stored in\n",
       "          sparse column format (‘\"CsparseMatrix\"’). For ‘\"multnet\"’ and\n",
       "          ‘\"mgaussian\"’, a list of ‘nc’ such matrices, one for each\n",
       "          class.\n",
       "\n",
       "  lambda: The actual sequence of ‘lambda’ values used. When ‘alpha=0’,\n",
       "          the largest lambda reported does not quite give the zero\n",
       "          coefficients reported (‘lambda=inf’ would in principle).\n",
       "          Instead, the largest ‘lambda’ for ‘alpha=0.001’ is used, and\n",
       "          the sequence of ‘lambda’ values is derived from this.\n",
       "\n",
       "dev.ratio: The fraction of (null) deviance explained (for ‘\"elnet\"’,\n",
       "          this is the R-square). The deviance calculations incorporate\n",
       "          weights if present in the model. The deviance is defined to\n",
       "          be 2*(loglike_sat - loglike), where loglike_sat is the\n",
       "          log-likelihood for the saturated model (a model with a free\n",
       "          parameter per observation). Hence dev.ratio=1-dev/nulldev.\n",
       "\n",
       " nulldev: Null deviance (per observation). This is defined to be\n",
       "          2*(loglike_sat -loglike(Null)); The NULL model refers to the\n",
       "          intercept model, except for the Cox, where it is the 0 model.\n",
       "\n",
       "      df: The number of nonzero coefficients for each value of\n",
       "          ‘lambda’. For ‘\"multnet\"’, this is the number of variables\n",
       "          with a nonzero coefficient for _any_ class.\n",
       "\n",
       "   dfmat: For ‘\"multnet\"’ and ‘\"mrelnet\"’ only. A matrix consisting of\n",
       "          the number of nonzero coefficients per class\n",
       "\n",
       "     dim: dimension of coefficient matrix (ices)\n",
       "\n",
       "    nobs: number of observations\n",
       "\n",
       " npasses: total passes over the data summed over all lambda values\n",
       "\n",
       "  offset: a logical variable indicating whether an offset was included\n",
       "          in the model\n",
       "\n",
       "    jerr: error flag, for warnings and errors (largely for internal\n",
       "          debugging).\n",
       "\n",
       " relaxed: If ‘relax=TRUE’, this additional item is another glmnet\n",
       "          object with different values for ‘beta’ and ‘dev.ratio’\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     Jerome Friedman, Trevor Hastie, Balasubramanian Narasimhan, Noah\n",
       "     Simon and Rob Tibshirani\n",
       "     Maintainer: Trevor Hastie <email: hastie@stanford.edu>\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Friedman, J., Hastie, T. and Tibshirani, R. (2008) _Regularization\n",
       "     Paths for Generalized Linear Models via Coordinate Descent_, <URL:\n",
       "     https://web.stanford.edu/~hastie/Papers/glmnet.pdf>\n",
       "     _Journal of Statistical Software, Vol. 33(1), 1-22 Feb 2010_\n",
       "     <URL: https://www.jstatsoft.org/v33/i01/>\n",
       "     Simon, N., Friedman, J., Hastie, T., Tibshirani, R. (2011)\n",
       "     _Regularization Paths for Cox's Proportional Hazards Model via\n",
       "     Coordinate Descent, Journal of Statistical Software, Vol. 39(5)\n",
       "     1-13_\n",
       "     <URL: https://www.jstatsoft.org/v39/i05/>\n",
       "     Tibshirani, Robert, Bien, J., Friedman, J., Hastie, T.,Simon,\n",
       "     N.,Taylor, J. and Tibshirani, Ryan. (2012) _Strong Rules for\n",
       "     Discarding Predictors in Lasso-type Problems, JRSSB vol 74_,\n",
       "     <URL: https://statweb.stanford.edu/~tibs/ftp/strong.pdf>\n",
       "     _Stanford Statistics Technical Report_\n",
       "     <URL: https://arxiv.org/abs/1707.08692>\n",
       "     Hastie, T., Tibshirani, Robert, Tibshirani, Ryan (2019) _Extended\n",
       "     Comparisons of Best Subset Selection, Forward Stepwise Selection,\n",
       "     and the Lasso_\n",
       "     _Glmnet Vignette_ <URL:\n",
       "     https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html>\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     ‘print’, ‘predict’, ‘coef’ and ‘plot’ methods, and the ‘cv.glmnet’\n",
       "     function.\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     # Gaussian\n",
       "     x = matrix(rnorm(100 * 20), 100, 20)\n",
       "     y = rnorm(100)\n",
       "     fit1 = glmnet(x, y)\n",
       "     print(fit1)\n",
       "     coef(fit1, s = 0.01)  # extract coefficients at a single value of lambda\n",
       "     predict(fit1, newx = x[1:10, ], s = c(0.01, 0.005))  # make predictions\n",
       "     \n",
       "     # Relaxed\n",
       "     fit1r = glmnet(x, y, relax = TRUE)  # can be used with any model\n",
       "     \n",
       "     # multivariate gaussian\n",
       "     y = matrix(rnorm(100 * 3), 100, 3)\n",
       "     fit1m = glmnet(x, y, family = \"mgaussian\")\n",
       "     plot(fit1m, type.coef = \"2norm\")\n",
       "     \n",
       "     # binomial\n",
       "     g2 = sample(1:2, 100, replace = TRUE)\n",
       "     fit2 = glmnet(x, g2, family = \"binomial\")\n",
       "     fit2r = glmnet(x,g2, family = \"binomial\", relax=TRUE)\n",
       "     fit2rp = glmnet(x,g2, family = \"binomial\", relax=TRUE, path=TRUE)\n",
       "     \n",
       "     # multinomial\n",
       "     g4 = sample(1:4, 100, replace = TRUE)\n",
       "     fit3 = glmnet(x, g4, family = \"multinomial\")\n",
       "     fit3a = glmnet(x, g4, family = \"multinomial\", type.multinomial = \"grouped\")\n",
       "     # poisson\n",
       "     N = 500\n",
       "     p = 20\n",
       "     nzc = 5\n",
       "     x = matrix(rnorm(N * p), N, p)\n",
       "     beta = rnorm(nzc)\n",
       "     f = x[, seq(nzc)] %*% beta\n",
       "     mu = exp(f)\n",
       "     y = rpois(N, mu)\n",
       "     fit = glmnet(x, y, family = \"poisson\")\n",
       "     plot(fit)\n",
       "     pfit = predict(fit, x, s = 0.001, type = \"response\")\n",
       "     plot(pfit, y)\n",
       "     \n",
       "     # Cox\n",
       "     set.seed(10101)\n",
       "     N = 1000\n",
       "     p = 30\n",
       "     nzc = p/3\n",
       "     x = matrix(rnorm(N * p), N, p)\n",
       "     beta = rnorm(nzc)\n",
       "     fx = x[, seq(nzc)] %*% beta/3\n",
       "     hx = exp(fx)\n",
       "     ty = rexp(N, hx)\n",
       "     tcens = rbinom(n = N, prob = 0.3, size = 1)  # censoring indicator\n",
       "     y = cbind(time = ty, status = 1 - tcens)  # y=Surv(ty,1-tcens) with library(survival)\n",
       "     fit = glmnet(x, y, family = \"cox\")\n",
       "     plot(fit)\n",
       "     \n",
       "     # Sparse\n",
       "     n = 10000\n",
       "     p = 200\n",
       "     nzc = trunc(p/10)\n",
       "     x = matrix(rnorm(n * p), n, p)\n",
       "     iz = sample(1:(n * p), size = n * p * 0.85, replace = FALSE)\n",
       "     x[iz] = 0\n",
       "     sx = Matrix(x, sparse = TRUE)\n",
       "     inherits(sx, \"sparseMatrix\")  #confirm that it is sparse\n",
       "     beta = rnorm(nzc)\n",
       "     fx = x[, seq(nzc)] %*% beta\n",
       "     eps = rnorm(n)\n",
       "     y = fx + eps\n",
       "     px = exp(fx)\n",
       "     px = px/(1 + px)\n",
       "     ly = rbinom(n = length(px), prob = px, size = 1)\n",
       "     system.time(fit1 <- glmnet(sx, y))\n",
       "     system.time(fit2n <- glmnet(x, y))\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?glmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "* Ver [3_minimos_cuadrados](https://github.com/ITAM-DS/Propedeutico/blob/master/Python/clases/3_algebra_lineal/3_minimos_cuadrados.ipynb) para una introducción al problema de mínimos cuadrados con ejemplos en Python3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
