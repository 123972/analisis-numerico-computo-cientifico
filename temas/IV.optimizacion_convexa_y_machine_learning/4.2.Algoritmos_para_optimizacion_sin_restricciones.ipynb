{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota basada en [liga1](https://drive.google.com/file/d/1xtkxPCx05Xg4Dj7JZoQ-LusBDrtYUqOF/view?usp=sharing), [liga2](https://drive.google.com/file/d/16-_PvWNaO0Zc9x04-SRsxCRdn5fxebf2/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas de optimización sin restricciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta nota se consideran resolver problemas de la forma:\n",
    "\n",
    "$$\\min f_o(x)$$\n",
    "\n",
    "con $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ convexa y $f \\in \\mathcal{C}^2(\\text{dom}f)$.\n",
    "\n",
    "También se asume que existe un punto óptimo $x^*$ por lo que el problema tiene solución y el valor óptimo se denota por $p^* = f(x^*) = \\inf f(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo anterior una **condición necesaria y suficiente** para que $x^*$ sea óptimo es: $\\nabla f(x^*) = 0$ que **en general** es un conjunto de $n$ **ecuaciones no lineales** en $n$ variables y que resuelve el problema de optimización planteado al inicio. \n",
    "\n",
    "\n",
    "**Ejemplos:**\n",
    "\n",
    "1)$$\\displaystyle \\min_{x \\in \\mathbb{R}^2} x_1^4+2x_1^2x_2+x_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces:\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = \n",
    "\\left [\n",
    "\\begin{array}{c}\n",
    "4x_1^3+4x_1x_2\\\\\n",
    "2x_1^2+2x_2\n",
    "\\end{array}\n",
    "\\right ]=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "que es una ecuación de dos variables y dos incógnitas **no lineal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) $$\\displaystyle \\min_{x \\in \\mathbb{R}^2} \\frac{1}{2}x^TPx+q^Tx+r$$\n",
    "\n",
    "con $P=\\left [\\begin{array}{cc}\n",
    "5 & 4\\\\\n",
    "4 & 5\n",
    "\\end{array}\n",
    "\\right ]$, $q=\\left [\\begin{array}{c}\n",
    "-1\\\\\n",
    "1\n",
    "\\end{array}\n",
    "\\right]\n",
    "$, $r=3$. Obsérvese que haciendo las multiplicaciones de matriz-vector y productos punto se reescribe el problema como:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\displaystyle \\min_{x \\in \\mathbb{R}^2} \\frac{5}{2}x_1^2 + \\frac{5}{2}x_2^2+4x_1x_2 -x_1 + x_2+3$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces:\n",
    "\n",
    "$$\\nabla f(x) = Px +q =\\left [ \\begin{array}{cc}\n",
    "5 & 4\\\\\n",
    "4 & 5\n",
    "\\end{array}\n",
    "\\right ]\n",
    "\\left [ \\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\n",
    "\\end{array}\n",
    "\\right ]\n",
    "+ \\left [ \\begin{array}{c}\n",
    "-1\\\\\n",
    "1\n",
    "\\end{array}\n",
    "\\right ]=\n",
    "\\left [ \\begin{array}{cc}\n",
    "5x_1+4x_2-1\\\\\n",
    "4x_1+5x_2+1\n",
    "\\end{array}\n",
    "\\right ]\n",
    "=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "que es una ecuación en dos variables con dos incógnitas **lineal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentario:** en algunos casos especiales es posible resolver la ecuación no lineal $\\nabla f(x) = 0$ para $x$ de forma analítica o cerrada. Este es el caso del ejemplo $2$ anterior la cual está dada por $x^* = -P^{-1}q$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P=np.array([[5,4],[4,5]])\n",
    "q=np.array([-1,1])\n",
    "np.linalg.solve(P,-q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pero típicamente se utiliza un algoritmo iterativo: calcular una secuencia de puntos $x^{(0)}, x^{(1)}, \\dots \\in \\text{dom}f$ con $f(x^{(k)}) \\rightarrow p^*$ si $k \\rightarrow \\infty$. El conjunto de puntos $x^{(0)}, x^{(1)},\\dots$ se nombra **secuencia de minimización** para el problema de optimización. El algoritmo termina si $f(x^{(k)})-p^* \\leq \\epsilon$ con $\\epsilon >0$ una tolerancia dada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de búsqueda de línea por *backtracking*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de descenso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Algoritmo de descenso\n",
    ">> Punto inicial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de máximo de descenso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influencia del número de condición "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_index(vec,index,h):\n",
    "    '''\n",
    "    Auxiliary function for gradient and Hessian computation.\n",
    "    Args:\n",
    "        vec (array): numpy array\n",
    "        index (int): index \n",
    "        h (float):   quantity that vec[index] will be increased\n",
    "    Returns:\n",
    "        vec (array): \n",
    "    '''\n",
    "    vec[index] +=h\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_index(vec,index,h):\n",
    "    '''\n",
    "    Auxiliary function for gradient and Hessian computation.\n",
    "    Args:\n",
    "        vec (array): numpy array\n",
    "        index (int): index \n",
    "        h (float):   quantity that vec[index] will be decreased\n",
    "    Returns:\n",
    "        vec (array): \n",
    "    '''\n",
    "    vec[index] -=h\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_approximation(f,x,h=1e-8):\n",
    "    '''\n",
    "    Numerical approximation of gradient for function f using forward differences.\n",
    "    Args:\n",
    "        f (lambda expression): definition of function f\n",
    "        x (array): numpy array that holds values where gradient will be computed\n",
    "        h (float): step size for forward differences, tipically h=1e-8\n",
    "    Returns:\n",
    "        gf (array):\n",
    "    '''\n",
    "    n = x.size\n",
    "    gf = np.zeros(n)\n",
    "    f_x = f(x)\n",
    "    for i in np.arange(n):\n",
    "        inc_index(x,i,h)\n",
    "        gf[i] = f(x) - f_x\n",
    "        dec_index(x,i,h)\n",
    "    return gf/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hessian_approximation(f,x,h=1e-6):\n",
    "    '''\n",
    "    Numerical approximation of Hessian for function f using forward differences.\n",
    "    Args:\n",
    "        f (lambda expression): definition of function f\n",
    "        x (array): numpy array that holds values where Hessian will be computed\n",
    "        h (float): step size for forward differences, tipically h=1e-6\n",
    "    Returns:\n",
    "        Hf (array):\n",
    "    '''\n",
    "    n = x.size\n",
    "    Hf = np.zeros((n,n))\n",
    "    f_x = f(x)\n",
    "    for i in np.arange(n):\n",
    "        inc_index(x,i,h)\n",
    "        f_x_inc_in_i = f(x)\n",
    "        for j in np.arange(i,n):\n",
    "            inc_index(x,j,h)\n",
    "            f_x_inc_in_i_j = f(x)\n",
    "            dec_index(x,i,h)\n",
    "            f_x_inc_in_j = f(x)\n",
    "            dif = f_x_inc_in_i_j-f_x_inc_in_i-f_x_inc_in_j+f_x\n",
    "            Hf[i,j] = dif\n",
    "            if j != i:\n",
    "                Hf[j,i] = dif\n",
    "            dec_index(x,j,h)\n",
    "            inc_index(x,i,h)\n",
    "        dec_index(x,i,h)\n",
    "    return Hf/h**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ej = lambda x: (x[0]**2-x[1]**2)**2+x[0]**2+(x[2]**2-x[3]**2)**2+x[2]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = np.array([1.5,1.5,1.5,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_ej(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.00000007e+00, 8.88178420e-08, 3.00000007e+00, 8.88178420e-08])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_approximation(f_ej,x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 1.5, 1.5, 1.5])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20.00000165, -17.99982385,   0.        ,   0.        ],\n",
       "       [-17.99982385,  17.99982385,   0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,  20.00000165, -17.99982385],\n",
       "       [  0.        ,   0.        , -17.99982385,  17.99982385]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hessian_approximation(f_ej,x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 1.5, 1.5, 1.5])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(alpha, beta,f,dir_desc,x,derivada_direccional):\n",
    "    t=1\n",
    "    if alpha > 1/2:\n",
    "        print('alpha de backtracking debe ser menor o igual a 1/2')\n",
    "        t=-1\n",
    "    if beta>1:\n",
    "        disp('beta de backtracking debe ser menor a 1')\n",
    "        t=-1;\n",
    "        \n",
    "    if t!=-1:\n",
    "        eval1 = f(x+t*dir_desc)\n",
    "        eval2 = f(x) + alpha*t*derivada_direccional\n",
    "        while eval1 > eval2:\n",
    "            t=beta*t\n",
    "            eval1=f(x+t*dir_desc)\n",
    "            eval2=f(x)+alpha*t*derivada_direccional\n",
    "    else:\n",
    "        t=-1\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "* S. P. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, 2009.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
