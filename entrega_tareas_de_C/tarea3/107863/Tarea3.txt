#NOTA: Para activar/desactivar conexi칩n con ssh ket
# sudo nano /etc/ssh/sshd_config
# PasswordAuthentication no

# Comandos en bash que se utilizan para montar el lcuster de hadoop usando docker

# Descargamos una imagen de ubuntu
# sudo docker pull ubuntu16.04

# Montamos el contenedor Master
sudo docker run -it --name hadoop-master -v /home/victor/Documents/Hadoop:/datos ubuntu:16.04 /bin/bash

# Salimos
exit

# Montamos el contenedor Slave1
sudo docker run -it --name hadoop-slave-1 -v /home/victor/Documents/Hadoop:/datos ubuntu:16.04 /bin/bash

# Salimos
exit

# Montamos el contenedor Slave2
sudo docker run -it --name hadoop-slave-2 -v /home/victor/Documents/Hadoop:/datos ubuntu:16.04 /bin/bash

# Salimos
exit

# Montamos el contenedor Slave2
sudo docker run -it -p 53022:22 --name hadoop-slave-3 -v /home/victor/Documents/Hadoop:/datos ubuntu:16.04 /bin/bash

# Salimos
exit

# Iniciamos los contenedores
sudo docker start hadoop-master
sudo docker start hadoop-slave-1
sudo docker start hadoop-slave-2


# Revisamos la IP de los nuevos contenedores
docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' hadoop-master
docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' hadoop-slave-1
docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' hadoop-slave-2

# Las IP asociadas son:
# Master: 172.17.0.5
# Slave-1: 172.17.0.6
# Slave-2: 172.17.0.4

##################################################################################################
# Hasta nuevo aviso, las instrucciones siguientes se deben repetir en cada uno de los contenedores

# Actualizamos ubuntu
apt-get update

# Instalamos java
apt-get install -y default-jdk

# Verificamos la version de java
java -version

# Editamos el host
apt-get install nano
nano /etc/hosts

# Master tiene 172.17.0.2 hadoop_master
# Salve-1 tiene 172.17.0.3 slave-1
# Salve-2 tiene 172.17.0.4 82b1dfde9ed5
# Salve-3 tiene 172.17.0.5 d96f115f1a1cl

# Lo modificamos a 
172.17.0.2 hadoop-master
172.17.0.3 hadoop-slave-1
172.17.0.4 hadoop-slave-2
172.17.0.5 hadoop-slave-3

# Instalamos SSH
apt install -y openssh-client
apt install -y openssh-server

# Creamos usuario "hadoop" con pass "hadoop"
adduser hadoop

# Creamos la llave
ssh-keygen

# Pasamos la llave a cada una de las m치quinas
# En este caso se asume que estamos con hadoop-master
ssh-copy-id hadoop@172.17.0.3
ssh-copy-id hadoop@172.17.0.4
ssh-copy-id hadoop@172.17.0.5

# Se itera el proceso de las otras m치quinas

# Hasta este punto las cuatro maquinas virtuales deben estar configuradas #
###########################################################################

# Se procede A instalar hadoop, pero ya una vez que nos aseguramos que las m치quinas se comuniquen

187.177.134.59

