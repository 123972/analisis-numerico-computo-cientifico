# Avance_02_05_2017
## Integrantes:

    Ixchel Guadalupe Meza Chávez  
    Amaury Gutierrez Acosta  

## Trabajo:
### Individual

**Ixchel**:  

Seguí leyendo los artículos recomendados por Erick que se encuentran en las referencias de este avance e hice notas para el trabajo escrito y la presentación.

**Amaury**:

Durante la semana pasada el agente se estuvo entrenando por varios días. El resultado para nuestra sorpresa fue que el agente consistentemente se volvió muy malo. Analizando el código se tuvo la hipótesis de que el signo de la actualización del gradiente era incorrecto. El agente efectivamente estaba aprendiendo, pero al revés de lo deseado, se alejaba cada vez más de la política óptima. Se corrigió este error y se lanzó un nuevo entrenamiento. Aparentemente las cosas van bien pero hacen falta algunos días para determinarlo con certeza. Se comenzó la implementación real en el lenguaje de programación C. Durante esta semana se reimplementará el prototipo en dicho lenguaje.

### Equipo

Se comenzó el esquema para la [presentación](https://ixime.github.io/Pong-RL) y trabajo escrito finales.

 ## Referencias
 
 - [Optimization Methods for Large-Scale Machine Learning](http://leon.bottou.org/publications/pdf/tr-optml-2016.pdf)

 - [The Tradeoffs of Large Scale Learning](http://leon.bottou.org/publications/pdf/nips-2007.pdf)

 - [Efficient BackProp](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)

