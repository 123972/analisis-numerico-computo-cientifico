# Avance_26_04_2017
## Integrantes:

    Ixchel Guadalupe Meza Chávez  
    Amaury Gutierrez Acosta  

## Trabajo:
### Individual

**Ixchel**:  

Lei hasta el capítulo 4 de este [artículo](http://leon.bottou.org/publications/pdf/tr-optml-2016.pdf), este otro [artículo](http://leon.bottou.org/publications/pdf/nips-2007.pdf) y parte de este otro [artículo](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) que Erick nos recomendó que leyeramos. Sigo leyendo lo que me falta por leer del tercer artículo y el resto del primer artículo.

**Amaury**:

Se continuó con implementó un prototipo del algoritmo usando python y [Open Gym AI](https://github.com/openai/gym) como se detalló en el avance de la semana anterior. Se revisó la derivación de la función softmax, para entender como es que se está optimizando la función de pérdida. La implementación del prototipo se puede encontrar [aquí](https://github.com/amaurs/breakout-rl). Este código está basado en las notas de [Andrej Karpathy](http://karpathy.github.io/2016/05/31/rl/). Se revisaron (sin demasiado detalle por cuestiones de tiempo), las referencias de los comentarios de los avances de la semana anterior.

### Equipo

Se comenzó el esquema para la [presentación](https://github.com/ixime/reveal.js) y trabajo escrito finales.

 ## Referencias
 
 - [Optimization Methods for Large-Scale Machine Learning](http://leon.bottou.org/publications/pdf/tr-optml-2016.pdf)

 - [The Tradeoffs of Large Scale Learning](http://leon.bottou.org/publications/pdf/nips-2007.pdf)

 - [Efficient BackProp](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)

